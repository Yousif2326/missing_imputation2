{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 11:21:36.963101: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-29 11:21:48.869699: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-29 11:21:49.928261: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-29 11:21:50.523089: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-29 11:21:53.242620: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-29 11:23:08.544347: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcc12/openmpi/4.1.5/lib/libmpi_cxx.so.40: undefined symbol: ompi_mpi_errors_throw_exceptions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 52\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ks_2samp\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmiceforest\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmf\u001b[39;00m\n",
      "File \u001b[0;32m~/py311/lib/python3.11/site-packages/miceforest/__init__.py:13\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mmiceforest, Multiple Imputation by Chained Equations with LightGBM.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03mhttps://github.com/AnotherSamWilson/miceforest\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mimportlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetadata\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimputation_kernel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImputationKernel\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimputed_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImputedData\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ampute_data\n",
      "File \u001b[0;32m~/py311/lib/python3.11/site-packages/miceforest/imputation_kernel.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m warn\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Booster, Dataset, cv, early_stopping, log_evaluation, train\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlightgbm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _ConfigAliases\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Categorical, DataFrame, MultiIndex, Series, read_parquet\n",
      "File \u001b[0;32m~/py311/lib/python3.11/site-packages/lightgbm/__init__.py:9\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"LightGBM, Light Gradient Boosting Machine.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mContributors: https://github.com/microsoft/LightGBM/graphs/contributors.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Booster, Dataset, Sequence, register_logger\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStopException, early_stopping, log_evaluation, record_evaluation, reset_parameter\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CVBooster, cv, train\n",
      "File \u001b[0;32m~/py311/lib/python3.11/site-packages/lightgbm/basic.py:281\u001b[0m\n\u001b[1;32m    279\u001b[0m     _LIB \u001b[38;5;241m=\u001b[39m Mock(ctypes\u001b[38;5;241m.\u001b[39mCDLL)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 281\u001b[0m     _LIB \u001b[38;5;241m=\u001b[39m \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m _NUMERIC_TYPES \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_safe_call\u001b[39m(ret: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/py311/lib/python3.11/site-packages/lightgbm/basic.py:265\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load LightGBM library.\"\"\"\u001b[39;00m\n\u001b[1;32m    264\u001b[0m lib_path \u001b[38;5;241m=\u001b[39m find_lib_path()\n\u001b[0;32m--> 265\u001b[0m lib \u001b[38;5;241m=\u001b[39m \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcdll\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoadLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlib_path\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m lib\u001b[38;5;241m.\u001b[39mLGBM_GetLastError\u001b[38;5;241m.\u001b[39mrestype \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p\n\u001b[1;32m    267\u001b[0m callback \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mCFUNCTYPE(\u001b[38;5;28;01mNone\u001b[39;00m, ctypes\u001b[38;5;241m.\u001b[39mc_char_p)\n",
      "File \u001b[0;32m/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.11.5/lib/python3.11/ctypes/__init__.py:454\u001b[0m, in \u001b[0;36mLibraryLoader.LoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mLoadLibrary\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[0;32m--> 454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dlltype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.11.5/lib/python3.11/ctypes/__init__.py:376\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[0;31mOSError\u001b[0m: /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcc12/openmpi/4.1.5/lib/libmpi_cxx.so.40: undefined symbol: ompi_mpi_errors_throw_exceptions"
     ]
    }
   ],
   "source": [
    "print(\"start\")\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import json\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import scipy.stats as stats\n",
    "# import statsmodels.api as sm\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Lambda, Dropout, Concatenate\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error as sk_mse\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import miceforest as mf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- -------------------------\n",
      "absl-py                      2.3.1\n",
      "accelerate                   1.8.1\n",
      "aiofiles                     24.1.0+computecanada\n",
      "aiohappyeyeballs             2.6.1+computecanada\n",
      "aiohttp                      3.12.13+computecanada\n",
      "aiosignal                    1.3.2+computecanada\n",
      "annotated_types              0.7.0+computecanada\n",
      "anyio                        4.9.0+computecanada\n",
      "argon2-cffi                  25.1.0\n",
      "argon2_cffi_bindings         21.2.0+computecanada\n",
      "arrow                        1.3.0+computecanada\n",
      "asttokens                    3.0.0+computecanada\n",
      "astunparse                   1.6.3+computecanada\n",
      "async-lru                    2.0.5\n",
      "attrs                        25.3.0+computecanada\n",
      "babel                        2.17.0+computecanada\n",
      "beautifulsoup4               4.13.4+computecanada\n",
      "bleach                       6.2.0+computecanada\n",
      "blinker                      1.9.0+computecanada\n",
      "certifi                      2025.6.15+computecanada\n",
      "cffi                         1.17.1+computecanada\n",
      "charset_normalizer           3.4.2+computecanada\n",
      "click                        8.2.1+computecanada\n",
      "comm                         0.2.2+computecanada\n",
      "contourpy                    1.3.1+computecanada\n",
      "cycler                       0.12.1+computecanada\n",
      "datasets                     3.6.0+computecanada\n",
      "debugpy                      1.8.12+computecanada\n",
      "decorator                    5.1.1+computecanada\n",
      "defusedxml                   0.7.1+computecanada\n",
      "dill                         0.3.8+computecanada\n",
      "et_xmlfile                   2.0.0+computecanada\n",
      "executing                    2.2.0+computecanada\n",
      "fastapi                      0.115.14\n",
      "fastjsonschema               2.21.1+computecanada\n",
      "ffmpy                        0.6.0\n",
      "filelock                     3.18.0+computecanada\n",
      "flask                        2.3.3+computecanada\n",
      "flatbuffers                  25.2.10+computecanada\n",
      "fonttools                    4.59.0+computecanada\n",
      "fqdn                         1.5.1+computecanada\n",
      "frozenlist                   1.7.0+computecanada\n",
      "fsspec                       2025.3.0+computecanada\n",
      "gast                         0.6.0+computecanada\n",
      "git-filter-repo              2.47.0\n",
      "google-pasta                 0.2.0+computecanada\n",
      "gradio                       5.35.0\n",
      "gradio_client                1.10.4\n",
      "groovy                       0.1.2+computecanada\n",
      "grpcio                       1.73.0+computecanada\n",
      "h11                          0.16.0+computecanada\n",
      "h5py                         3.13.0+computecanada\n",
      "hf_xet                       1.1.3+computecanada\n",
      "httpcore                     1.0.9+computecanada\n",
      "httpx                        0.28.1+computecanada\n",
      "huggingface-hub              0.33.2\n",
      "idna                         3.10+computecanada\n",
      "ipykernel                    6.29.5+computecanada\n",
      "ipython                      8.32.0+computecanada\n",
      "ipywidgets                   8.1.5+computecanada\n",
      "isoduration                  20.11.0+computecanada\n",
      "itsdangerous                 2.2.0+computecanada\n",
      "jedi                         0.19.2+computecanada\n",
      "jinja2                       3.1.6+computecanada\n",
      "joblib                       1.5.1+computecanada\n",
      "json5                        0.12.0\n",
      "jsonpointer                  3.0.0+computecanada\n",
      "jsonschema                   4.24.0+computecanada\n",
      "jsonschema_specifications    2025.4.1+computecanada\n",
      "jupyter_client               8.6.3+computecanada\n",
      "jupyter_core                 5.7.2+computecanada\n",
      "jupyter_events               0.12.0+computecanada\n",
      "jupyter_lsp                  2.2.5+computecanada\n",
      "jupyter_server               2.16.0\n",
      "jupyter_server_terminals     0.5.3+computecanada\n",
      "jupyterlab                   4.4.4\n",
      "jupyterlab_pygments          0.3.0+computecanada\n",
      "jupyterlab_server            2.27.3+computecanada\n",
      "jupyterlab_widgets           3.0.13+computecanada\n",
      "keras                        3.10.0+computecanada\n",
      "kiwisolver                   1.4.8+computecanada\n",
      "libclang                     14.0.1+computecanada\n",
      "lightgbm                     4.5.0+computecanada\n",
      "markdown                     3.8.2+computecanada\n",
      "markdown_it_py               3.0.0+computecanada\n",
      "MarkupSafe                   2.1.5+computecanada\n",
      "matplotlib                   3.10.1+computecanada\n",
      "matplotlib_inline            0.1.7+computecanada\n",
      "mdurl                        0.1.2+computecanada\n",
      "miceforest                   6.0.3\n",
      "mistune                      3.1.3\n",
      "ml_dtypes                    0.2.0+computecanada\n",
      "mpmath                       1.3.0+computecanada\n",
      "multidict                    6.6.3\n",
      "multiprocess                 0.70.16+computecanada\n",
      "namex                        0.1.0+computecanada\n",
      "nbclient                     0.10.2+computecanada\n",
      "nbconvert                    7.16.6+computecanada\n",
      "nbformat                     5.10.4+computecanada\n",
      "nest_asyncio                 1.6.0+computecanada\n",
      "networkx                     3.5+computecanada\n",
      "nose                         1.3.7+computecanada\n",
      "notebook                     7.4.4\n",
      "notebook_shim                0.2.4+computecanada\n",
      "numpy                        1.26.4+computecanada\n",
      "openpyxl                     3.1.5+computecanada\n",
      "opt_einsum                   3.4.0+computecanada\n",
      "optree                       0.14.0+computecanada\n",
      "orjson                       3.10.5+computecanada\n",
      "overrides                    7.7.0+computecanada\n",
      "packaging                    25.0+computecanada\n",
      "pandas                       2.2.3+computecanada\n",
      "pandocfilters                1.5.1+computecanada\n",
      "parso                        0.8.4+computecanada\n",
      "peft                         0.15.2+computecanada\n",
      "pexpect                      4.9.0+computecanada\n",
      "pillow                       11.1.0+computecanada\n",
      "pip                          25.1.1\n",
      "platformdirs                 3.10.0+computecanada\n",
      "prometheus_client            0.22.1+computecanada\n",
      "prompt_toolkit               3.0.50+computecanada\n",
      "propcache                    0.3.2+computecanada\n",
      "protobuf                     4.25.8+computecanada\n",
      "psutil                       6.1.1+computecanada\n",
      "ptyprocess                   0.7.0+computecanada\n",
      "pure_eval                    0.2.3+computecanada\n",
      "pyarrow                      19.0.1\n",
      "pycparser                    2.22+computecanada\n",
      "pydantic                     2.11.7+computecanada\n",
      "pydantic_core                2.33.2+computecanada\n",
      "pydub                        0.25.1+computecanada\n",
      "pygments                     2.19.2+computecanada\n",
      "pyparsing                    3.2.3+computecanada\n",
      "python_dateutil              2.9.0.post0+computecanada\n",
      "python_json_logger           3.3.0+computecanada\n",
      "python_multipart             0.0.20+computecanada\n",
      "pytz                         2025.2+computecanada\n",
      "PyYAML                       6.0.2+computecanada\n",
      "pyzmq                        26.2.1+computecanada\n",
      "referencing                  0.36.2+computecanada\n",
      "regex                        2024.11.6+computecanada\n",
      "requests                     2.32.4+computecanada\n",
      "rfc3339_validator            0.1.4+computecanada\n",
      "rfc3986_validator            0.1.1+computecanada\n",
      "rich                         14.0.0+computecanada\n",
      "rpds_py                      0.21.0+computecanada\n",
      "ruff                         0.11.0+computecanada\n",
      "safehttpx                    0.1.6+computecanada\n",
      "safetensors                  0.5.3+computecanada\n",
      "scikit_learn                 1.6.1+computecanada\n",
      "scipy                        1.15.2+computecanada\n",
      "seaborn                      0.13.2+computecanada\n",
      "semantic_version             2.10.0+computecanada\n",
      "Send2Trash                   1.8.3+computecanada\n",
      "setuptools                   80.7.1\n",
      "shellingham                  1.5.4+computecanada\n",
      "six                          1.17.0+computecanada\n",
      "sniffio                      1.3.1+computecanada\n",
      "soupsieve                    2.7+computecanada\n",
      "stack_data                   0.6.3+computecanada\n",
      "starlette                    0.46.2+computecanada\n",
      "sympy                        1.13.3+computecanada\n",
      "tensorboard                  2.17.1+computecanada\n",
      "tensorboard_data_server      0.7.2+computecanada\n",
      "tensorflow                   2.17.0+computecanada\n",
      "tensorflow_io_gcs_filesystem 0.32.0+computecanada\n",
      "termcolor                    3.1.0+computecanada\n",
      "terminado                    0.18.1+computecanada\n",
      "threadpoolctl                3.6.0+computecanada\n",
      "tinycss2                     1.4.0+computecanada\n",
      "tokenizers                   0.21.1+computecanada\n",
      "tomlkit                      0.13.3+computecanada\n",
      "torch                        2.7.1+computecanada\n",
      "tornado                      6.4.2+computecanada\n",
      "tqdm                         4.67.1+computecanada\n",
      "traitlets                    5.14.3+computecanada\n",
      "transformers                 4.53.0+computecanada\n",
      "typer                        0.16.0+computecanada\n",
      "types-python-dateutil        2.9.0.20250516\n",
      "typing_extensions            4.14.0+computecanada\n",
      "typing_inspection            0.4.1+computecanada\n",
      "tzdata                       2025.2+computecanada\n",
      "uri_template                 1.3.0+computecanada\n",
      "urllib3                      2.5.0+computecanada\n",
      "uvicorn                      0.35.0\n",
      "wcwidth                      0.2.13+computecanada\n",
      "webcolors                    24.11.1+computecanada\n",
      "webencodings                 0.5.1+computecanada\n",
      "websocket_client             1.8.0+computecanada\n",
      "websockets                   15.0.1+computecanada\n",
      "werkzeug                     3.1.3+computecanada\n",
      "wheel                        0.45.1+computecanada\n",
      "widgetsnbextension           4.0.13+computecanada\n",
      "wrapt                        1.17.2+computecanada\n",
      "xxhash                       3.5.0+computecanada\n",
      "yarl                         1.20.1+computecanada\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import + only Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>operation_date</th>\n",
       "      <th>redcap_event_name</th>\n",
       "      <th>ComplicationDate</th>\n",
       "      <th>dob</th>\n",
       "      <th>qol_date</th>\n",
       "      <th>age_diagnosis</th>\n",
       "      <th>gender</th>\n",
       "      <th>overall_primary_tumour</th>\n",
       "      <th>overall_regional_ln</th>\n",
       "      <th>...</th>\n",
       "      <th>a_e5</th>\n",
       "      <th>a_e6</th>\n",
       "      <th>a_e7</th>\n",
       "      <th>a_c6</th>\n",
       "      <th>a_c2</th>\n",
       "      <th>a_act11</th>\n",
       "      <th>readmission_30d</th>\n",
       "      <th>postop_comp</th>\n",
       "      <th>los</th>\n",
       "      <th>DischargeDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>baseline_arm_1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2049-08-04</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-08-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2010-03-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2009-02-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2009-03-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-02-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2008-03-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18182</th>\n",
       "      <td>1770</td>\n",
       "      <td>NaT</td>\n",
       "      <td>preoperative_arm_1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18183</th>\n",
       "      <td>1770</td>\n",
       "      <td>NaT</td>\n",
       "      <td>preoperative_arm_1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18184</th>\n",
       "      <td>1770</td>\n",
       "      <td>NaT</td>\n",
       "      <td>preoperative_arm_1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2025-02-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18185</th>\n",
       "      <td>1770</td>\n",
       "      <td>NaT</td>\n",
       "      <td>baseline_arm_1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1982-10-12</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18186</th>\n",
       "      <td>1770</td>\n",
       "      <td>2025-03-14</td>\n",
       "      <td>surgery_arm_1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18187 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id operation_date   redcap_event_name ComplicationDate        dob  \\\n",
       "0         1            NaT      baseline_arm_1              NaT 2049-08-04   \n",
       "1         1     2011-08-26                 NaN              NaT        NaT   \n",
       "2         1     2010-02-20                 NaN              NaT        NaT   \n",
       "3         1     2009-02-25                 NaN              NaT        NaT   \n",
       "4         1     2008-02-22                 NaN              NaT        NaT   \n",
       "...     ...            ...                 ...              ...        ...   \n",
       "18182  1770            NaT  preoperative_arm_1              NaT        NaT   \n",
       "18183  1770            NaT  preoperative_arm_1              NaT        NaT   \n",
       "18184  1770            NaT  preoperative_arm_1              NaT        NaT   \n",
       "18185  1770            NaT      baseline_arm_1              NaT 1982-10-12   \n",
       "18186  1770     2025-03-14       surgery_arm_1              NaT        NaT   \n",
       "\n",
       "        qol_date  age_diagnosis  gender overall_primary_tumour  \\\n",
       "0            NaT            NaN     1.0                    NaN   \n",
       "1            NaT            NaN     NaN                    NaN   \n",
       "2            NaT            NaN     NaN                    NaN   \n",
       "3            NaT            NaN     NaN                    NaN   \n",
       "4            NaT            NaN     NaN                    NaN   \n",
       "...          ...            ...     ...                    ...   \n",
       "18182        NaT            NaN     NaN                    NaN   \n",
       "18183        NaT            NaN     NaN                    NaN   \n",
       "18184 2025-02-24            NaN     NaN                    NaN   \n",
       "18185        NaT            NaN     1.0                    NaN   \n",
       "18186        NaT            NaN     NaN                    NaN   \n",
       "\n",
       "      overall_regional_ln  ...  a_e5  a_e6  a_e7  a_c6  a_c2  a_act11  \\\n",
       "0                     NaN  ...   NaN   NaN   NaN   NaN   NaN      NaN   \n",
       "1                     NaN  ...   NaN   NaN   NaN   NaN   NaN      NaN   \n",
       "2                     NaN  ...   NaN   NaN   NaN   NaN   NaN      NaN   \n",
       "3                     NaN  ...   NaN   NaN   NaN   NaN   NaN      NaN   \n",
       "4                     NaN  ...   NaN   NaN   NaN   NaN   NaN      NaN   \n",
       "...                   ...  ...   ...   ...   ...   ...   ...      ...   \n",
       "18182                 NaN  ...   NaN   NaN   NaN   NaN   NaN      NaN   \n",
       "18183                 NaN  ...   NaN   NaN   NaN   NaN   NaN      NaN   \n",
       "18184                 NaN  ...   0.0   0.0   0.0   1.0   3.0      3.0   \n",
       "18185                 NaN  ...   NaN   NaN   NaN   NaN   NaN      NaN   \n",
       "18186                 NaN  ...   NaN   NaN   NaN   NaN   NaN      NaN   \n",
       "\n",
       "       readmission_30d  postop_comp   los DischargeDate  \n",
       "0                  NaN          0.0   NaN    2012-04-27  \n",
       "1                  NaN          NaN   NaN    2011-08-26  \n",
       "2                  NaN          NaN  16.0    2010-03-08  \n",
       "3                  NaN          NaN   8.0    2009-03-05  \n",
       "4                  NaN          NaN  13.0    2008-03-06  \n",
       "...                ...          ...   ...           ...  \n",
       "18182              NaN          NaN   NaN           NaT  \n",
       "18183              NaN          NaN   NaN           NaT  \n",
       "18184              NaN          NaN   NaN           NaT  \n",
       "18185              NaN          NaN   NaN           NaT  \n",
       "18186              NaN          NaN   NaN           NaT  \n",
       "\n",
       "[18187 rows x 70 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file - linked file \n",
    "file_path = \"../data/Merged_TSQIC_REDCap_ACCESS.xlsx\" \n",
    "df = pd.read_excel(file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              ge1         ge2         ge3         ge4  \\\n",
      "1_month_postop_arm_1    44.060150   43.909774   45.112782   44.360902   \n",
      "1_year_postop_arm_1      5.820106    5.820106    6.878307    5.291005   \n",
      "2_years_postop_arm_1     3.921569    3.921569    3.921569    3.921569   \n",
      "3_months_postop_arm_1    2.702703    4.729730    4.054054    3.378378   \n",
      "3_years_postop_arm_1     6.410256    8.974359    7.692308    6.410256   \n",
      "4_years_postop_arm_1     4.347826    6.521739    4.347826    4.347826   \n",
      "5_years_postop_arm_1    94.918567   94.983713   94.918567   94.918567   \n",
      "6_months_postop_arm_1    3.174603    3.703704    3.703704    4.232804   \n",
      "baseline_arm_1          47.491448   48.916762   50.969213   48.289624   \n",
      "preoperative_arm_1      74.343832   74.409449   74.540682   74.278215   \n",
      "surgery_arm_1          100.000000  100.000000  100.000000  100.000000   \n",
      "\n",
      "                              ge5         ge6  \n",
      "1_month_postop_arm_1    44.210526   44.060150  \n",
      "1_year_postop_arm_1      5.820106    5.291005  \n",
      "2_years_postop_arm_1     4.901961    3.921569  \n",
      "3_months_postop_arm_1    4.054054    2.702703  \n",
      "3_years_postop_arm_1     7.692308    6.410256  \n",
      "4_years_postop_arm_1     6.521739    4.347826  \n",
      "5_years_postop_arm_1    94.918567   94.918567  \n",
      "6_months_postop_arm_1    4.761905    3.703704  \n",
      "baseline_arm_1          48.346636   48.232611  \n",
      "preoperative_arm_1      74.343832   74.409449  \n",
      "surgery_arm_1          100.000000  100.000000  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, let's create a function to calculate missing value percentages\n",
    "def calculate_missing_percentages(df, columns, group_col):\n",
    "    # Group by both id and the specified column to handle multiple rows per (id, group_col)\n",
    "    grouped = df.groupby(['id', group_col])\n",
    "    \n",
    "    # Aggregate by taking the first non-null value for each (id, group_col) combination\n",
    "    aggregated_df = grouped[columns].apply(lambda x: x.bfill().ffill().iloc[0] if len(x) > 0 else pd.Series([None] * len(columns), index=columns))\n",
    "    aggregated_df = aggregated_df.reset_index()\n",
    "    \n",
    "    # Now group by the specified column only\n",
    "    grouped_by_event = aggregated_df.groupby(group_col)\n",
    "    \n",
    "    # Initialize a dictionary to store results\n",
    "    missing_percentages = {}\n",
    "    \n",
    "    # Calculate missing percentages for each group\n",
    "    for name, group in grouped_by_event:\n",
    "        # Calculate percentage of missing values for each column\n",
    "        missing_pct = group[columns].isna().mean() * 100\n",
    "        missing_percentages[name] = missing_pct\n",
    "    \n",
    "    # Convert to DataFrame for better visualization\n",
    "    result_df = pd.DataFrame(missing_percentages)\n",
    "    return result_df.T # Transpose for better readability\n",
    "\n",
    "# Columns of interest\n",
    "ge_columns = ['ge1', 'ge2', 'ge3', 'ge4', 'ge5', 'ge6']\n",
    "\n",
    "# Calculate missing percentages for each redcap_event_name\n",
    "missing_pct_by_event = calculate_missing_percentages(df, ge_columns, 'redcap_event_name')\n",
    "\n",
    "# Display the results\n",
    "print(missing_pct_by_event)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(missing_pct_by_event, annot=True, cmap='YlGnBu', fmt='.1f')\n",
    "plt.title('Missing Values Percentage by Event and Column')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>operation_date</th>\n",
       "      <th>redcap_event_name</th>\n",
       "      <th>ComplicationDate</th>\n",
       "      <th>dob</th>\n",
       "      <th>qol_date</th>\n",
       "      <th>age_diagnosis</th>\n",
       "      <th>gender</th>\n",
       "      <th>overall_primary_tumour</th>\n",
       "      <th>overall_regional_ln</th>\n",
       "      <th>...</th>\n",
       "      <th>a_e5</th>\n",
       "      <th>a_e6</th>\n",
       "      <th>a_e7</th>\n",
       "      <th>a_c6</th>\n",
       "      <th>a_c2</th>\n",
       "      <th>a_act11</th>\n",
       "      <th>readmission_30d</th>\n",
       "      <th>postop_comp</th>\n",
       "      <th>los</th>\n",
       "      <th>DischargeDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>baseline_arm_1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2049-08-04</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>baseline_arm_1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>NaT</td>\n",
       "      <td>baseline_arm_1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>NaT</td>\n",
       "      <td>baseline_arm_1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2041-02-25</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>NaT</td>\n",
       "      <td>baseline_arm_1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2007-01-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18178</th>\n",
       "      <td>1769</td>\n",
       "      <td>NaT</td>\n",
       "      <td>baseline_arm_1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18179</th>\n",
       "      <td>1769</td>\n",
       "      <td>NaT</td>\n",
       "      <td>baseline_arm_1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2025-03-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18180</th>\n",
       "      <td>1769</td>\n",
       "      <td>NaT</td>\n",
       "      <td>baseline_arm_1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18181</th>\n",
       "      <td>1770</td>\n",
       "      <td>NaT</td>\n",
       "      <td>baseline_arm_1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>42.054252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18185</th>\n",
       "      <td>1770</td>\n",
       "      <td>NaT</td>\n",
       "      <td>baseline_arm_1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1982-10-12</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5230 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id operation_date redcap_event_name ComplicationDate        dob  \\\n",
       "0         1            NaT    baseline_arm_1              NaT 2049-08-04   \n",
       "14        1            NaT    baseline_arm_1              NaT        NaT   \n",
       "18        2            NaT    baseline_arm_1              NaT        NaT   \n",
       "22        2            NaT    baseline_arm_1              NaT 2041-02-25   \n",
       "25        2            NaT    baseline_arm_1              NaT        NaT   \n",
       "...     ...            ...               ...              ...        ...   \n",
       "18178  1769            NaT    baseline_arm_1              NaT        NaT   \n",
       "18179  1769            NaT    baseline_arm_1              NaT        NaT   \n",
       "18180  1769            NaT    baseline_arm_1              NaT        NaT   \n",
       "18181  1770            NaT    baseline_arm_1              NaT        NaT   \n",
       "18185  1770            NaT    baseline_arm_1              NaT 1982-10-12   \n",
       "\n",
       "        qol_date  age_diagnosis  gender overall_primary_tumour  \\\n",
       "0            NaT            NaN     1.0                    NaN   \n",
       "14           NaT            NaN     NaN                      2   \n",
       "18           NaT            NaN     NaN                      3   \n",
       "22           NaT            NaN     1.0                    NaN   \n",
       "25    2007-01-12            NaN     NaN                    NaN   \n",
       "...          ...            ...     ...                    ...   \n",
       "18178        NaT            NaN     NaN                    NaN   \n",
       "18179 2025-03-10            NaN     NaN                    NaN   \n",
       "18180        NaT            NaN     NaN                      3   \n",
       "18181        NaT      42.054252     NaN                      3   \n",
       "18185        NaT            NaN     1.0                    NaN   \n",
       "\n",
       "      overall_regional_ln  ...  a_e5  a_e6  a_e7  a_c6  a_c2  a_act11  \\\n",
       "0                     NaN  ...   NaN   NaN   NaN   NaN   NaN      NaN   \n",
       "14                      0  ...   NaN   NaN   NaN   NaN   NaN      NaN   \n",
       "18                      1  ...   NaN   NaN   NaN   NaN   NaN      NaN   \n",
       "22                    NaN  ...   NaN   NaN   NaN   NaN   NaN      NaN   \n",
       "25                    NaN  ...   0.0   4.0   0.0   4.0   0.0      1.0   \n",
       "...                   ...  ...   ...   ...   ...   ...   ...      ...   \n",
       "18178                 NaN  ...   NaN   NaN   NaN   NaN   NaN      NaN   \n",
       "18179                 NaN  ...   0.0   0.0   0.0   0.0   1.0      1.0   \n",
       "18180                   1  ...   NaN   NaN   NaN   NaN   NaN      NaN   \n",
       "18181                   0  ...   NaN   NaN   NaN   NaN   NaN      NaN   \n",
       "18185                 NaN  ...   NaN   NaN   NaN   NaN   NaN      NaN   \n",
       "\n",
       "       readmission_30d  postop_comp  los DischargeDate  \n",
       "0                  NaN          0.0  NaN    2012-04-27  \n",
       "14                 NaN          NaN  NaN           NaT  \n",
       "18                 NaN          NaN  NaN           NaT  \n",
       "22                 NaN          NaN  NaN           NaT  \n",
       "25                 NaN          NaN  NaN           NaT  \n",
       "...                ...          ...  ...           ...  \n",
       "18178              NaN          NaN  NaN           NaT  \n",
       "18179              NaN          NaN  NaN           NaT  \n",
       "18180              NaN          NaN  NaN           NaT  \n",
       "18181              NaN          NaN  NaN           NaT  \n",
       "18185              NaN          NaN  NaN           NaT  \n",
       "\n",
       "[5230 rows x 70 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Leave only baseline\n",
    "df = df[df['redcap_event_name'] == 'baseline_arm_1']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'operation_date', 'redcap_event_name', 'ComplicationDate', 'dob',\n",
       "       'qol_date', 'age_diagnosis', 'gender', 'overall_primary_tumour',\n",
       "       'overall_regional_ln', 'overall_distant_metastasis', 'neotx___notx',\n",
       "       'neotx___chemo', 'neotx___rads', 'neotx___chemorads', 'neotx___immuno',\n",
       "       'neotx___other', 'procedure123456', 'expectation_treatment',\n",
       "       'path_esoph_primtumour', 'path_esoph_regionalln',\n",
       "       'path_esoph_distantmetast', 'gp1', 'gp2', 'gp3', 'gp4', 'gp5', 'gp6',\n",
       "       'gp7', 'gs1', 'gs2', 'gs3', 'gs4', 'gs5', 'gs6', 'gs7', 'ge1', 'ge2',\n",
       "       'ge3', 'ge4', 'ge5', 'ge6', 'gf1', 'gf2', 'gf3', 'gf4', 'gf5', 'gf6',\n",
       "       'gf7', 'a_hn1', 'a_hn2', 'a_hn3', 'a_hn4', 'a_hn5', 'a_hn7', 'a_hn10',\n",
       "       'a_e1', 'a_e2', 'a_e3', 'a_e4', 'a_e5', 'a_e6', 'a_e7', 'a_c6', 'a_c2',\n",
       "       'a_act11', 'readmission_30d', 'postop_comp', 'los', 'DischargeDate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'redcap_event_name', 'qol_date', 'age_diagnosis', 'gender',\n",
       "       'overall_primary_tumour', 'overall_regional_ln',\n",
       "       'overall_distant_metastasis', 'neotx___notx', 'neotx___chemo',\n",
       "       'neotx___rads', 'neotx___chemorads', 'neotx___immuno', 'neotx___other',\n",
       "       'procedure123456', 'expectation_treatment', 'path_esoph_primtumour',\n",
       "       'path_esoph_regionalln', 'path_esoph_distantmetast', 'gp1', 'gp2',\n",
       "       'gp3', 'gp4', 'gp5', 'gp6', 'gp7', 'gs1', 'gs2', 'gs3', 'gs4', 'gs5',\n",
       "       'gs6', 'gs7', 'ge1', 'ge2', 'ge3', 'ge4', 'ge5', 'ge6', 'gf1', 'gf2',\n",
       "       'gf3', 'gf4', 'gf5', 'gf6', 'gf7', 'a_hn1', 'a_hn2', 'a_hn3', 'a_hn4',\n",
       "       'a_hn5', 'a_hn7', 'a_hn10', 'a_e1', 'a_e2', 'a_e3', 'a_e4', 'a_e5',\n",
       "       'a_e6', 'a_e7', 'a_c6', 'a_c2', 'a_act11', 'readmission_30d',\n",
       "       'postop_comp', 'los'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop dates\n",
    "df = df.drop(columns=[\"ComplicationDate\", \"dob\", \"operation_date\", \"DischargeDate\"]) #qol_date\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>redcap_event_name</th>\n",
       "      <th>qol_date</th>\n",
       "      <th>age_diagnosis</th>\n",
       "      <th>gender</th>\n",
       "      <th>overall_primary_tumour</th>\n",
       "      <th>overall_regional_ln</th>\n",
       "      <th>overall_distant_metastasis</th>\n",
       "      <th>neotx___notx</th>\n",
       "      <th>neotx___chemo</th>\n",
       "      <th>...</th>\n",
       "      <th>a_e4</th>\n",
       "      <th>a_e5</th>\n",
       "      <th>a_e6</th>\n",
       "      <th>a_e7</th>\n",
       "      <th>a_c6</th>\n",
       "      <th>a_c2</th>\n",
       "      <th>a_act11</th>\n",
       "      <th>readmission_30d</th>\n",
       "      <th>postop_comp</th>\n",
       "      <th>los</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-01-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18178</th>\n",
       "      <td>1769</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18179</th>\n",
       "      <td>1769</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-03-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18180</th>\n",
       "      <td>1769</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18181</th>\n",
       "      <td>1770</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>42.054252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18185</th>\n",
       "      <td>1770</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5230 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id redcap_event_name   qol_date  age_diagnosis gender  \\\n",
       "0         1                 0        NaT            NaN    1.0   \n",
       "14        1                 0        NaT            NaN    NaN   \n",
       "18        2                 0        NaT            NaN    NaN   \n",
       "22        2                 0        NaT            NaN    1.0   \n",
       "25        2                 0 2007-01-12            NaN    NaN   \n",
       "...     ...               ...        ...            ...    ...   \n",
       "18178  1769                 0        NaT            NaN    NaN   \n",
       "18179  1769                 0 2025-03-10            NaN    NaN   \n",
       "18180  1769                 0        NaT            NaN    NaN   \n",
       "18181  1770                 0        NaT      42.054252    NaN   \n",
       "18185  1770                 0        NaT            NaN    1.0   \n",
       "\n",
       "      overall_primary_tumour overall_regional_ln  overall_distant_metastasis  \\\n",
       "0                        NaN                 NaN                         NaN   \n",
       "14                         2                   0                         NaN   \n",
       "18                         3                   1                         0.0   \n",
       "22                       NaN                 NaN                         NaN   \n",
       "25                       NaN                 NaN                         NaN   \n",
       "...                      ...                 ...                         ...   \n",
       "18178                    NaN                 NaN                         NaN   \n",
       "18179                    NaN                 NaN                         NaN   \n",
       "18180                      3                   1                         0.0   \n",
       "18181                      3                   0                         0.0   \n",
       "18185                    NaN                 NaN                         NaN   \n",
       "\n",
       "      neotx___notx neotx___chemo  ... a_e4 a_e5 a_e6 a_e7 a_c6 a_c2 a_act11  \\\n",
       "0              NaN           NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN     NaN   \n",
       "14             NaN           NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN     NaN   \n",
       "18             NaN           NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN     NaN   \n",
       "22             NaN           NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN     NaN   \n",
       "25             NaN           NaN  ...  3.0  0.0  4.0  0.0  4.0  0.0     1.0   \n",
       "...            ...           ...  ...  ...  ...  ...  ...  ...  ...     ...   \n",
       "18178          NaN           NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN     NaN   \n",
       "18179          NaN           NaN  ...  2.0  0.0  0.0  0.0  0.0  1.0     1.0   \n",
       "18180          NaN           NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN     NaN   \n",
       "18181          NaN           NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN     NaN   \n",
       "18185          NaN           NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN     NaN   \n",
       "\n",
       "      readmission_30d  postop_comp  los  \n",
       "0                 NaN          0.0  NaN  \n",
       "14                NaN          NaN  NaN  \n",
       "18                NaN          NaN  NaN  \n",
       "22                NaN          NaN  NaN  \n",
       "25                NaN          NaN  NaN  \n",
       "...               ...          ...  ...  \n",
       "18178             NaN          NaN  NaN  \n",
       "18179             NaN          NaN  NaN  \n",
       "18180             NaN          NaN  NaN  \n",
       "18181             NaN          NaN  NaN  \n",
       "18185             NaN          NaN  NaN  \n",
       "\n",
       "[5230 rows x 66 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Preprocess categorical variables\n",
    "# Low-cardinality variables: Convert to category dtype\n",
    "low_cardinality_cols = [\n",
    "    'postop_comp', 'readmission_30d', 'gender', 'neotx___notx', 'neotx___chemo',\n",
    "    'neotx___rads', 'neotx___chemorads', 'neotx___immuno', 'neotx___other',\n",
    "    'expectation_treatment'\n",
    "]\n",
    "for col in low_cardinality_cols:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "# High-cardinality variables: Label encode and convert to category\n",
    "le_redcap = LabelEncoder()\n",
    "df['redcap_event_name'] = df['redcap_event_name'].astype(str)  # Convert to string to handle NaN\n",
    "df['redcap_event_name'] = le_redcap.fit_transform(df['redcap_event_name'])\n",
    "df['redcap_event_name'] = df['redcap_event_name'].astype('category')\n",
    "\n",
    "# procedure123456 is already numerical but should be treated as categorical\n",
    "df['procedure123456'] = df['procedure123456'].astype('category')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>redcap_event_name</th>\n",
       "      <th>qol_date</th>\n",
       "      <th>age_diagnosis</th>\n",
       "      <th>gender</th>\n",
       "      <th>overall_primary_tumour</th>\n",
       "      <th>overall_regional_ln</th>\n",
       "      <th>overall_distant_metastasis</th>\n",
       "      <th>neotx___notx</th>\n",
       "      <th>neotx___chemo</th>\n",
       "      <th>...</th>\n",
       "      <th>a_e4</th>\n",
       "      <th>a_e5</th>\n",
       "      <th>a_e6</th>\n",
       "      <th>a_e7</th>\n",
       "      <th>a_c6</th>\n",
       "      <th>a_c2</th>\n",
       "      <th>a_act11</th>\n",
       "      <th>readmission_30d</th>\n",
       "      <th>postop_comp</th>\n",
       "      <th>los</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-01-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18178</th>\n",
       "      <td>1769</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18179</th>\n",
       "      <td>1769</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-03-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18180</th>\n",
       "      <td>1769</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18181</th>\n",
       "      <td>1770</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>42.054252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18185</th>\n",
       "      <td>1770</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5230 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id redcap_event_name   qol_date  age_diagnosis gender  \\\n",
       "0         1                 0        NaT            NaN    1.0   \n",
       "14        1                 0        NaT            NaN    NaN   \n",
       "18        2                 0        NaT            NaN    NaN   \n",
       "22        2                 0        NaT            NaN    1.0   \n",
       "25        2                 0 2007-01-12            NaN    NaN   \n",
       "...     ...               ...        ...            ...    ...   \n",
       "18178  1769                 0        NaT            NaN    NaN   \n",
       "18179  1769                 0 2025-03-10            NaN    NaN   \n",
       "18180  1769                 0        NaT            NaN    NaN   \n",
       "18181  1770                 0        NaT      42.054252    NaN   \n",
       "18185  1770                 0        NaT            NaN    1.0   \n",
       "\n",
       "      overall_primary_tumour overall_regional_ln overall_distant_metastasis  \\\n",
       "0                        nan                 nan                        nan   \n",
       "14                         2                   0                        nan   \n",
       "18                         3                   1                        0.0   \n",
       "22                       nan                 nan                        nan   \n",
       "25                       nan                 nan                        nan   \n",
       "...                      ...                 ...                        ...   \n",
       "18178                    nan                 nan                        nan   \n",
       "18179                    nan                 nan                        nan   \n",
       "18180                      3                   1                        0.0   \n",
       "18181                      3                   0                        0.0   \n",
       "18185                    nan                 nan                        nan   \n",
       "\n",
       "      neotx___notx neotx___chemo  ... a_e4 a_e5 a_e6 a_e7 a_c6 a_c2 a_act11  \\\n",
       "0              NaN           NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN     NaN   \n",
       "14             NaN           NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN     NaN   \n",
       "18             NaN           NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN     NaN   \n",
       "22             NaN           NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN     NaN   \n",
       "25             NaN           NaN  ...  3.0  0.0  4.0  0.0  4.0  0.0     1.0   \n",
       "...            ...           ...  ...  ...  ...  ...  ...  ...  ...     ...   \n",
       "18178          NaN           NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN     NaN   \n",
       "18179          NaN           NaN  ...  2.0  0.0  0.0  0.0  0.0  1.0     1.0   \n",
       "18180          NaN           NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN     NaN   \n",
       "18181          NaN           NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN     NaN   \n",
       "18185          NaN           NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN     NaN   \n",
       "\n",
       "      readmission_30d postop_comp  los  \n",
       "0                 NaN         0.0  NaN  \n",
       "14                NaN         NaN  NaN  \n",
       "18                NaN         NaN  NaN  \n",
       "22                NaN         NaN  NaN  \n",
       "25                NaN         NaN  NaN  \n",
       "...               ...         ...  ...  \n",
       "18178             NaN         NaN  NaN  \n",
       "18179             NaN         NaN  NaN  \n",
       "18180             NaN         NaN  NaN  \n",
       "18181             NaN         NaN  NaN  \n",
       "18185             NaN         NaN  NaN  \n",
       "\n",
       "[5230 rows x 66 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Preprocess numerical and ordinal columns\n",
    "# True numerical columns: Ensure float/int dtype\n",
    "numerical_cols = ['los', 'age_diagnosis']\n",
    "for col in numerical_cols:\n",
    "    df[col] = df[col].astype(float)\n",
    "\n",
    "#Step 3\n",
    "# Ordinal columns: Treat as numerical (already float)\n",
    "ordinal_cols = (\n",
    "    [f\"gp{i}\" for i in range(1, 8)] + [f\"gs{i}\" for i in range(1, 8)] +\n",
    "    [f\"ge{i}\" for i in range(1, 7)] + [f\"gf{i}\" for i in range(1, 8)] +\n",
    "    [f\"a_hn{i}\" for i in range(1, 6)] + [\"a_hn7\", \"a_hn10\"] +\n",
    "    [f\"a_e{i}\" for i in range(1, 8)] + [\"a_c6\", \"a_c2\", \"a_act11\"]\n",
    ")\n",
    "# Subset for this example\n",
    "ordinal_cols = [col for col in ordinal_cols if col in df.columns]\n",
    "for col in ordinal_cols:\n",
    "    df[col] = df[col].astype(float)\n",
    "\n",
    "#Step 4\n",
    "# Categorical-like columns: Treat as categorical\n",
    "categorical_like_cols = [\n",
    "    'overall_primary_tumour', 'overall_regional_ln', 'overall_distant_metastasis', \n",
    "    'path_esoph_primtumour', 'path_esoph_regionalln', 'path_esoph_distantmetast'\n",
    "]\n",
    "for col in categorical_like_cols:\n",
    "    df[col] = df[col].astype(str)  # Convert to string to handle mixed types\n",
    "    df[col] = df[col].astype('category')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'redcap_event_name' has only one unique value: 0\n",
      "Column 'path_esoph_primtumour' has only one unique value: nan\n",
      "Column 'path_esoph_regionalln' has only one unique value: nan\n",
      "Column 'path_esoph_distantmetast' has only one unique value: nan\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def analyze_categorical_columns(dataframe):\n",
    "    \"\"\"\n",
    "    Analyzes all categorical columns in a dataframe to check if they contain only one unique value.\n",
    "    \n",
    "    Args:\n",
    "        dataframe: pandas DataFrame to analyze\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with column names as keys and tuples (has_single_category, unique_value) as values\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Identify categorical columns\n",
    "    # This includes object dtype, category dtype, and any other non-numeric columns\n",
    "    categorical_columns = dataframe.select_dtypes(\n",
    "        include=['object', 'category', 'bool']\n",
    "    ).columns.tolist()\n",
    "    \n",
    "    # For each categorical column, check if it has only one unique value\n",
    "    for column in categorical_columns:\n",
    "        # Skip columns with all null values\n",
    "        if dataframe[column].isna().all():\n",
    "            results[column] = (False, None, \"All values are null\")\n",
    "            continue\n",
    "            \n",
    "        # Get unique non-null values\n",
    "        unique_values = dataframe[column].dropna().unique()\n",
    "        \n",
    "        # Check if there's only one unique category\n",
    "        has_single_category = len(unique_values) == 1\n",
    "        \n",
    "        if has_single_category:\n",
    "            results[column] = (True, unique_values[0], None)\n",
    "        else:\n",
    "            results[column] = (False, None, f\"Found {len(unique_values)} unique values\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "column_analysis = analyze_categorical_columns(df)\n",
    "\n",
    "# Print results\n",
    "for column, (has_single_value, unique_value, message) in column_analysis.items():\n",
    "    if has_single_value:\n",
    "        print(f\"Column '{column}' has only one unique value: {unique_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 4 columns with only one unique value:\n",
      "  - redcap_event_name\n",
      "  - path_esoph_primtumour\n",
      "  - path_esoph_regionalln\n",
      "  - path_esoph_distantmetast\n"
     ]
    }
   ],
   "source": [
    "def drop_single_value_categorical_columns(dataframe, inplace=False):\n",
    "    \"\"\"\n",
    "    Identifies and drops all categorical columns that contain only one unique value.\n",
    "    \n",
    "    Args:\n",
    "        dataframe: pandas DataFrame to process\n",
    "        inplace: Whether to modify the original dataframe (True) or return a copy (False)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Modified dataframe with single-value categorical columns removed\n",
    "        list: List of column names that were dropped\n",
    "    \"\"\"\n",
    "    # Make a copy if not inplace\n",
    "    df = dataframe if inplace else dataframe.copy()\n",
    "    \n",
    "    # Identify categorical columns\n",
    "    categorical_columns = df.select_dtypes(\n",
    "        include=['object', 'category', 'bool']\n",
    "    ).columns.tolist()\n",
    "    \n",
    "    # Track columns to drop\n",
    "    columns_to_drop = []\n",
    "    \n",
    "    # Check each categorical column\n",
    "    for column in categorical_columns:\n",
    "        # Skip columns with all null values\n",
    "        if df[column].isna().all():\n",
    "            continue\n",
    "            \n",
    "        # Get unique non-null values\n",
    "        unique_values = df[column].dropna().unique()\n",
    "        \n",
    "        # If only one unique value, add to drop list\n",
    "        if len(unique_values) == 1:\n",
    "            columns_to_drop.append(column)\n",
    "    \n",
    "    # Drop the identified columns\n",
    "    if columns_to_drop:\n",
    "        df.drop(columns=columns_to_drop, inplace=True)\n",
    "        \n",
    "    return df, columns_to_drop\n",
    "\n",
    "# Example usage:\n",
    "# Drop single-value categorical columns\n",
    "df_cleaned, dropped_columns = drop_single_value_categorical_columns(df, inplace=False)\n",
    "\n",
    "# Report results\n",
    "if dropped_columns:\n",
    "    print(f\"Dropped {len(dropped_columns)} columns with only one unique value:\")\n",
    "    for col in dropped_columns:\n",
    "        print(f\"  - {col}\")\n",
    "else:\n",
    "    print(\"No single-value categorical columns found.\")\n",
    "\n",
    "df = df_cleaned.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification process + metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add these imports at the top of your file\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def process_for_classification(values, min_val=0, max_val=4):\n",
    "    \"\"\"\n",
    "    Process imputed values for classification evaluation\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    values : array-like\n",
    "        Raw imputed values\n",
    "    min_val : int\n",
    "        Minimum allowed value (default: 0)\n",
    "    max_val : int  \n",
    "        Maximum allowed value (default: 4)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Processed values as integers in range [min_val, max_val]\n",
    "    \"\"\"\n",
    "    # Round to nearest integer\n",
    "    rounded = np.round(values)\n",
    "    # Clip to valid range\n",
    "    clipped = np.clip(rounded, min_val, max_val)\n",
    "    return clipped.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_classification_metrics(y_true, y_pred, classes=None):\n",
    "    \"\"\"\n",
    "    Calculate classification metrics for multi-class problem\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        True class labels\n",
    "    y_pred : array-like\n",
    "        Predicted class labels\n",
    "    classes : array-like, optional\n",
    "        Class labels (default: [0, 1, 2, 3, 4])\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing classification metrics\n",
    "    \"\"\"\n",
    "    if classes is None:\n",
    "        classes = np.array([0, 1, 2, 3, 4])\n",
    "    \n",
    "    try:\n",
    "        # Convert to numpy arrays\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        \n",
    "        # Basic accuracy\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        \n",
    "        # Macro-averaged metrics (average across classes)\n",
    "        precision_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        recall_macro = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        \n",
    "        # Weighted-averaged metrics (weighted by class frequency)\n",
    "        precision_weighted = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "        recall_weighted = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "        \n",
    "        # For multi-class AUC, we need to binarize the labels\n",
    "        try:\n",
    "            # Only calculate AUC if we have more than one class present\n",
    "            if len(np.unique(y_true)) > 1:\n",
    "                y_true_bin = label_binarize(y_true, classes=classes)\n",
    "                y_pred_bin = label_binarize(y_pred, classes=classes)\n",
    "                \n",
    "                # If only 2 classes present, reshape\n",
    "                if y_true_bin.shape[1] == 1:\n",
    "                    auc_score = roc_auc_score(y_true_bin, y_pred_bin)\n",
    "                else:\n",
    "                    # Multi-class AUC (macro average)\n",
    "                    auc_score = roc_auc_score(y_true_bin, y_pred_bin, average='macro', multi_class='ovr')\n",
    "            else:\n",
    "                auc_score = np.nan\n",
    "        except:\n",
    "            auc_score = np.nan\n",
    "        \n",
    "        # Per-class metrics\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "        \n",
    "        # Calculate sensitivity (recall) and specificity for each class\n",
    "        per_class_metrics = {}\n",
    "        for i, class_label in enumerate(classes):\n",
    "            if i < cm.shape[0] and i < cm.shape[1]:\n",
    "                tp = cm[i, i] if i < cm.shape[0] and i < cm.shape[1] else 0\n",
    "                fp = cm[:, i].sum() - tp if i < cm.shape[1] else 0\n",
    "                fn = cm[i, :].sum() - tp if i < cm.shape[0] else 0\n",
    "                tn = cm.sum() - tp - fp - fn\n",
    "                \n",
    "                # Sensitivity (recall/true positive rate)\n",
    "                sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "                \n",
    "                # Specificity (true negative rate)\n",
    "                specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "                \n",
    "                # PPV (precision)\n",
    "                ppv = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "                \n",
    "                # NPV\n",
    "                npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "                \n",
    "                per_class_metrics[f'class_{class_label}'] = {\n",
    "                    'sensitivity': sensitivity,\n",
    "                    'specificity': specificity,\n",
    "                    'ppv': ppv,\n",
    "                    'npv': npv\n",
    "                }\n",
    "        \n",
    "        # Average across classes for summary\n",
    "        avg_sensitivity = np.mean([metrics['sensitivity'] for metrics in per_class_metrics.values()])\n",
    "        avg_specificity = np.mean([metrics['specificity'] for metrics in per_class_metrics.values()])\n",
    "        avg_ppv = np.mean([metrics['ppv'] for metrics in per_class_metrics.values()])\n",
    "        avg_npv = np.mean([metrics['npv'] for metrics in per_class_metrics.values()])\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'auc_multiclass': auc_score,\n",
    "            'precision_macro': precision_macro,\n",
    "            'recall_macro': recall_macro,\n",
    "            'precision_weighted': precision_weighted,\n",
    "            'recall_weighted': recall_weighted,\n",
    "            'avg_sensitivity': avg_sensitivity,\n",
    "            'avg_specificity': avg_specificity,\n",
    "            'avg_ppv': avg_ppv,\n",
    "            'avg_npv': avg_npv,\n",
    "            'per_class_metrics': per_class_metrics,\n",
    "            'confusion_matrix': cm\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating classification metrics: {e}\")\n",
    "        return {\n",
    "            'accuracy': np.nan,\n",
    "            'auc_multiclass': np.nan,\n",
    "            'precision_macro': np.nan,\n",
    "            'recall_macro': np.nan,\n",
    "            'precision_weighted': np.nan,\n",
    "            'recall_weighted': np.nan,\n",
    "            'avg_sensitivity': np.nan,\n",
    "            'avg_specificity': np.nan,\n",
    "            'avg_ppv': np.nan,\n",
    "            'avg_npv': np.nan,\n",
    "            'per_class_metrics': {},\n",
    "            'confusion_matrix': None\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model - MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mice_imputation(df, columns_to_impute, validation_df=None, validation_masks=None, original_values=None):\n",
    "    \"\"\"\n",
    "    Apply MICE imputation using miceforest package\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Data with missing values\n",
    "    columns_to_impute : list\n",
    "        List of column names to impute\n",
    "    validation_df : pandas.DataFrame, optional\n",
    "        Validation dataset with artificially missing values\n",
    "    validation_masks : dict, optional\n",
    "        Dictionary of masks for validation data\n",
    "    original_values : dict, optional\n",
    "        Dictionary of original values for validation\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    imputed_df : pandas.DataFrame\n",
    "        Data with imputed values\n",
    "    validation_results : dict, optional\n",
    "        Validation results if validation data provided\n",
    "    \"\"\"\n",
    "\n",
    "    # Set threads for LightGBM\n",
    "    os.environ['OMP_NUM_THREADS'] = '10'\n",
    "    \n",
    "    # Initialize the imputation kernel\n",
    "    kernel = mf.ImputationKernel(\n",
    "        df,\n",
    "        datasets=1,\n",
    "        variable_schema={\n",
    "            col: [c for c in df.columns if c != col] for col in columns_to_impute\n",
    "        },\n",
    "        random_state=42  # Using fixed seed for reproducibility, can be parameterized\n",
    "    )\n",
    "    \n",
    "    # Run imputation\n",
    "    for _ in tqdm(range(5), desc=\"MICE Imputation\"):\n",
    "        kernel.mice(\n",
    "            iterations=1,\n",
    "            verbose=False,\n",
    "            num_boost_round=80,\n",
    "            max_depth=10,\n",
    "            num_threads=10\n",
    "        )\n",
    "    \n",
    "    # Get imputed data\n",
    "    imputed_df = kernel.complete_data(0)\n",
    "    \n",
    "    # Check if there's a label encoder for redcap_event_name that needs inverse transformation\n",
    "    if 'redcap_event_name' in imputed_df.columns:\n",
    "        try:\n",
    "            # This is optional - only execute if le_redcap exists in the global scope\n",
    "            if 'le_redcap' in globals():\n",
    "                # Check if we're dealing with numeric values (could be int or float)\n",
    "                if pd.api.types.is_numeric_dtype(imputed_df['redcap_event_name']) or \\\n",
    "                   (hasattr(imputed_df['redcap_event_name'], 'cat') and pd.api.types.is_numeric_dtype(imputed_df['redcap_event_name'].cat.categories)):\n",
    "                    imputed_df['redcap_event_name'] = globals()['le_redcap'].inverse_transform(imputed_df['redcap_event_name'].astype(int))\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not inverse transform redcap_event_name: {e}\")\n",
    "    \n",
    "    # Validate if validation data provided\n",
    "    validation_results = None\n",
    "    if validation_df is not None and validation_masks is not None and original_values is not None:\n",
    "        validation_results = {}\n",
    "        \n",
    "        # Compare imputed values to real values\n",
    "        for col in columns_to_impute:\n",
    "            # Get indices where values were artificially set to NaN\n",
    "            mask = validation_masks[col] & validation_df[col].isna()\n",
    "            \n",
    "            if mask.sum() == 0:\n",
    "                validation_results[col] = {\n",
    "                    'error': \"No artificially missing values\"\n",
    "                }\n",
    "                continue\n",
    "                \n",
    "            real_vals = original_values[col][mask]\n",
    "            imputed_vals = imputed_df[col][mask]\n",
    "            \n",
    "            # Calculate continuous metrics (MAE and RMSE) - NO ROUNDING\n",
    "            mae = mean_absolute_error(real_vals, imputed_vals)\n",
    "            rmse = np.sqrt(mean_squared_error(real_vals, imputed_vals))\n",
    "            \n",
    "            # Calculate classification metrics - WITH ROUNDING\n",
    "            real_vals_class = process_for_classification(real_vals)\n",
    "            imputed_vals_class = process_for_classification(imputed_vals)\n",
    "            \n",
    "            classification_metrics = calculate_classification_metrics(real_vals_class, imputed_vals_class)\n",
    "            \n",
    "            validation_results[col] = {\n",
    "                'mae': mae,\n",
    "                'rmse': rmse,\n",
    "                'accuracy': classification_metrics['accuracy'],\n",
    "                'auc_multiclass': classification_metrics['auc_multiclass'],\n",
    "                'avg_sensitivity': classification_metrics['avg_sensitivity'],\n",
    "                'avg_specificity': classification_metrics['avg_specificity'],\n",
    "                'avg_ppv': classification_metrics['avg_ppv'],\n",
    "                'avg_npv': classification_metrics['avg_npv'],\n",
    "                'precision_macro': classification_metrics['precision_macro'],\n",
    "                'recall_macro': classification_metrics['recall_macro'],\n",
    "                'real_distribution': real_vals.describe(),\n",
    "                'imputed_distribution': imputed_vals.describe()\n",
    "            }\n",
    "    \n",
    "    return imputed_df, validation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m ordinal_cols \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      2\u001b[0m     [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgp\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m8\u001b[39m)] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgs\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m8\u001b[39m)] \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m      3\u001b[0m     [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mge\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m7\u001b[39m)] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgf\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m8\u001b[39m)] \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m      4\u001b[0m     [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma_hn\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m6\u001b[39m)] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma_hn7\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma_hn10\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m      5\u001b[0m     [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma_e\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m8\u001b[39m)] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma_c6\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma_c2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma_act11\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m columns_to_impute \u001b[38;5;241m=\u001b[39m ordinal_cols\u001b[38;5;66;03m#['ge1', 'ge2', 'ge3', 'ge4', 'ge5', 'ge6']\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m imputed_df_mice, validation_results_mice \u001b[38;5;241m=\u001b[39m \u001b[43mapply_mice_imputation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns_to_impute\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 30\u001b[0m, in \u001b[0;36mapply_mice_imputation\u001b[0;34m(df, columns_to_impute, validation_df, validation_masks, original_values)\u001b[0m\n\u001b[1;32m     27\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOMP_NUM_THREADS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m10\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Initialize the imputation kernel\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m kernel \u001b[38;5;241m=\u001b[39m \u001b[43mmf\u001b[49m\u001b[38;5;241m.\u001b[39mImputationKernel(\n\u001b[1;32m     31\u001b[0m     df,\n\u001b[1;32m     32\u001b[0m     datasets\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     33\u001b[0m     variable_schema\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     34\u001b[0m         col: [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;241m!=\u001b[39m col] \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns_to_impute\n\u001b[1;32m     35\u001b[0m     },\n\u001b[1;32m     36\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m  \u001b[38;5;66;03m# Using fixed seed for reproducibility, can be parameterized\u001b[39;00m\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Run imputation\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMICE Imputation\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mf' is not defined"
     ]
    }
   ],
   "source": [
    "ordinal_cols = (\n",
    "    [f\"gp{i}\" for i in range(1, 8)] + [f\"gs{i}\" for i in range(1, 8)] +\n",
    "    [f\"ge{i}\" for i in range(1, 7)] + [f\"gf{i}\" for i in range(1, 8)] +\n",
    "    [f\"a_hn{i}\" for i in range(1, 6)] + [\"a_hn7\", \"a_hn10\"] +\n",
    "    [f\"a_e{i}\" for i in range(1, 8)] + [\"a_c6\", \"a_c2\", \"a_act11\"]\n",
    ")\n",
    "columns_to_impute = ordinal_cols#['ge1', 'ge2', 'ge3', 'ge4', 'ge5', 'ge6']\n",
    "imputed_df_mice, validation_results_mice = apply_mice_imputation(df, columns_to_impute)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model - VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Variational VAE optimized for CPU usage\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dims=(64, 32, 16), latent_dim=8, dropout_rate=0.1):\n",
    "        \"\"\"\n",
    "        Initialize VAE model\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_dim : int\n",
    "            Dimension of input feature space\n",
    "        hidden_dims : tuple\n",
    "            Sizes of hidden layers in the encoder and decoder\n",
    "        latent_dim : int\n",
    "            Dimension of the latent space\n",
    "        dropout_rate : float\n",
    "            Dropout rate for regularization\n",
    "        \"\"\"\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # Determine if we should use batch normalization (can be slow on CPU)\n",
    "        self.use_cpu_efficient = True  # Flag for CPU optimization\n",
    "        \n",
    "        # Encoder layers\n",
    "        encoder_layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for h_dim in hidden_dims:\n",
    "            layer_components = [nn.Linear(prev_dim, h_dim)]\n",
    "            \n",
    "            # Use layer norm instead of batch norm if optimizing for CPU\n",
    "            if self.use_cpu_efficient:\n",
    "                layer_components.append(nn.LayerNorm(h_dim))\n",
    "            else:\n",
    "                layer_components.append(nn.BatchNorm1d(h_dim))\n",
    "                \n",
    "            layer_components.extend([\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            \n",
    "            encoder_layers.append(nn.Sequential(*layer_components))\n",
    "            prev_dim = h_dim\n",
    "        \n",
    "        self.encoder_layers = nn.ModuleList(encoder_layers)\n",
    "        \n",
    "        # Latent space mapping\n",
    "        self.mu_layer = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "        self.logvar_layer = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "        \n",
    "        # Decoder layers\n",
    "        decoder_layers = []\n",
    "        decoder_dims = list(reversed(hidden_dims))\n",
    "        \n",
    "        # First decoder layer from latent space\n",
    "        first_layer_components = [nn.Linear(latent_dim, decoder_dims[0])]\n",
    "        \n",
    "        # Use layer norm instead of batch norm if optimizing for CPU\n",
    "        if self.use_cpu_efficient:\n",
    "            first_layer_components.append(nn.LayerNorm(decoder_dims[0]))\n",
    "        else:\n",
    "            first_layer_components.append(nn.BatchNorm1d(decoder_dims[0]))\n",
    "            \n",
    "        first_layer_components.extend([\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        ])\n",
    "        \n",
    "        decoder_layers.append(nn.Sequential(*first_layer_components))\n",
    "        \n",
    "        # Remaining decoder layers\n",
    "        for i in range(len(decoder_dims) - 1):\n",
    "            layer_components = [nn.Linear(decoder_dims[i], decoder_dims[i+1])]\n",
    "            \n",
    "            # Use layer norm instead of batch norm if optimizing for CPU\n",
    "            if self.use_cpu_efficient:\n",
    "                layer_components.append(nn.LayerNorm(decoder_dims[i+1]))\n",
    "            else:\n",
    "                layer_components.append(nn.BatchNorm1d(decoder_dims[i+1]))\n",
    "                \n",
    "            layer_components.extend([\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            \n",
    "            decoder_layers.append(nn.Sequential(*layer_components))\n",
    "        \n",
    "        # Output layer\n",
    "        decoder_layers.append(nn.Linear(decoder_dims[-1], input_dim))\n",
    "        \n",
    "        self.decoder_layers = nn.ModuleList(decoder_layers)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        Encode input to latent parameters\n",
    "        \"\"\"\n",
    "        h = x\n",
    "        for layer in self.encoder_layers:\n",
    "            h = layer(h)\n",
    "            \n",
    "        mu = self.mu_layer(h)\n",
    "        logvar = self.logvar_layer(h)\n",
    "        \n",
    "        return mu, logvar\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        Reparameterization trick\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        return z\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        Decode latent vector to reconstructed input\n",
    "        \"\"\"\n",
    "        h = z\n",
    "        for layer in self.decoder_layers:\n",
    "            h = layer(h)\n",
    "            \n",
    "        return h\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the VAE\n",
    "        \"\"\"\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_reconstructed = self.decode(z)\n",
    "        \n",
    "        return x_reconstructed, mu, logvar\n",
    "    \n",
    "    \n",
    "class MaskedMSELoss(nn.Module):\n",
    "    \"\"\"\n",
    "    MSE loss that only considers non-missing values\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(MaskedMSELoss, self).__init__()\n",
    "        \n",
    "    def forward(self, pred, target, mask):\n",
    "        \"\"\"\n",
    "        Calculate MSE loss ignoring missing values\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        pred : torch.Tensor\n",
    "            Predicted values\n",
    "        target : torch.Tensor\n",
    "            Target values\n",
    "        mask : torch.Tensor\n",
    "            Binary mask (1 for observed, 0 for missing)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        loss : torch.Tensor\n",
    "            Masked MSE loss\n",
    "        \"\"\"\n",
    "        # Only calculate loss for observed values\n",
    "        masked_pred = pred * mask\n",
    "        masked_target = target * mask\n",
    "        \n",
    "        # Calculate squared error\n",
    "        se = (masked_pred - masked_target) ** 2\n",
    "        \n",
    "        # Sum squared error and count observed values\n",
    "        sse = torch.sum(se)\n",
    "        count = torch.sum(mask)\n",
    "        \n",
    "        # Return MSE\n",
    "        return sse / (count + 1e-8)\n",
    "\n",
    "\n",
    "def kl_divergence_loss(mu, logvar):\n",
    "    \"\"\"\n",
    "    Calculate KL divergence loss\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    mu : torch.Tensor\n",
    "        Mean of the latent space\n",
    "    logvar : torch.Tensor\n",
    "        Log variance of the latent space\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    kl_loss : torch.Tensor\n",
    "        KL divergence loss\n",
    "    \"\"\"\n",
    "    # KL divergence between q(z|x) and p(z)\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return kl_loss\n",
    "\n",
    "\n",
    "class VAEImputer:\n",
    "    \"\"\"\n",
    "    Variational VAE Imputation model using PyTorch\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 hidden_dims=(64, 32, 16),\n",
    "                 latent_dim=8,\n",
    "                 batch_size=64,\n",
    "                 learning_rate=0.001,\n",
    "                 epochs=100,\n",
    "                 beta=1.0,\n",
    "                 device=None,\n",
    "                 verbose=True):\n",
    "        \"\"\"\n",
    "        Initialize VAE imputer\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        hidden_dims : tuple\n",
    "            Sizes of hidden layers in the encoder and decoder\n",
    "        latent_dim : int\n",
    "            Dimension of the latent space\n",
    "        batch_size : int\n",
    "            Batch size for training\n",
    "        learning_rate : float\n",
    "            Learning rate for optimizer\n",
    "        epochs : int\n",
    "            Number of training epochs\n",
    "        beta : float\n",
    "            Weight of the KL divergence loss (beta-VAE)\n",
    "        device : torch.device\n",
    "            Device to use for training (CPU or GPU)\n",
    "        verbose : bool\n",
    "            Whether to print progress\n",
    "        \"\"\"\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.latent_dim = latent_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.beta = beta\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Set device - Compute Canada specific approach\n",
    "        if device is None:\n",
    "            # Check for SLURM environment variables that indicate we're on a cluster\n",
    "            slurm_job_id = os.environ.get('SLURM_JOB_ID')\n",
    "            \n",
    "            if slurm_job_id:\n",
    "                print(f\"Running on Compute Canada cluster (Job ID: {slurm_job_id})\")\n",
    "                \n",
    "                # Check if GPUs were allocated\n",
    "                slurm_gpus = os.environ.get('SLURM_GPUS')\n",
    "                if slurm_gpus:\n",
    "                    print(f\"GPUs allocated: {slurm_gpus}\")\n",
    "                    \n",
    "                # On Compute Canada, we need to look at the environment variables\n",
    "                visible_devices = os.environ.get('CUDA_VISIBLE_DEVICES')\n",
    "                print(f\"CUDA_VISIBLE_DEVICES: {visible_devices}\")\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    self.device = torch.device('cuda')\n",
    "                    n_gpus = torch.cuda.device_count()\n",
    "                    print(f\"PyTorch sees {n_gpus} GPUs\")\n",
    "                    if n_gpus > 0:\n",
    "                        print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "                        # Show GPU memory\n",
    "                        print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "                    else:\n",
    "                        print(\"Warning: torch.cuda.is_available() is True but device_count() is 0\")\n",
    "                        self.device = torch.device('cpu')\n",
    "                else:\n",
    "                    print(\"CUDA not available according to PyTorch\")\n",
    "                    # Try to provide more diagnostics\n",
    "                    try:\n",
    "                        if os.path.exists('/usr/bin/nvidia-smi'):\n",
    "                            import subprocess\n",
    "                            result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE)\n",
    "                            print(\"nvidia-smi output:\")\n",
    "                            print(result.stdout.decode('utf-8'))\n",
    "                        else:\n",
    "                            print(\"nvidia-smi not found in /usr/bin\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error checking for nvidia-smi: {e}\")\n",
    "                    \n",
    "                    self.device = torch.device('cpu')\n",
    "            else:\n",
    "                # Not on a cluster, use standard detection\n",
    "                if torch.cuda.is_available():\n",
    "                    self.device = torch.device('cuda')\n",
    "                    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "                else:\n",
    "                    self.device = torch.device('cpu')\n",
    "                    print(\"Using CPU\")\n",
    "        else:\n",
    "            self.device = device\n",
    "            \n",
    "        # Initialize model, scalers and masks\n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "        self.columns = None\n",
    "        \n",
    "    def fit(self, X, columns_to_impute=None):\n",
    "        \"\"\"\n",
    "        Fit VAE model for imputation\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pandas.DataFrame\n",
    "            Data with missing values\n",
    "        columns_to_impute : list, optional\n",
    "            List of column names to impute. If None, all columns with missing values.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        self : object\n",
    "            Returns self\n",
    "        \"\"\"\n",
    "        # Identify columns to impute if not specified\n",
    "        if columns_to_impute is None:\n",
    "            columns_to_impute = [col for col in X.columns if X[col].isna().any()]\n",
    "        \n",
    "        # Store list of columns to impute and all columns\n",
    "        self.columns_to_impute = columns_to_impute\n",
    "        self.columns = list(X.columns)\n",
    "        \n",
    "        # Create missing value mask (1 for observed, 0 for missing)\n",
    "        missing_mask = ~X.isna()\n",
    "        \n",
    "        # Initialize scaler\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        # Simple imputer for initial values (will be refined by VAE)\n",
    "        simple_imputer = SimpleImputer(strategy='mean')\n",
    "        X_simple_imputed = pd.DataFrame(\n",
    "            simple_imputer.fit_transform(X),\n",
    "            columns=X.columns,\n",
    "            index=X.index\n",
    "        )\n",
    "        \n",
    "        # Scale data\n",
    "        X_scaled = self.scaler.fit_transform(X_simple_imputed)\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        X_tensor = torch.FloatTensor(X_scaled)\n",
    "        mask_tensor = torch.FloatTensor(missing_mask.values)\n",
    "        \n",
    "        # Create dataset and dataloader\n",
    "        dataset = TensorDataset(X_tensor, mask_tensor)\n",
    "        # Use multiple workers if on CPU for better performance\n",
    "        num_workers = 0\n",
    "        if self.device.type == 'cpu':\n",
    "            import multiprocessing\n",
    "            num_workers = min(2, multiprocessing.cpu_count() // 2)  # Use at most half the cores\n",
    "        \n",
    "        dataloader = DataLoader(\n",
    "            dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=(self.device.type == 'cuda')  # Only pin memory if using CUDA\n",
    "        )\n",
    "        \n",
    "        # Initialize model\n",
    "        input_dim = X.shape[1]\n",
    "        self.model = VAE(\n",
    "            input_dim=input_dim,\n",
    "            hidden_dims=self.hidden_dims,\n",
    "            latent_dim=self.latent_dim\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Initialize optimizer\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        \n",
    "        # Initialize loss function\n",
    "        recon_loss_fn = MaskedMSELoss()\n",
    "        \n",
    "        # Training loop\n",
    "        self.model.train()\n",
    "        \n",
    "        # Create progress bar if verbose\n",
    "        pbar = range(self.epochs)\n",
    "        if self.verbose:\n",
    "            pbar = tqdm(pbar, desc=\"Training VAE\")\n",
    "            \n",
    "        for epoch in pbar:\n",
    "            epoch_loss = 0.0\n",
    "            epoch_recon_loss = 0.0\n",
    "            epoch_kl_loss = 0.0\n",
    "            \n",
    "            for x, mask in dataloader:\n",
    "                # Move tensors to device\n",
    "                x = x.to(self.device)\n",
    "                mask = mask.to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                x_reconstructed, mu, logvar = self.model(x)\n",
    "                \n",
    "                # Calculate losses\n",
    "                recon_loss = recon_loss_fn(x_reconstructed, x, mask)\n",
    "                kl_loss = kl_divergence_loss(mu, logvar) / x.size(0)  # Normalize by batch size\n",
    "                \n",
    "                # Total loss (beta-VAE formulation)\n",
    "                loss = recon_loss + self.beta * kl_loss\n",
    "                \n",
    "                # Backward pass and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Accumulate losses\n",
    "                epoch_loss += loss.item()\n",
    "                epoch_recon_loss += recon_loss.item()\n",
    "                epoch_kl_loss += kl_loss.item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            if self.verbose:\n",
    "                pbar.set_postfix({\n",
    "                    \"loss\": epoch_loss / len(dataloader),\n",
    "                    \"recon\": epoch_recon_loss / len(dataloader),\n",
    "                    \"kl\": epoch_kl_loss / len(dataloader)\n",
    "                })\n",
    "                \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Impute missing values using trained VAE model\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pandas.DataFrame\n",
    "            Data with missing values\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        imputed_df : pandas.DataFrame\n",
    "            Data with imputed values\n",
    "        \"\"\"\n",
    "        # Create copy to avoid modifying original\n",
    "        imputed_df = X.copy()\n",
    "        \n",
    "        # Get missing value mask\n",
    "        missing_mask = X.isna()\n",
    "        \n",
    "        # Use simple imputation for initial values\n",
    "        simple_imputer = SimpleImputer(strategy='mean')\n",
    "        X_simple_imputed = pd.DataFrame(\n",
    "            simple_imputer.fit_transform(X),\n",
    "            columns=X.columns,\n",
    "            index=X.index\n",
    "        )\n",
    "        \n",
    "        # Scale data\n",
    "        X_scaled = self.scaler.transform(X_simple_imputed)\n",
    "        \n",
    "        # Convert to PyTorch tensor\n",
    "        X_tensor = torch.FloatTensor(X_scaled).to(self.device)\n",
    "        \n",
    "        # Set model to evaluation mode\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Disable gradient calculation\n",
    "        with torch.no_grad():\n",
    "            # Forward pass through VAE\n",
    "            X_reconstructed, _, _ = self.model(X_tensor)\n",
    "            \n",
    "            # Convert reconstructed values to numpy\n",
    "            X_reconstructed_np = X_reconstructed.cpu().numpy()\n",
    "            \n",
    "            # Inverse transform to original scale\n",
    "            X_reconstructed_orig = self.scaler.inverse_transform(X_reconstructed_np)\n",
    "            \n",
    "            # Create DataFrame with reconstructed values\n",
    "            X_reconstructed_df = pd.DataFrame(\n",
    "                X_reconstructed_orig,\n",
    "                columns=X.columns,\n",
    "                index=X.index\n",
    "            )\n",
    "            \n",
    "            # Replace missing values with imputed values for specified columns\n",
    "            for col in self.columns_to_impute:\n",
    "                # Only replace missing values\n",
    "                imputed_df.loc[missing_mask[col], col] = X_reconstructed_df.loc[missing_mask[col], col]\n",
    "        \n",
    "        return imputed_df\n",
    "    \n",
    "    def fit_transform(self, X, columns_to_impute=None):\n",
    "        \"\"\"\n",
    "        Fit model and impute missing values\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pandas.DataFrame\n",
    "            Data with missing values\n",
    "        columns_to_impute : list, optional\n",
    "            List of column names to impute. If None, all columns with missing values.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        imputed_df : pandas.DataFrame\n",
    "            Data with imputed values\n",
    "        \"\"\"\n",
    "        self.fit(X, columns_to_impute)\n",
    "        return self.transform(X)\n",
    "\n",
    "\n",
    "def apply_vae_imputation(df, columns_to_impute, validation_df=None, validation_masks=None, original_values=None,\n",
    "                        hidden_dims=(64, 32, 16), latent_dim=8, batch_size=64, epochs=100, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Apply VAE imputation to data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Data with missing values\n",
    "    columns_to_impute : list\n",
    "        List of column names to impute\n",
    "    validation_df : pandas.DataFrame, optional\n",
    "        Validation dataset with artificially missing values\n",
    "    validation_masks : dict, optional\n",
    "        Dictionary of masks for validation data\n",
    "    original_values : dict, optional\n",
    "        Dictionary of original values for validation\n",
    "    hidden_dims : tuple\n",
    "        Sizes of hidden layers\n",
    "    latent_dim : int\n",
    "        Dimension of the latent space\n",
    "    batch_size : int\n",
    "        Batch size for training\n",
    "    epochs : int\n",
    "        Number of training epochs\n",
    "    learning_rate : float\n",
    "        Learning rate for optimizer\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    imputed_df : pandas.DataFrame\n",
    "        Data with imputed values\n",
    "    validation_results : dict, optional\n",
    "        Validation results if validation data provided\n",
    "    \"\"\"\n",
    "    # Extract relevant columns including potential predictors\n",
    "    # Use all columns except those with excessive missing values\n",
    "    threshold = 0.5  # Columns with more than 50% missing values are excluded\n",
    "    columns_to_use = [col for col in df.columns \n",
    "                        if df[col].isna().mean() < threshold]\n",
    "    \n",
    "    # Ensure all columns_to_impute are included\n",
    "    for col in columns_to_impute:\n",
    "        if col not in columns_to_use:\n",
    "            columns_to_use.append(col)\n",
    "    \n",
    "    # Extract subset of data\n",
    "    X = df[columns_to_use].copy()\n",
    "    \n",
    "    # Ensure all columns are numeric\n",
    "    for col in X.columns:\n",
    "        X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "    \n",
    "    # Compute Canada specific detection\n",
    "    print(\"\\n--- Compute Canada / Cluster Environment Detection ---\")\n",
    "    slurm_info = {\n",
    "        'SLURM_JOB_ID': os.environ.get('SLURM_JOB_ID', 'Not found'),\n",
    "        'SLURM_JOB_GPUS': os.environ.get('SLURM_JOB_GPUS', 'Not found'),\n",
    "        'SLURM_GPUS': os.environ.get('SLURM_GPUS', 'Not found'), \n",
    "        'CUDA_VISIBLE_DEVICES': os.environ.get('CUDA_VISIBLE_DEVICES', 'Not found'),\n",
    "        'SLURM_JOB_PARTITION': os.environ.get('SLURM_JOB_PARTITION', 'Not found'),\n",
    "    }\n",
    "    \n",
    "    for key, value in slurm_info.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    # Check CUDA availability with Compute Canada settings\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        n_gpus = torch.cuda.device_count()\n",
    "        print(f\"\\nPyTorch detects {n_gpus} GPUs\")\n",
    "        \n",
    "        # On Compute Canada clusters, sometimes device_count is incorrect\n",
    "        # but we can still use cuda:0 if CUDA_VISIBLE_DEVICES is set\n",
    "        if n_gpus == 0 and os.environ.get('CUDA_VISIBLE_DEVICES') is not None:\n",
    "            print(\"Detected potential Compute Canada environment mismatch\")\n",
    "            print(\"Attempting to force GPU usage...\")\n",
    "            try:\n",
    "                # Try to explicitly set the device\n",
    "                device = torch.device('cuda:0')\n",
    "                # Test if it works\n",
    "                test_tensor = torch.zeros(1).to(device)\n",
    "                print(\"Successfully forced GPU usage!\")\n",
    "            except Exception as e:\n",
    "                print(f\"Force attempt failed: {e}\")\n",
    "                device = torch.device('cpu')\n",
    "                print(\"Falling back to CPU\")\n",
    "        else:\n",
    "            for i in range(n_gpus):\n",
    "                print(f\"GPU #{i}: {torch.cuda.get_device_name(i)}\")\n",
    "                props = torch.cuda.get_device_properties(i)\n",
    "                print(f\"  Memory: {props.total_memory / 1e9:.2f} GB\")\n",
    "                print(f\"  Compute Capability: {props.major}.{props.minor}\")\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        print(\"\\nCUDA not available, using CPU\")\n",
    "        \n",
    "        # Check if we're on a compute node that should have GPUs\n",
    "        if 'SLURM_JOB_GPUS' in os.environ or 'SLURM_GPUS' in os.environ:\n",
    "            print(\"Warning: GPUs were allocated in SLURM but PyTorch cannot detect them\")\n",
    "            print(\"This might be due to a configuration issue.\")\n",
    "            print(\"Try running 'module load cuda' before starting your script\")\n",
    "    \n",
    "    print(\"\\n--- End of Environment Detection ---\\n\")\n",
    "    \n",
    "    # Initialize VAE imputer\n",
    "    imputer = VAEImputer(\n",
    "        hidden_dims=hidden_dims,\n",
    "        latent_dim=latent_dim,\n",
    "        batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        device=device,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Fit and transform\n",
    "    print(\"Training VAE imputation model...\")\n",
    "    X_imputed = imputer.fit_transform(X, columns_to_impute)\n",
    "    \n",
    "    # Create imputed dataframe\n",
    "    imputed_df = df.copy()\n",
    "    imputed_df[columns_to_impute] = X_imputed[columns_to_impute]\n",
    "    \n",
    "    # Validate if validation data provided\n",
    "    validation_results = None\n",
    "    if validation_df is not None and validation_masks is not None and original_values is not None:\n",
    "        validation_results = {}\n",
    "        \n",
    "        # Extract validation data\n",
    "        X_val = validation_df[columns_to_use].copy()\n",
    "        \n",
    "        # Ensure all validation columns are numeric\n",
    "        for col in X_val.columns:\n",
    "            X_val[col] = pd.to_numeric(X_val[col], errors='coerce')\n",
    "            \n",
    "        # Impute validation data\n",
    "        X_val_imputed = imputer.transform(X_val)\n",
    "        \n",
    "        # Compare imputed values to real values\n",
    "        with tqdm(columns_to_impute, desc=\"Validating results\") as pbar:\n",
    "            for col in pbar:\n",
    "                pbar.set_description(f\"Validating {col}\")\n",
    "                # Get indices where values were artificially set to NaN\n",
    "                mask = validation_masks[col] & validation_df[col].isna()\n",
    "                \n",
    "                if mask.sum() == 0:\n",
    "                    validation_results[col] = {\n",
    "                        'error': \"No artificially missing values\"\n",
    "                    }\n",
    "                    continue\n",
    "                    \n",
    "                real_vals = original_values[col][mask]\n",
    "                imputed_vals = X_val_imputed.loc[mask, col]\n",
    "                \n",
    "                # Calculate continuous metrics (MAE and RMSE) - NO ROUNDING\n",
    "                mae = mean_absolute_error(real_vals, imputed_vals)\n",
    "                rmse = np.sqrt(mean_squared_error(real_vals, imputed_vals))\n",
    "                \n",
    "                # Calculate classification metrics - WITH ROUNDING\n",
    "                real_vals_class = process_for_classification(real_vals)\n",
    "                imputed_vals_class = process_for_classification(imputed_vals)\n",
    "                \n",
    "                classification_metrics = calculate_classification_metrics(real_vals_class, imputed_vals_class)\n",
    "                \n",
    "                validation_results[col] = {\n",
    "                    'mae': mae,\n",
    "                    'rmse': rmse,\n",
    "                    'accuracy': classification_metrics['accuracy'],\n",
    "                    'auc_multiclass': classification_metrics['auc_multiclass'],\n",
    "                    'avg_sensitivity': classification_metrics['avg_sensitivity'],\n",
    "                    'avg_specificity': classification_metrics['avg_specificity'],\n",
    "                    'avg_ppv': classification_metrics['avg_ppv'],\n",
    "                    'avg_npv': classification_metrics['avg_npv'],\n",
    "                    'precision_macro': classification_metrics['precision_macro'],\n",
    "                    'recall_macro': classification_metrics['recall_macro'],\n",
    "                    'real_distribution': real_vals.describe(),\n",
    "                    'imputed_distribution': pd.Series(imputed_vals).describe()\n",
    "                }\n",
    "                \n",
    "                # Update progress\n",
    "                pbar.set_postfix({\"MAE\": f\"{mae:.4f}\", \"RMSE\": f\"{rmse:.4f}\", \"Acc\": f\"{classification_metrics['accuracy']:.4f}\"})\n",
    "    \n",
    "    return imputed_df, validation_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CUDA Diagnostics ===\n",
      "PyTorch version: 2.7.1\n",
      "CUDA version: 12.6\n",
      "\n",
      "CUDA availability check:\n",
      "torch.cuda.is_available(): True\n",
      "\n",
      "NVIDIA-SMI output:\n",
      "Tue Jul 29 11:30:08 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  |   00000000:18:00.0 Off |                    0 |\n",
      "| N/A   43C    P0             44W /  300W |       3MiB /  32768MiB |      1%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "CUDA Environment Variables:\n",
      "CUDA_VISIBLE_DEVICES: 0\n",
      "CUDA_DEVICE_ORDER: Not set\n",
      "CUDA_HOME: Not set\n",
      "LD_LIBRARY_PATH: Not set\n",
      "\n",
      "GPUs detected by PyTorch:\n",
      "  GPU #0: Tesla V100-SXM2-32GB\n",
      "\n",
      "Attempting to force CUDA initialization...\n",
      "  Success! Test tensor on: cuda:0\n",
      "\n",
      "=== End of Diagnostics ===\n",
      "\n",
      "\n",
      "--- Compute Canada / Cluster Environment Detection ---\n",
      "SLURM_JOB_ID: 64928648\n",
      "SLURM_JOB_GPUS: 0\n",
      "SLURM_GPUS: Not found\n",
      "CUDA_VISIBLE_DEVICES: 0\n",
      "SLURM_JOB_PARTITION: gpubackfill\n",
      "\n",
      "PyTorch detects 1 GPUs\n",
      "GPU #0: Tesla V100-SXM2-32GB\n",
      "  Memory: 34.07 GB\n",
      "  Compute Capability: 7.0\n",
      "\n",
      "--- End of Environment Detection ---\n",
      "\n",
      "Training VAE imputation model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE: 100%|████████████████████████████████████████████████| 100/100 [00:56<00:00,  1.77it/s, loss=3.91, recon=3.67, kl=0.237]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # More detailed CUDA diagnostics\n",
    "    print(\"\\n=== CUDA Diagnostics ===\")\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    \n",
    "    # Check CUDA availability\n",
    "    print(f\"\\nCUDA availability check:\")\n",
    "    print(f\"torch.cuda.is_available(): {torch.cuda.is_available()}\")\n",
    "    \n",
    "    # Show NVIDIA driver info if available\n",
    "    try:\n",
    "        import subprocess\n",
    "        nvidia_info = subprocess.check_output(\"nvidia-smi\", shell=True).decode()\n",
    "        print(\"\\nNVIDIA-SMI output:\")\n",
    "        print(nvidia_info)\n",
    "    except:\n",
    "        print(\"Could not run nvidia-smi\")\n",
    "    \n",
    "    # CUDA environment variables\n",
    "    print(\"\\nCUDA Environment Variables:\")\n",
    "    import os\n",
    "    cuda_vars = [\n",
    "        \"CUDA_VISIBLE_DEVICES\",\n",
    "        \"CUDA_DEVICE_ORDER\",\n",
    "        \"CUDA_HOME\",\n",
    "        \"LD_LIBRARY_PATH\"\n",
    "    ]\n",
    "    for var in cuda_vars:\n",
    "        print(f\"{var}: {os.environ.get(var, 'Not set')}\")\n",
    "    \n",
    "    # Try to force CUDA if available\n",
    "    if torch.cuda.device_count() > 0:\n",
    "        print(\"\\nGPUs detected by PyTorch:\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"  GPU #{i}: {torch.cuda.get_device_name(i)}\")\n",
    "            \n",
    "        # Try to force CUDA initialization\n",
    "        try:\n",
    "            print(\"\\nAttempting to force CUDA initialization...\")\n",
    "            x = torch.zeros(1).cuda()\n",
    "            print(f\"  Success! Test tensor on: {x.device}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Failed to initialize CUDA: {e}\")\n",
    "\n",
    "            # Try enabling TF32 or reduced precision\n",
    "            try:\n",
    "                print(\"\\nTrying to enable TF32...\")\n",
    "                torch.backends.cuda.matmul.allow_tf32 = True\n",
    "                torch.backends.cudnn.allow_tf32 = True\n",
    "                x = torch.zeros(1).cuda()\n",
    "                print(f\"  Success with TF32! Test tensor on: {x.device}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Failed with TF32: {e}\")\n",
    "    else:\n",
    "        print(\"\\nNo GPUs detected by PyTorch.\")\n",
    "        print(\"If you see GPUs in nvidia-smi but not here, check CUDA version compatibility.\")\n",
    "    \n",
    "    print(\"\\n=== End of Diagnostics ===\\n\")\n",
    "    \n",
    "    \n",
    "    ordinal_cols = (\n",
    "    [f\"gp{i}\" for i in range(1, 8)] + [f\"gs{i}\" for i in range(1, 8)] +\n",
    "    [f\"ge{i}\" for i in range(1, 7)] + [f\"gf{i}\" for i in range(1, 8)] +\n",
    "    [f\"a_hn{i}\" for i in range(1, 6)] + [\"a_hn7\", \"a_hn10\"] +\n",
    "    [f\"a_e{i}\" for i in range(1, 8)] + [\"a_c6\", \"a_c2\", \"a_act11\"]\n",
    "    )\n",
    "    columns_to_impute = ordinal_cols#['ge1', 'ge2', 'ge3', 'ge4', 'ge5', 'ge6']\n",
    "\n",
    "    # Apply VAE imputation\n",
    "    imputed_df_vae, validation_results_vae  = apply_vae_imputation(df, columns_to_impute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model - Denoising Autoencoder (DAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnDAE(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Denoising VAE implementation using scikit-learn's MLPRegressor\n",
    "    This avoids TensorFlow execution mode issues completely\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                    hidden_layer_sizes=(64, 32, 16, 32, 64),\n",
    "                    activation='relu',\n",
    "                    max_iter=200,\n",
    "                    learning_rate='adaptive',\n",
    "                    learning_rate_init=0.001,\n",
    "                    noise_factor=0.1,\n",
    "                    alpha=0.0001,\n",
    "                    verbose=True):\n",
    "        \"\"\"\n",
    "        Initialize DAE model parameters\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        hidden_layer_sizes : tuple\n",
    "            Size of hidden layers\n",
    "        activation : str\n",
    "            Activation function ('relu', 'tanh', 'logistic')\n",
    "        max_iter : int\n",
    "            Maximum number of iterations\n",
    "        learning_rate : str\n",
    "            Learning rate schedule\n",
    "        learning_rate_init : float\n",
    "            Initial learning rate\n",
    "        noise_factor : float\n",
    "            Amount of noise to add for denoising effect\n",
    "        alpha : float\n",
    "            L2 regularization parameter\n",
    "        verbose : bool\n",
    "            Whether to print progress\n",
    "        \"\"\"\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.activation = activation\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.learning_rate_init = learning_rate_init\n",
    "        self.noise_factor = noise_factor\n",
    "        self.alpha = alpha\n",
    "        self.verbose = verbose\n",
    "        self.model = None\n",
    "        self.scaler_X = StandardScaler()\n",
    "        \n",
    "    def fit(self, X, missing_mask=None):\n",
    "        \"\"\"\n",
    "        Fit the DAE model to input data\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : numpy.ndarray or pandas.DataFrame\n",
    "            Input data with missing values (NaN)\n",
    "        missing_mask : numpy.ndarray\n",
    "            Binary mask where 1 indicates observed value, 0 for missing\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        self : object\n",
    "            Returns self\n",
    "        \"\"\"\n",
    "        # Convert to numpy array if DataFrame\n",
    "        is_df = isinstance(X, pd.DataFrame)\n",
    "        if is_df:\n",
    "            if self.verbose:\n",
    "                print(\"Converting DataFrame to numpy array\")\n",
    "            X_values = X.values\n",
    "        else:\n",
    "            X_values = X\n",
    "        \n",
    "        # Create missing mask if not provided\n",
    "        if missing_mask is None:\n",
    "            missing_mask = ~np.isnan(X_values)\n",
    "        \n",
    "        # Initial imputation (replace missing values with column means)\n",
    "        X_imputed = np.copy(X_values)\n",
    "        col_means = np.nanmean(X_values, axis=0)\n",
    "        for col in range(X_values.shape[1]):\n",
    "            mask = np.isnan(X_values[:, col])\n",
    "            X_imputed[mask, col] = col_means[col]\n",
    "        \n",
    "        # Scale the data\n",
    "        X_scaled = self.scaler_X.fit_transform(X_imputed)\n",
    "        \n",
    "        # Add noise to create denoising effect\n",
    "        X_noisy = X_scaled + np.random.normal(0, self.noise_factor, X_scaled.shape)\n",
    "        \n",
    "        # Apply mask to noise (only add noise to observed values)\n",
    "        X_noisy = X_noisy * missing_mask + X_scaled * (~missing_mask)\n",
    "        \n",
    "        # Create the model\n",
    "        self.model = MLPRegressor(\n",
    "            hidden_layer_sizes=self.hidden_layer_sizes,\n",
    "            activation=self.activation,\n",
    "            solver='adam',\n",
    "            alpha=self.alpha,\n",
    "            batch_size='auto',\n",
    "            learning_rate=self.learning_rate,\n",
    "            learning_rate_init=self.learning_rate_init,\n",
    "            max_iter=self.max_iter,\n",
    "            shuffle=True,\n",
    "            random_state=42,\n",
    "            verbose=self.verbose\n",
    "        )\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"Fitting DAE model...\")\n",
    "        \n",
    "        # Train the model to reconstruct the original data\n",
    "        self.model.fit(X_noisy, X_scaled)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, missing_mask=None):\n",
    "        \"\"\"\n",
    "        Impute missing values\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : numpy.ndarray or pandas.DataFrame\n",
    "            Data with missing values (NaN)\n",
    "        missing_mask : numpy.ndarray\n",
    "            Binary mask where 1 indicates observed value, 0 for missing\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        X_imputed : numpy.ndarray or pandas.DataFrame\n",
    "            Data with imputed values\n",
    "        \"\"\"\n",
    "        # Handle DataFrame input\n",
    "        is_df = isinstance(X, pd.DataFrame)\n",
    "        if is_df:\n",
    "            columns = X.columns\n",
    "            index = X.index\n",
    "            X_values = X.values\n",
    "        else:\n",
    "            X_values = X\n",
    "        \n",
    "        # Create missing mask if not provided\n",
    "        if missing_mask is None:\n",
    "            missing_mask = ~np.isnan(X_values)\n",
    "        \n",
    "        # Initial imputation for model input\n",
    "        X_imputed = np.copy(X_values)\n",
    "        col_means = np.nanmean(X_values, axis=0)\n",
    "        for col in range(X_values.shape[1]):\n",
    "            mask = np.isnan(X_values[:, col])\n",
    "            X_imputed[mask, col] = col_means[col]\n",
    "        \n",
    "        # Scale data\n",
    "        X_scaled = self.scaler_X.transform(X_imputed)\n",
    "        \n",
    "        # Reconstruct data\n",
    "        X_reconstructed_scaled = self.model.predict(X_scaled)\n",
    "        \n",
    "        # Unscale data\n",
    "        X_reconstructed = self.scaler_X.inverse_transform(X_reconstructed_scaled)\n",
    "        \n",
    "        # Only replace missing values with reconstructed values\n",
    "        X_final = np.copy(X_values)\n",
    "        mask_missing = ~missing_mask\n",
    "        X_final[mask_missing] = X_reconstructed[mask_missing]\n",
    "        \n",
    "        # Return DataFrame if input was DataFrame\n",
    "        if is_df:\n",
    "            return pd.DataFrame(X_final, index=index, columns=columns)\n",
    "        \n",
    "        return X_final\n",
    "    \n",
    "    def fit_transform(self, X, missing_mask=None):\n",
    "        \"\"\"\n",
    "        Fit the model and impute missing values\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : numpy.ndarray or pandas.DataFrame\n",
    "            Data with missing values (NaN)\n",
    "        missing_mask : numpy.ndarray\n",
    "            Binary mask where 1 indicates observed value, 0 for missing\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        X_imputed : numpy.ndarray or pandas.DataFrame\n",
    "            Data with imputed values\n",
    "        \"\"\"\n",
    "        return self.fit(X, missing_mask).transform(X, missing_mask)\n",
    "\n",
    "\n",
    "def apply_sklearn_dae_imputation(df, columns_to_impute, validation_df=None, validation_masks=None, original_values=None):\n",
    "    \"\"\"\n",
    "    Apply scikit-learn based DAE imputation to data using feature importance selection\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Data with missing values\n",
    "    columns_to_impute : list\n",
    "        List of column names to impute\n",
    "    validation_df : pandas.DataFrame, optional\n",
    "        Validation data with artificially missing values\n",
    "    validation_masks : dict, optional\n",
    "        Dictionary of masks for validation\n",
    "    original_values : dict, optional\n",
    "        Dictionary of original values for validation\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    imputed_df : pandas.DataFrame\n",
    "        Data with imputed values\n",
    "    validation_results : dict, optional\n",
    "        Validation results if validation data provided\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        # Create a copy of the dataframe to avoid modifying the original\n",
    "        work_df = df.copy()\n",
    "        \n",
    "        # Ensure all columns are numeric\n",
    "        for col in work_df.columns:\n",
    "            work_df[col] = pd.to_numeric(work_df[col], errors='coerce')\n",
    "        \n",
    "        print(f\"Original data shape: {work_df.shape}\")\n",
    "        print(f\"Missing values: {work_df.isna().sum().sum()}\")\n",
    "        print(f\"Columns to impute: {columns_to_impute}\")\n",
    "        \n",
    "        # Step 1: Identify important features for each target column\n",
    "        feature_importances = {}\n",
    "        max_features_per_target = 20  # Maximum number of features to select per target\n",
    "        min_importance_threshold = 0.01  # Minimum importance score to include a feature\n",
    "        \n",
    "        print(\"Identifying important features for each target column...\")\n",
    "        \n",
    "        # For each target column, find the most important predictors\n",
    "        for target in columns_to_impute:\n",
    "            # Create temporary dataset without missing values in the target\n",
    "            temp_df = work_df.dropna(subset=[target]).copy()\n",
    "            \n",
    "            # Skip if there are too few samples\n",
    "            if len(temp_df) < 30:\n",
    "                print(f\"  Skipping feature selection for {target}: insufficient samples\")\n",
    "                # Use all columns except other targets as predictors\n",
    "                non_target_cols = [col for col in work_df.columns if col not in columns_to_impute or col == target]\n",
    "                feature_importances[target] = non_target_cols\n",
    "                continue\n",
    "            \n",
    "            # Separate predictors and target\n",
    "            other_targets = [col for col in columns_to_impute if col != target]\n",
    "            X_temp = temp_df.drop(columns=other_targets)\n",
    "            potential_predictors = [col for col in X_temp.columns if col != target]\n",
    "            \n",
    "            # Skip if there are no potential predictors\n",
    "            if len(potential_predictors) == 0:\n",
    "                print(f\"  No potential predictors for {target}\")\n",
    "                feature_importances[target] = [target]  # Use only the target itself\n",
    "                continue\n",
    "            \n",
    "            # Use potential predictors that have fewer than 30% missing values\n",
    "            valid_predictors = []\n",
    "            for col in potential_predictors:\n",
    "                if X_temp[col].isna().mean() < 0.3 and col != target:\n",
    "                    valid_predictors.append(col)\n",
    "            \n",
    "            # Skip feature selection if there are too few valid predictors\n",
    "            if len(valid_predictors) <= 3:\n",
    "                print(f\"  Too few valid predictors for {target}, using all available\")\n",
    "                feature_importances[target] = valid_predictors + [target]\n",
    "                continue\n",
    "            \n",
    "            # Create dataset for feature selection\n",
    "            X_select = X_temp[valid_predictors].copy()\n",
    "            y_select = X_temp[target].copy()\n",
    "            \n",
    "            # Fill any remaining NaNs in predictors with mean\n",
    "            for col in X_select.columns:\n",
    "                if X_select[col].isna().any():\n",
    "                    X_select[col] = X_select[col].fillna(X_select[col].mean())\n",
    "            \n",
    "            # Train random forest to identify important features\n",
    "            print(f\"  Training feature selector for {target} using {len(X_select)} samples and {len(valid_predictors)} predictors\")\n",
    "            rf = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\n",
    "            rf.fit(X_select, y_select)\n",
    "            \n",
    "            # Get important features\n",
    "            importances = rf.feature_importances_\n",
    "            features_with_importance = list(zip(valid_predictors, importances))\n",
    "            \n",
    "            # Sort by importance\n",
    "            features_with_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            # Select top features with importance above threshold\n",
    "            top_features = []\n",
    "            for feat, imp in features_with_importance:\n",
    "                if imp >= min_importance_threshold and len(top_features) < max_features_per_target:\n",
    "                    top_features.append(feat)\n",
    "            \n",
    "            # Always include the target itself\n",
    "            if target not in top_features:\n",
    "                top_features.append(target)\n",
    "            \n",
    "            print(f\"  Selected {len(top_features)} features for {target}\")\n",
    "            feature_importances[target] = top_features\n",
    "        \n",
    "        # Step 2: Combine all important features\n",
    "        selected_columns = set()\n",
    "        for target, features in feature_importances.items():\n",
    "            selected_columns.update(features)\n",
    "        \n",
    "        # Ensure all target columns are included\n",
    "        for col in columns_to_impute:\n",
    "            selected_columns.add(col)\n",
    "        \n",
    "        selected_columns = list(selected_columns)\n",
    "        print(f\"Using {len(selected_columns)} columns for imputation: {selected_columns}\")\n",
    "        \n",
    "        # Step 3: Extract data with selected columns\n",
    "        X = work_df[selected_columns].copy()\n",
    "        \n",
    "        # Create missing mask\n",
    "        missing_mask = ~X.isna()\n",
    "        \n",
    "        # Step 4: Initialize DAE model with adaptive parameters based on data size\n",
    "        neurons_per_layer = min(128, max(16, X.shape[0] // 100))\n",
    "        print(f\"Using {neurons_per_layer} neurons per layer\")\n",
    "        \n",
    "        # Initialize the SklearnDAE model\n",
    "        dae = SklearnDAE(\n",
    "            hidden_layer_sizes=(neurons_per_layer, neurons_per_layer//2, neurons_per_layer//4, neurons_per_layer//2, neurons_per_layer),\n",
    "            activation='relu',\n",
    "            max_iter=200,\n",
    "            learning_rate='adaptive',\n",
    "            learning_rate_init=0.001,\n",
    "            noise_factor=0.1,\n",
    "            alpha=0.0001,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # Step 5: Fit and transform using selected features\n",
    "        X_imputed = dae.fit_transform(X, missing_mask.values)\n",
    "        \n",
    "        # Step 6: Create imputed dataframe, only updating the target columns\n",
    "        imputed_df = df.copy()\n",
    "        imputed_df[columns_to_impute] = X_imputed[columns_to_impute]\n",
    "        \n",
    "        # Step 7: Validate if required\n",
    "        validation_results = None\n",
    "        if validation_df is not None and validation_masks is not None and original_values is not None:\n",
    "            validation_results = {}\n",
    "            \n",
    "            # Extract validation data\n",
    "            X_val = validation_df[selected_columns].copy()\n",
    "            \n",
    "            # Ensure numeric\n",
    "            for col in X_val.columns:\n",
    "                X_val[col] = pd.to_numeric(X_val[col], errors='coerce')\n",
    "                \n",
    "            # Create validation mask\n",
    "            val_mask = ~X_val.isna()\n",
    "            \n",
    "            # Impute validation data\n",
    "            X_val_imputed = dae.transform(X_val, val_mask.values)\n",
    "            \n",
    "            # Compare imputed values to real values\n",
    "            for col in columns_to_impute:\n",
    "                mask = validation_masks[col] & validation_df[col].isna()\n",
    "                \n",
    "                if mask.sum() == 0:\n",
    "                    validation_results[col] = {'error': \"No artificially missing values\"}\n",
    "                    continue\n",
    "                    \n",
    "                real_vals = original_values[col][mask]\n",
    "                imputed_vals = X_val_imputed[mask][col]\n",
    "                \n",
    "                # Calculate continuous metrics (MAE and RMSE) - NO ROUNDING\n",
    "                mae = mean_absolute_error(real_vals, imputed_vals)\n",
    "                rmse = np.sqrt(mean_squared_error(real_vals, imputed_vals))\n",
    "                \n",
    "                # Calculate classification metrics - WITH ROUNDING\n",
    "                real_vals_class = process_for_classification(real_vals)\n",
    "                imputed_vals_class = process_for_classification(imputed_vals)\n",
    "                \n",
    "                classification_metrics = calculate_classification_metrics(real_vals_class, imputed_vals_class)\n",
    "                \n",
    "                validation_results[col] = {\n",
    "                    'mae': mae,\n",
    "                    'rmse': rmse,\n",
    "                    'accuracy': classification_metrics['accuracy'],\n",
    "                    'auc_multiclass': classification_metrics['auc_multiclass'],\n",
    "                    'avg_sensitivity': classification_metrics['avg_sensitivity'],\n",
    "                    'avg_specificity': classification_metrics['avg_specificity'],\n",
    "                    'avg_ppv': classification_metrics['avg_ppv'],\n",
    "                    'avg_npv': classification_metrics['avg_npv'],\n",
    "                    'precision_macro': classification_metrics['precision_macro'],\n",
    "                    'recall_macro': classification_metrics['recall_macro'],\n",
    "                    'real_distribution': real_vals.describe(),\n",
    "                    'imputed_distribution': imputed_vals.describe()\n",
    "                }\n",
    "                \n",
    "                print(f\"Validation for {col}: MAE={mae:.4f}, RMSE={rmse:.4f}, Acc={classification_metrics['accuracy']:.4f}\")\n",
    "        \n",
    "        return imputed_df, validation_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"Error in scikit-learn DAE imputation: {str(e)}\")\n",
    "        print(traceback.format_exc())\n",
    "        \n",
    "        # Fallback to simple imputation\n",
    "        print(\"Falling back to simple mean imputation\")\n",
    "        result_df = df.copy()\n",
    "        for col in columns_to_impute:\n",
    "            result_df[col] = pd.to_numeric(result_df[col], errors='coerce')\n",
    "            result_df[col] = result_df[col].fillna(result_df[col].mean())\n",
    "        return result_df, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (5230, 62)\n",
      "Missing values: 262139\n",
      "Columns to impute: ['gp1', 'gp2', 'gp3', 'gp4', 'gp5', 'gp6', 'gp7', 'gs1', 'gs2', 'gs3', 'gs4', 'gs5', 'gs6', 'gs7', 'ge1', 'ge2', 'ge3', 'ge4', 'ge5', 'ge6', 'gf1', 'gf2', 'gf3', 'gf4', 'gf5', 'gf6', 'gf7', 'a_hn1', 'a_hn2', 'a_hn3', 'a_hn4', 'a_hn5', 'a_hn7', 'a_hn10', 'a_e1', 'a_e2', 'a_e3', 'a_e4', 'a_e5', 'a_e6', 'a_e7', 'a_c6', 'a_c2', 'a_act11']\n",
      "Identifying important features for each target column...\n",
      "  Too few valid predictors for gp1, using all available\n",
      "  Too few valid predictors for gp2, using all available\n",
      "  Too few valid predictors for gp3, using all available\n",
      "  Too few valid predictors for gp4, using all available\n",
      "  Too few valid predictors for gp5, using all available\n",
      "  Too few valid predictors for gp6, using all available\n",
      "  Too few valid predictors for gp7, using all available\n",
      "  Too few valid predictors for gs1, using all available\n",
      "  Too few valid predictors for gs2, using all available\n",
      "  Too few valid predictors for gs3, using all available\n",
      "  Too few valid predictors for gs4, using all available\n",
      "  Too few valid predictors for gs5, using all available\n",
      "  Too few valid predictors for gs6, using all available\n",
      "  Too few valid predictors for gs7, using all available\n",
      "  Too few valid predictors for ge1, using all available\n",
      "  Too few valid predictors for ge2, using all available\n",
      "  Too few valid predictors for ge3, using all available\n",
      "  Too few valid predictors for ge4, using all available\n",
      "  Too few valid predictors for ge5, using all available\n",
      "  Too few valid predictors for ge6, using all available\n",
      "  Too few valid predictors for gf1, using all available\n",
      "  Too few valid predictors for gf2, using all available\n",
      "  Too few valid predictors for gf3, using all available\n",
      "  Too few valid predictors for gf4, using all available\n",
      "  Too few valid predictors for gf5, using all available\n",
      "  Too few valid predictors for gf6, using all available\n",
      "  Too few valid predictors for gf7, using all available\n",
      "  Too few valid predictors for a_hn1, using all available\n",
      "  Too few valid predictors for a_hn2, using all available\n",
      "  Too few valid predictors for a_hn3, using all available\n",
      "  Too few valid predictors for a_hn4, using all available\n",
      "  Too few valid predictors for a_hn5, using all available\n",
      "  Too few valid predictors for a_hn7, using all available\n",
      "  Too few valid predictors for a_hn10, using all available\n",
      "  Too few valid predictors for a_e1, using all available\n",
      "  Too few valid predictors for a_e2, using all available\n",
      "  Too few valid predictors for a_e3, using all available\n",
      "  Too few valid predictors for a_e4, using all available\n",
      "  Too few valid predictors for a_e5, using all available\n",
      "  Too few valid predictors for a_e6, using all available\n",
      "  Too few valid predictors for a_e7, using all available\n",
      "  Too few valid predictors for a_c6, using all available\n",
      "  Too few valid predictors for a_c2, using all available\n",
      "  Too few valid predictors for a_act11, using all available\n",
      "Using 46 columns for imputation: ['gp3', 'gp1', 'gf1', 'a_e6', 'a_e2', 'ge1', 'gf2', 'a_hn2', 'gs5', 'ge5', 'gs7', 'a_c6', 'gs1', 'ge4', 'gs6', 'a_e3', 'gf4', 'gf6', 'qol_date', 'a_hn1', 'a_c2', 'a_e5', 'a_hn5', 'gs2', 'gf5', 'a_hn4', 'ge6', 'ge2', 'gs4', 'a_hn10', 'gf7', 'a_e4', 'a_hn7', 'a_hn3', 'gp6', 'a_e7', 'a_act11', 'gp5', 'gp4', 'gs3', 'gp2', 'a_e1', 'gp7', 'ge3', 'gf3', 'id']\n",
      "Using 52 neurons per layer\n",
      "Converting DataFrame to numpy array\n",
      "Fitting DAE model...\n",
      "Iteration 1, loss = 0.49983812\n",
      "Iteration 2, loss = 0.43041987\n",
      "Iteration 3, loss = 0.37210194\n",
      "Iteration 4, loss = 0.34337592\n",
      "Iteration 5, loss = 0.32424917\n",
      "Iteration 6, loss = 0.30856581\n",
      "Iteration 7, loss = 0.29390852\n",
      "Iteration 8, loss = 0.28084403\n",
      "Iteration 9, loss = 0.26988242\n",
      "Iteration 10, loss = 0.26257058\n",
      "Iteration 11, loss = 0.25508301\n",
      "Iteration 12, loss = 0.24986644\n",
      "Iteration 13, loss = 0.24550963\n",
      "Iteration 14, loss = 0.24099683\n",
      "Iteration 15, loss = 0.23693363\n",
      "Iteration 16, loss = 0.23264183\n",
      "Iteration 17, loss = 0.22879225\n",
      "Iteration 18, loss = 0.22538962\n",
      "Iteration 19, loss = 0.22249606\n",
      "Iteration 20, loss = 0.21837680\n",
      "Iteration 21, loss = 0.21580429\n",
      "Iteration 22, loss = 0.21328965\n",
      "Iteration 23, loss = 0.20982082\n",
      "Iteration 24, loss = 0.20719861\n",
      "Iteration 25, loss = 0.20530035\n",
      "Iteration 26, loss = 0.20266806\n",
      "Iteration 27, loss = 0.19975299\n",
      "Iteration 28, loss = 0.19825480\n",
      "Iteration 29, loss = 0.19637733\n",
      "Iteration 30, loss = 0.19470515\n",
      "Iteration 31, loss = 0.19248840\n",
      "Iteration 32, loss = 0.19027146\n",
      "Iteration 33, loss = 0.18877831\n",
      "Iteration 34, loss = 0.18714313\n",
      "Iteration 35, loss = 0.18595063\n",
      "Iteration 36, loss = 0.18480419\n",
      "Iteration 37, loss = 0.18314967\n",
      "Iteration 38, loss = 0.18157894\n",
      "Iteration 39, loss = 0.18034546\n",
      "Iteration 40, loss = 0.17905912\n",
      "Iteration 41, loss = 0.17793886\n",
      "Iteration 42, loss = 0.17736847\n",
      "Iteration 43, loss = 0.17675010\n",
      "Iteration 44, loss = 0.17563595\n",
      "Iteration 45, loss = 0.17442863\n",
      "Iteration 46, loss = 0.17468243\n",
      "Iteration 47, loss = 0.17308803\n",
      "Iteration 48, loss = 0.17209150\n",
      "Iteration 49, loss = 0.17159093\n",
      "Iteration 50, loss = 0.17140768\n",
      "Iteration 51, loss = 0.17067953\n",
      "Iteration 52, loss = 0.16976026\n",
      "Iteration 53, loss = 0.16988073\n",
      "Iteration 54, loss = 0.16876653\n",
      "Iteration 55, loss = 0.16838220\n",
      "Iteration 56, loss = 0.16804328\n",
      "Iteration 57, loss = 0.16660409\n",
      "Iteration 58, loss = 0.16680715\n",
      "Iteration 59, loss = 0.16589565\n",
      "Iteration 60, loss = 0.16534293\n",
      "Iteration 61, loss = 0.16592272\n",
      "Iteration 62, loss = 0.16532935\n",
      "Iteration 63, loss = 0.16444114\n",
      "Iteration 64, loss = 0.16403725\n",
      "Iteration 65, loss = 0.16362486\n",
      "Iteration 66, loss = 0.16311540\n",
      "Iteration 67, loss = 0.16254913\n",
      "Iteration 68, loss = 0.16249562\n",
      "Iteration 69, loss = 0.16207800\n",
      "Iteration 70, loss = 0.16192884\n",
      "Iteration 71, loss = 0.16134152\n",
      "Iteration 72, loss = 0.16082294\n",
      "Iteration 73, loss = 0.16072556\n",
      "Iteration 74, loss = 0.16053945\n",
      "Iteration 75, loss = 0.16054981\n",
      "Iteration 76, loss = 0.15999020\n",
      "Iteration 77, loss = 0.15932443\n",
      "Iteration 78, loss = 0.15912186\n",
      "Iteration 79, loss = 0.15899888\n",
      "Iteration 80, loss = 0.15885589\n",
      "Iteration 81, loss = 0.15822757\n",
      "Iteration 82, loss = 0.15799061\n",
      "Iteration 83, loss = 0.15798996\n",
      "Iteration 84, loss = 0.15785530\n",
      "Iteration 85, loss = 0.15756192\n",
      "Iteration 86, loss = 0.15787299\n",
      "Iteration 87, loss = 0.15817638\n",
      "Iteration 88, loss = 0.15699374\n",
      "Iteration 89, loss = 0.15754347\n",
      "Iteration 90, loss = 0.15711069\n",
      "Iteration 91, loss = 0.15588800\n",
      "Iteration 92, loss = 0.15602360\n",
      "Iteration 93, loss = 0.15538108\n",
      "Iteration 94, loss = 0.15563048\n",
      "Iteration 95, loss = 0.15536205\n",
      "Iteration 96, loss = 0.15503701\n",
      "Iteration 97, loss = 0.15415830\n",
      "Iteration 98, loss = 0.15396894\n",
      "Iteration 99, loss = 0.15412561\n",
      "Iteration 100, loss = 0.15448937\n",
      "Iteration 101, loss = 0.15353893\n",
      "Iteration 102, loss = 0.15398516\n",
      "Iteration 103, loss = 0.15344473\n",
      "Iteration 104, loss = 0.15316817\n",
      "Iteration 105, loss = 0.15323033\n",
      "Iteration 106, loss = 0.15345300\n",
      "Iteration 107, loss = 0.15267994\n",
      "Iteration 108, loss = 0.15233326\n",
      "Iteration 109, loss = 0.15264730\n",
      "Iteration 110, loss = 0.15175840\n",
      "Iteration 111, loss = 0.15184717\n",
      "Iteration 112, loss = 0.15202567\n",
      "Iteration 113, loss = 0.15141969\n",
      "Iteration 114, loss = 0.15113107\n",
      "Iteration 115, loss = 0.15086888\n",
      "Iteration 116, loss = 0.15095439\n",
      "Iteration 117, loss = 0.15065931\n",
      "Iteration 118, loss = 0.15042304\n",
      "Iteration 119, loss = 0.15022474\n",
      "Iteration 120, loss = 0.15015033\n",
      "Iteration 121, loss = 0.15015589\n",
      "Iteration 122, loss = 0.14972342\n",
      "Iteration 123, loss = 0.14976702\n",
      "Iteration 124, loss = 0.14955854\n",
      "Iteration 125, loss = 0.14987601\n",
      "Iteration 126, loss = 0.14904907\n",
      "Iteration 127, loss = 0.14893399\n",
      "Iteration 128, loss = 0.14866167\n",
      "Iteration 129, loss = 0.14934233\n",
      "Iteration 130, loss = 0.14869647\n",
      "Iteration 131, loss = 0.14834591\n",
      "Iteration 132, loss = 0.14748189\n",
      "Iteration 133, loss = 0.14816763\n",
      "Iteration 134, loss = 0.14848483\n",
      "Iteration 135, loss = 0.14834909\n",
      "Iteration 136, loss = 0.14809713\n",
      "Iteration 137, loss = 0.14741282\n",
      "Iteration 138, loss = 0.14786594\n",
      "Iteration 139, loss = 0.14732693\n",
      "Iteration 140, loss = 0.14705460\n",
      "Iteration 141, loss = 0.14731967\n",
      "Iteration 142, loss = 0.14649999\n",
      "Iteration 143, loss = 0.14666387\n",
      "Iteration 144, loss = 0.14610376\n",
      "Iteration 145, loss = 0.14668948\n",
      "Iteration 146, loss = 0.14637972\n",
      "Iteration 147, loss = 0.14635680\n",
      "Iteration 148, loss = 0.14577186\n",
      "Iteration 149, loss = 0.14647985\n",
      "Iteration 150, loss = 0.14570521\n",
      "Iteration 151, loss = 0.14599163\n",
      "Iteration 152, loss = 0.14497908\n",
      "Iteration 153, loss = 0.14508123\n",
      "Iteration 154, loss = 0.14475445\n",
      "Iteration 155, loss = 0.14453194\n",
      "Iteration 156, loss = 0.14495657\n",
      "Iteration 157, loss = 0.14453637\n",
      "Iteration 158, loss = 0.14440919\n",
      "Iteration 159, loss = 0.14426500\n",
      "Iteration 160, loss = 0.14483656\n",
      "Iteration 161, loss = 0.14384905\n",
      "Iteration 162, loss = 0.14377548\n",
      "Iteration 163, loss = 0.14394058\n",
      "Iteration 164, loss = 0.14367438\n",
      "Iteration 165, loss = 0.14350795\n",
      "Iteration 166, loss = 0.14343810\n",
      "Iteration 167, loss = 0.14377805\n",
      "Iteration 168, loss = 0.14317888\n",
      "Iteration 169, loss = 0.14363549\n",
      "Iteration 170, loss = 0.14342693\n",
      "Iteration 171, loss = 0.14298687\n",
      "Iteration 172, loss = 0.14268668\n",
      "Iteration 173, loss = 0.14200617\n",
      "Iteration 174, loss = 0.14259767\n",
      "Iteration 175, loss = 0.14297930\n",
      "Iteration 176, loss = 0.14334635\n",
      "Iteration 177, loss = 0.14256461\n",
      "Iteration 178, loss = 0.14227790\n",
      "Iteration 179, loss = 0.14219350\n",
      "Iteration 180, loss = 0.14191123\n",
      "Iteration 181, loss = 0.14212845\n",
      "Iteration 182, loss = 0.14186843\n",
      "Iteration 183, loss = 0.14150669\n",
      "Iteration 184, loss = 0.14209066\n",
      "Iteration 185, loss = 0.14144137\n",
      "Iteration 186, loss = 0.14141671\n",
      "Iteration 187, loss = 0.14190371\n",
      "Iteration 188, loss = 0.14106261\n",
      "Iteration 189, loss = 0.14147816\n",
      "Iteration 190, loss = 0.14096191\n",
      "Iteration 191, loss = 0.14150575\n",
      "Iteration 192, loss = 0.14113280\n",
      "Iteration 193, loss = 0.14101816\n",
      "Iteration 194, loss = 0.14094737\n",
      "Iteration 195, loss = 0.14013775\n",
      "Iteration 196, loss = 0.14046015\n",
      "Iteration 197, loss = 0.14037704\n",
      "Iteration 198, loss = 0.14030981\n",
      "Iteration 199, loss = 0.14046448\n",
      "Iteration 200, loss = 0.13981959\n"
     ]
    }
   ],
   "source": [
    "# Define columns to impute\n",
    "ordinal_cols = (\n",
    "    [f\"gp{i}\" for i in range(1, 8)] + [f\"gs{i}\" for i in range(1, 8)] +\n",
    "    [f\"ge{i}\" for i in range(1, 7)] + [f\"gf{i}\" for i in range(1, 8)] +\n",
    "    [f\"a_hn{i}\" for i in range(1, 6)] + [\"a_hn7\", \"a_hn10\"] +\n",
    "    [f\"a_e{i}\" for i in range(1, 8)] + [\"a_c6\", \"a_c2\", \"a_act11\"]\n",
    ")\n",
    "columns_to_impute = ordinal_cols#['ge1', 'ge2', 'ge3', 'ge4', 'ge5', 'ge6']\n",
    "\n",
    "\n",
    "# Apply DAE imputation\n",
    "imputed_df_dae, validation_results_dae = apply_sklearn_dae_imputation(df, columns_to_impute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_results_dae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model - Bayesian PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.distributions as dist\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import time\n",
    "\n",
    "\n",
    "class BayesianPCATorch(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch implementation of Bayesian PCA model\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features, n_components):\n",
    "        super(BayesianPCATorch, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.n_components = n_components\n",
    "        \n",
    "        # Priors for loadings (W)\n",
    "        self.w_mu = nn.Parameter(torch.zeros(n_features, n_components), requires_grad=True)\n",
    "        self.w_log_sigma = nn.Parameter(torch.zeros(n_features, n_components), requires_grad=True)\n",
    "        \n",
    "        # Noise precision (inverse variance)\n",
    "        self.log_tau = nn.Parameter(torch.zeros(1), requires_grad=True)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        # Sample from approximate posterior for W\n",
    "        w_sigma = torch.exp(self.w_log_sigma)\n",
    "        epsilon_w = torch.randn_like(self.w_mu)\n",
    "        w = self.w_mu + w_sigma * epsilon_w\n",
    "        \n",
    "        # Compute reconstruction\n",
    "        tau = torch.exp(self.log_tau)\n",
    "        reconstruction = torch.matmul(z, w.t())\n",
    "        \n",
    "        return reconstruction, w, tau\n",
    "    \n",
    "    def sample_loadings(self, n_samples=1):\n",
    "        \"\"\"Sample loadings (W) from the approximate posterior\"\"\"\n",
    "        w_sigma = torch.exp(self.w_log_sigma)\n",
    "        epsilon_w = torch.randn(n_samples, self.n_features, self.n_components, device=self.w_mu.device)\n",
    "        w_samples = self.w_mu.unsqueeze(0) + w_sigma.unsqueeze(0) * epsilon_w\n",
    "        return w_samples\n",
    "\n",
    "\n",
    "class BayesianPCAImputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    A scikit-learn compatible Bayesian PCA imputation model\n",
    "    using PyTorch for GPU acceleration\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 n_components=5,\n",
    "                 n_samples=1000,\n",
    "                 batch_size=64,\n",
    "                 n_epochs=100,\n",
    "                 learning_rate=0.01,\n",
    "                 device=None,\n",
    "                 verbose=True):\n",
    "        \"\"\"\n",
    "        Initialize PyTorch-based Bayesian PCA imputer\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_components : int\n",
    "            Number of principal components\n",
    "        n_samples : int\n",
    "            Number of posterior samples to draw\n",
    "        batch_size : int\n",
    "            Batch size for training\n",
    "        n_epochs : int\n",
    "            Number of training epochs\n",
    "        learning_rate : float\n",
    "            Learning rate for optimizer\n",
    "        device : str or torch.device\n",
    "            Device to use ('cuda' or 'cpu'), defaults to CUDA if available\n",
    "        verbose : bool\n",
    "            Whether to print progress\n",
    "        \"\"\"\n",
    "        self.n_components = n_components\n",
    "        self.n_samples = n_samples\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs = n_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Set device\n",
    "        if device is None:\n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        else:\n",
    "            self.device = torch.device(device)\n",
    "            \n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Initialize model components\n",
    "        self.pca_model = None  # For standard PCA initialization\n",
    "        self.scaler = None     # For data scaling\n",
    "        self.model = None      # The PyTorch model\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit Bayesian PCA model using PyTorch\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pandas.DataFrame\n",
    "            Data with missing values\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        self : object\n",
    "            Returns self\n",
    "        \"\"\"\n",
    "        # Store column names and index\n",
    "        self.columns = X.columns\n",
    "        self.index = X.index\n",
    "        \n",
    "        # Create a copy of data\n",
    "        X_data = X.copy()\n",
    "        \n",
    "        # Convert to numpy array\n",
    "        X_array = X_data.values\n",
    "        \n",
    "        # Initialize scaler\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        # Simple imputation for initial values (for fitting the scaler)\n",
    "        simple_imputer = SimpleImputer(strategy='mean')\n",
    "        X_imputed_for_scaling = simple_imputer.fit_transform(X_array)\n",
    "        \n",
    "        # Scale data\n",
    "        X_scaled = self.scaler.fit_transform(X_imputed_for_scaling)\n",
    "        \n",
    "        # Create a mask for missing values\n",
    "        self.missing_mask = np.isnan(X_array)\n",
    "        \n",
    "        # Perform standard PCA for initialization\n",
    "        pca = PCA(n_components=self.n_components)\n",
    "        pca.fit(X_scaled)\n",
    "        self.pca_model = pca\n",
    "        \n",
    "        # Initialize PyTorch model\n",
    "        n_samples, n_features = X_scaled.shape\n",
    "        self.model = BayesianPCATorch(n_features, self.n_components).to(self.device)\n",
    "        \n",
    "        # Initialize model parameters using standard PCA\n",
    "        with torch.no_grad():\n",
    "            # Initialize W to PCA loadings\n",
    "            self.model.w_mu.data = torch.tensor(pca.components_.T, dtype=torch.float32).to(self.device)\n",
    "            \n",
    "            # Initialize noise precision (tau) based on explained variance\n",
    "            explained_var = pca.explained_variance_\n",
    "            noise_var = np.mean(np.var(X_scaled, axis=0) - np.sum(explained_var))\n",
    "            noise_var = max(noise_var, 1e-6)  # Ensure positive variance\n",
    "            self.model.log_tau.data = torch.tensor([np.log(1.0 / noise_var)], dtype=torch.float32).to(self.device)\n",
    "        \n",
    "        # Prepare data for PyTorch training\n",
    "        # Fill missing values with zeros (will be handled by the mask)\n",
    "        X_for_torch = X_scaled.copy()\n",
    "        X_for_torch[self.missing_mask] = 0.0\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        X_tensor = torch.tensor(X_for_torch, dtype=torch.float32).to(self.device)\n",
    "        mask_tensor = torch.tensor(~self.missing_mask, dtype=torch.float32).to(self.device)\n",
    "        \n",
    "        # Initialize latent variables (z) using PCA scores\n",
    "        z_init = pca.transform(X_scaled)\n",
    "        \n",
    "        # Store the latent variables as a model parameter\n",
    "        self.latent_z = nn.Parameter(torch.tensor(z_init, dtype=torch.float32, device=self.device))\n",
    "        \n",
    "        # Train the model\n",
    "        self._train_model(X_tensor, mask_tensor)\n",
    "        \n",
    "        # Store final latent variables for later use\n",
    "        self.z = self.latent_z.detach().cpu().numpy()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _train_model(self, X, mask):\n",
    "        \"\"\"\n",
    "        Train the Bayesian PCA model using stochastic variational inference\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : torch.Tensor\n",
    "            Data tensor\n",
    "        mask : torch.Tensor\n",
    "            Mask tensor (1 for observed, 0 for missing)\n",
    "        \"\"\"\n",
    "        # Setup optimizer - include latent_z as a parameter of self\n",
    "        parameters = list(self.model.parameters()) + [self.latent_z]\n",
    "        optimizer = optim.Adam(parameters, lr=self.learning_rate)\n",
    "        \n",
    "        # Setup scheduler for learning rate decay\n",
    "        try:\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer, mode='min', factor=0.5, patience=5, verbose=self.verbose\n",
    "            )\n",
    "        except TypeError:\n",
    "            print(\"⚠️ 'verbose' not supported in ReduceLROnPlateau, using fallback...\")\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer, mode='min', factor=0.5, patience=5\n",
    "            )\n",
    "        \n",
    "        # Training loop\n",
    "        if self.verbose:\n",
    "            print(f\"Training Bayesian PCA model on {self.device}...\")\n",
    "            print(f\"Data shape: {X.shape}, Components: {self.n_components}\")\n",
    "            print(f\"Missing values: {torch.sum(mask == 0).item()} out of {X.numel()}\")\n",
    "            \n",
    "        epoch_pbar = range(self.n_epochs)\n",
    "        if self.verbose:\n",
    "            epoch_pbar = tqdm(epoch_pbar, desc=\"Training\")\n",
    "            \n",
    "        # For early stopping\n",
    "        best_loss = float('inf')\n",
    "        patience = 60  # Increased patience to 60\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Store z for later use\n",
    "        for epoch in epoch_pbar:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            x_recon, w_samples, tau = self.model(self.latent_z)\n",
    "            \n",
    "            # Compute loss - only for observed values\n",
    "            # Likelihood term (reconstruction error)\n",
    "            mse_loss = torch.sum(mask * (X - x_recon) ** 2)\n",
    "            \n",
    "            # Prior on z (standard normal)\n",
    "            z_prior_loss = 0.5 * torch.sum(self.latent_z ** 2)\n",
    "            \n",
    "            # Prior on W (standard normal)\n",
    "            w_mu = self.model.w_mu\n",
    "            w_sigma = torch.exp(self.model.w_log_sigma)\n",
    "            w_prior_loss = 0.5 * torch.sum(w_mu ** 2 + w_sigma ** 2 - torch.log(w_sigma ** 2) - 1)\n",
    "            \n",
    "            # Total loss\n",
    "            loss = mse_loss * tau + z_prior_loss + w_prior_loss\n",
    "            \n",
    "            # Backward pass and optimization step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Get current loss\n",
    "            current_loss = loss.item()\n",
    "            \n",
    "            # Update learning rate\n",
    "            scheduler.step(current_loss)\n",
    "            \n",
    "            # Update progress bar with current loss\n",
    "            if self.verbose:\n",
    "                epoch_pbar.set_postfix({\"Loss\": f\"{current_loss:.4f}\"})\n",
    "            \n",
    "            # Early stopping\n",
    "            if current_loss < best_loss:\n",
    "                best_loss = current_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                \n",
    "            if patience_counter >= patience:\n",
    "                if self.verbose:\n",
    "                    print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "                \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Impute missing values using Bayesian PCA\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pandas.DataFrame\n",
    "            Data with missing values\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        imputed_df : pandas.DataFrame\n",
    "            Data with imputed values\n",
    "        \"\"\"\n",
    "        # Create copy to avoid modifying original\n",
    "        imputed_df = X.copy()\n",
    "        \n",
    "        # Check if this is the same data used for fitting\n",
    "        new_data = not np.array_equal(X.index, self.index) or not np.array_equal(X.columns, self.columns)\n",
    "        \n",
    "        if new_data:\n",
    "            # For new data, we need to project onto the learned components\n",
    "            # This is a simplified approach and could be improved\n",
    "            \n",
    "            # Create a copy of data\n",
    "            X_data = X.copy()\n",
    "            \n",
    "            # Convert to numpy array\n",
    "            X_array = X_data.values\n",
    "            \n",
    "            # Simple imputation for initial values\n",
    "            simple_imputer = SimpleImputer(strategy='mean')\n",
    "            X_imputed = simple_imputer.fit_transform(X_array)\n",
    "            \n",
    "            # Scale data\n",
    "            X_scaled = self.scaler.transform(X_imputed)\n",
    "            \n",
    "            # Create a mask for missing values\n",
    "            missing_mask = np.isnan(X_array)\n",
    "            \n",
    "            # Project data onto principal components\n",
    "            z = self.pca_model.transform(X_scaled)\n",
    "            \n",
    "            # Get mean of W from model\n",
    "            w_samples = self.model.sample_loadings(n_samples=self.n_samples)\n",
    "            w_mean = w_samples.mean(dim=0).cpu().detach().numpy()\n",
    "            \n",
    "            # Reconstruct data\n",
    "            X_reconstructed = np.dot(z, w_mean.T)\n",
    "            \n",
    "            # Inverse transform to original scale\n",
    "            X_reconstructed = self.scaler.inverse_transform(X_reconstructed)\n",
    "            \n",
    "            # Only replace missing values\n",
    "            X_array_imputed = X_array.copy()\n",
    "            X_array_imputed[missing_mask] = X_reconstructed[missing_mask]\n",
    "            \n",
    "            # Convert back to DataFrame\n",
    "            imputed_df = pd.DataFrame(X_array_imputed, \n",
    "                                      columns=X.columns, \n",
    "                                      index=X.index)\n",
    "        else:\n",
    "            # For the same data used in fitting, use posterior samples\n",
    "            \n",
    "            # Sample from the model multiple times to get uncertainty estimates\n",
    "            w_samples = self.model.sample_loadings(n_samples=self.n_samples)  # [n_samples, n_features, n_components]\n",
    "            w_mean = w_samples.mean(dim=0).cpu().detach().numpy()  # [n_features, n_components]\n",
    "            \n",
    "            # Reconstruct data from latent variables (z)\n",
    "            X_reconstructed = np.dot(self.z, w_mean.T)  # [n_samples, n_features]\n",
    "            \n",
    "            # Inverse transform to original scale\n",
    "            X_reconstructed = self.scaler.inverse_transform(X_reconstructed)\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            X_reconstructed_df = pd.DataFrame(X_reconstructed, \n",
    "                                             columns=self.columns, \n",
    "                                             index=self.index)\n",
    "            \n",
    "            # Only replace missing values\n",
    "            for col in imputed_df.columns:\n",
    "                missing_idx = imputed_df[col].isna()\n",
    "                if missing_idx.any():\n",
    "                    imputed_df.loc[missing_idx, col] = X_reconstructed_df.loc[missing_idx, col].values\n",
    "        \n",
    "        return imputed_df\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit and transform\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pandas.DataFrame\n",
    "            Data with missing values\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        imputed_df : pandas.DataFrame\n",
    "            Data with imputed values\n",
    "        \"\"\"\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "\n",
    "\n",
    "def apply_bpca_imputation(df, columns_to_impute, validation_df=None, validation_masks=None, original_values=None, display_progress=True, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Apply Bayesian PCA imputation to patient data using PyTorch\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Patient data with missing values\n",
    "    columns_to_impute : list\n",
    "        List of column names to impute\n",
    "    validation_df : pandas.DataFrame, optional\n",
    "        Validation dataset with artificially missing values\n",
    "    validation_masks : dict, optional\n",
    "        Dictionary of masks for validation data\n",
    "    original_values : dict, optional\n",
    "        Dictionary of original values for validation\n",
    "    display_progress : bool\n",
    "        Whether to display progress\n",
    "    use_gpu : bool\n",
    "        Whether to use GPU acceleration\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    imputed_df : pandas.DataFrame\n",
    "        Data with imputed values\n",
    "    validation_results : dict, optional\n",
    "        Validation results if validation data provided\n",
    "    \"\"\"\n",
    "    # Extract relevant columns including potential predictors\n",
    "    # Use all columns except those with excessive missing values\n",
    "    threshold = 0.5  # Columns with more than 50% missing values are excluded\n",
    "    columns_to_use = [col for col in df.columns \n",
    "                      if df[col].isna().mean() < threshold]\n",
    "    \n",
    "    # Ensure all columns_to_impute are included\n",
    "    for col in columns_to_impute:\n",
    "        if col not in columns_to_use:\n",
    "            columns_to_use.append(col)\n",
    "    \n",
    "    # Extract subset of data\n",
    "    X = df[columns_to_use].copy()\n",
    "    \n",
    "    # Ensure all columns are numeric\n",
    "    for col in X.columns:\n",
    "        X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "    \n",
    "    # Initialize Bayesian PCA imputer\n",
    "    n_components = min(5, len(columns_to_use) - 1)  # Ensure n_components is valid\n",
    "    \n",
    "    # Set device based on user preference and availability\n",
    "    device = 'cuda' if use_gpu and torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Determine batch size based on data size\n",
    "    batch_size = min(64, len(X))  # Default 64, but smaller if dataset is tiny\n",
    "    \n",
    "    # Configure epochs based on data size\n",
    "    n_epochs = max(100, min(300, 10000 // len(X) + 30))  # Updated minimum to 100 epochs\n",
    "    \n",
    "    if display_progress:\n",
    "        print(f\"Starting PyTorch Bayesian PCA imputation with {n_components} components\")\n",
    "        print(f\"Using device: {device}\")\n",
    "        print(f\"Training for up to {n_epochs} epochs with batch size {batch_size}\")\n",
    "        \n",
    "        if device == 'cuda':\n",
    "            print(f\"GPU Info: {torch.cuda.get_device_name(0)}\")\n",
    "            print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "        \n",
    "    # Determine reasonable number of posterior samples based on data size\n",
    "    n_samples = 1000  # Default\n",
    "    \n",
    "    imputer = BayesianPCAImputer(\n",
    "        n_components=n_components,\n",
    "        n_samples=n_samples,\n",
    "        batch_size=batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        learning_rate=0.01,\n",
    "        device=device,\n",
    "        verbose=display_progress\n",
    "    )\n",
    "    \n",
    "    # Fit and transform with progress tracking\n",
    "    start_time = None\n",
    "    if display_progress:\n",
    "        start_time = time.time()\n",
    "        print(\"Training PyTorch Bayesian PCA imputation model...\")\n",
    "    \n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    \n",
    "    if display_progress and start_time:\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"BPCA imputation completed in {elapsed:.2f} seconds ({elapsed/60:.2f} minutes)\")\n",
    "    \n",
    "    # Create imputed dataframe\n",
    "    imputed_df = df.copy()\n",
    "    imputed_df[columns_to_impute] = X_imputed[columns_to_impute]\n",
    "    \n",
    "    # Validate if validation data provided\n",
    "    validation_results = None\n",
    "    if validation_df is not None and validation_masks is not None and original_values is not None:\n",
    "        validation_results = {}\n",
    "        validation_start_time = None\n",
    "        \n",
    "        if display_progress:\n",
    "            validation_start_time = time.time()\n",
    "            print(\"\\nStarting validation on test data...\")\n",
    "        \n",
    "        # Extract validation data\n",
    "        X_val = validation_df[columns_to_use].copy()\n",
    "        \n",
    "        # Ensure all validation columns are numeric\n",
    "        for col in X_val.columns:\n",
    "            X_val[col] = pd.to_numeric(X_val[col], errors='coerce')\n",
    "            \n",
    "        # Impute validation data\n",
    "        X_val_imputed = imputer.transform(X_val)\n",
    "        \n",
    "        # For storing overall metrics\n",
    "        all_real_vals = []\n",
    "        all_imputed_vals = []\n",
    "        column_metrics = []\n",
    "        \n",
    "        # Compare imputed values to real values\n",
    "        with tqdm(columns_to_impute, desc=\"Validating results\") as pbar:\n",
    "            for col in pbar:\n",
    "                pbar.set_description(f\"Validating {col}\")\n",
    "                # Get indices where values were artificially set to NaN\n",
    "                mask = validation_masks[col] & validation_df[col].isna()\n",
    "                \n",
    "                if mask.sum() == 0:\n",
    "                    validation_results[col] = {\n",
    "                        'error': \"No artificially missing values\"\n",
    "                    }\n",
    "                    continue\n",
    "                    \n",
    "                real_vals = original_values[col][mask]\n",
    "                imputed_vals = X_val_imputed[col][mask]\n",
    "                \n",
    "                # Collect all values for overall metrics\n",
    "                all_real_vals.extend(real_vals.values)\n",
    "                all_imputed_vals.extend(imputed_vals.values)\n",
    "                \n",
    "                # Calculate continuous metrics (MAE and RMSE) - NO ROUNDING\n",
    "                mae = mean_absolute_error(real_vals, imputed_vals)\n",
    "                rmse = np.sqrt(mean_squared_error(real_vals, imputed_vals))\n",
    "                \n",
    "                # Calculate classification metrics - WITH ROUNDING\n",
    "                real_vals_class = process_for_classification(real_vals)\n",
    "                imputed_vals_class = process_for_classification(imputed_vals)\n",
    "                \n",
    "                classification_metrics = calculate_classification_metrics(real_vals_class, imputed_vals_class)\n",
    "                \n",
    "                # Store metrics for summary\n",
    "                column_metrics.append({\n",
    "                    'column': col,\n",
    "                    'mae': mae,\n",
    "                    'rmse': rmse,\n",
    "                    'accuracy': classification_metrics['accuracy'],\n",
    "                    'count': len(real_vals)\n",
    "                })\n",
    "                \n",
    "                validation_results[col] = {\n",
    "                    'mae': mae,\n",
    "                    'rmse': rmse,\n",
    "                    'accuracy': classification_metrics['accuracy'],\n",
    "                    'auc_multiclass': classification_metrics['auc_multiclass'],\n",
    "                    'avg_sensitivity': classification_metrics['avg_sensitivity'],\n",
    "                    'avg_specificity': classification_metrics['avg_specificity'],\n",
    "                    'avg_ppv': classification_metrics['avg_ppv'],\n",
    "                    'avg_npv': classification_metrics['avg_npv'],\n",
    "                    'precision_macro': classification_metrics['precision_macro'],\n",
    "                    'recall_macro': classification_metrics['recall_macro'],\n",
    "                    'real_distribution': real_vals.describe(),\n",
    "                    'imputed_distribution': imputed_vals.describe()\n",
    "                }\n",
    "                \n",
    "                # Update progress\n",
    "                pbar.set_postfix({\"MAE\": f\"{mae:.4f}\", \"RMSE\": f\"{rmse:.4f}\", \"Acc\": f\"{classification_metrics['accuracy']:.4f}\"})\n",
    "        \n",
    "        # Calculate overall metrics\n",
    "        if all_real_vals:\n",
    "            overall_mae = mean_absolute_error(all_real_vals, all_imputed_vals)\n",
    "            overall_rmse = np.sqrt(mean_squared_error(all_real_vals, all_imputed_vals))\n",
    "            \n",
    "            validation_results['overall'] = {\n",
    "                'mae': overall_mae,\n",
    "                'rmse': overall_rmse,\n",
    "                'total_values': len(all_real_vals)\n",
    "            }\n",
    "        \n",
    "        # Print detailed summary\n",
    "        if display_progress:\n",
    "            validation_time = time.time() - validation_start_time if validation_start_time else 0\n",
    "            total_time = validation_time + (time.time() - start_time if start_time else 0)\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(f\"PYTORCH BAYESIAN PCA IMPUTATION SUMMARY (Device: {device})\")\n",
    "            print(\"=\"*80)\n",
    "            \n",
    "            # Time information\n",
    "            print(f\"\\nTIMING INFORMATION:\")\n",
    "            print(f\"  Training Time: {elapsed:.2f} seconds ({elapsed/60:.2f} minutes)\")\n",
    "            print(f\"  Validation Time: {validation_time:.2f} seconds ({validation_time/60:.2f} minutes)\")\n",
    "            print(f\"  Total Time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")\n",
    "            \n",
    "            # Overall metrics\n",
    "            if 'overall' in validation_results:\n",
    "                print(f\"\\nOVERALL METRICS (across {validation_results['overall']['total_values']} values):\")\n",
    "                print(f\"  MAE: {validation_results['overall']['mae']:.4f}\")\n",
    "                print(f\"  RMSE: {validation_results['overall']['rmse']:.4f}\")\n",
    "            \n",
    "            # Per-column metrics\n",
    "            print(\"\\nPER-COLUMN METRICS:\")\n",
    "            print(\"-\"*80)\n",
    "            print(f\"{'Column':<20} {'MAE':<10} {'RMSE':<10} {'Accuracy':<10} {'Count':<10}\")\n",
    "            print(\"-\"*80)\n",
    "            \n",
    "            for metric in sorted(column_metrics, key=lambda x: x['mae']):\n",
    "                print(f\"{metric['column']:<20} {metric['mae']:<10.4f} {metric['rmse']:<10.4f} {metric['accuracy']:<10.4f} {metric['count']:<10}\")\n",
    "            \n",
    "            print(\"=\"*80)\n",
    "    \n",
    "    return imputed_df, validation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.optim.lr_scheduler\n"
     ]
    }
   ],
   "source": [
    "import torch.optim.lr_scheduler\n",
    "print(torch.optim.lr_scheduler.ReduceLROnPlateau.__module__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PyTorch Bayesian PCA imputation with 5 components\n",
      "Using device: cuda\n",
      "Training for up to 100 epochs with batch size 64\n",
      "GPU Info: Tesla V100-SXM2-32GB\n",
      "GPU Memory: 34.1 GB\n",
      "Training PyTorch Bayesian PCA imputation model...\n",
      "⚠️ 'verbose' not supported in ReduceLROnPlateau, using fallback...\n",
      "Training Bayesian PCA model on cuda...\n",
      "Data shape: torch.Size([5230, 48]), Components: 5\n",
      "Missing values: 197141 out of 251040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 189.18it/s, Loss=2327907401728.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPCA imputation completed in 1.41 seconds (0.02 minutes)\n"
     ]
    }
   ],
   "source": [
    "# Define columns to impute\n",
    "ordinal_cols = (\n",
    "    [f\"gp{i}\" for i in range(1, 8)] + [f\"gs{i}\" for i in range(1, 8)] +\n",
    "    [f\"ge{i}\" for i in range(1, 7)] + [f\"gf{i}\" for i in range(1, 8)] +\n",
    "    [f\"a_hn{i}\" for i in range(1, 6)] + [\"a_hn7\", \"a_hn10\"] +\n",
    "    [f\"a_e{i}\" for i in range(1, 8)] + [\"a_c6\", \"a_c2\", \"a_act11\"]\n",
    ")\n",
    "columns_to_impute = ordinal_cols#['ge1', 'ge2', 'ge3', 'ge4', 'ge5', 'ge6']\n",
    "\n",
    "# Apply Transformer imputation\n",
    "imputed_df_bpca, validation_results_bpca = apply_bpca_imputation(df, columns_to_impute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1.319476\n",
       "14       1.322628\n",
       "18       1.323068\n",
       "22       1.319482\n",
       "25       1.000000\n",
       "           ...   \n",
       "18178    1.308018\n",
       "18179    1.000000\n",
       "18180    1.312157\n",
       "18181    1.312025\n",
       "18185    1.308024\n",
       "Name: ge1, Length: 5230, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_df_bpca['ge1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model - Da Xu (interview paper) DL method"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "https://www.sciencedirect.com/science/article/pii/S1532046420302045\n",
    "https://ieeexplore.ieee.org/document/9238392"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class DeepAutoencoderModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Deep Autoencoder model for missing value imputation with patient embedding\n",
    "    \n",
    "    Based on the papers:\n",
    "    - \"A Deep Learning–Based Unsupervised Method to Impute Missing Values in Patient Records\"\n",
    "    - \"A deep learning–based, unsupervised method to impute missing values in electronic health records\"\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, patient_vocab_size, embedding_dim=16, hidden_dims=(64, 32, 16, 32, 64), \n",
    "                 dropout_rate=0.2, activation='relu'):\n",
    "        \"\"\"\n",
    "        Initialize the model\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_dim : int\n",
    "            Dimension of input data\n",
    "        patient_vocab_size : int\n",
    "            Number of unique patients for embedding\n",
    "        embedding_dim : int\n",
    "            Size of patient embedding vectors\n",
    "        hidden_dims : tuple\n",
    "            Sizes of hidden layers\n",
    "        dropout_rate : float\n",
    "            Dropout rate for regularization\n",
    "        activation : str\n",
    "            Activation function ('relu' or 'elu')\n",
    "        \"\"\"\n",
    "        super(DeepAutoencoderModel, self).__init__()\n",
    "        \n",
    "        # Patient embedding layer\n",
    "        self.patient_embedding = nn.Embedding(patient_vocab_size + 1, embedding_dim)\n",
    "        \n",
    "        # Build encoder layers\n",
    "        self.encoder_layers = nn.ModuleList()\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        # Get the number of layers for encoder (half of hidden_dims rounded up)\n",
    "        encoder_size = (len(hidden_dims) + 1) // 2\n",
    "        \n",
    "        for i in range(encoder_size):\n",
    "            layer = nn.Sequential(\n",
    "                nn.Linear(prev_dim, hidden_dims[i]),\n",
    "                nn.BatchNorm1d(hidden_dims[i]),\n",
    "                nn.ReLU() if activation == 'relu' else nn.ELU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            )\n",
    "            self.encoder_layers.append(layer)\n",
    "            prev_dim = hidden_dims[i]\n",
    "        \n",
    "        # Code layer dimension (bottleneck)\n",
    "        self.code_dim = hidden_dims[encoder_size - 1]\n",
    "        \n",
    "        # Build decoder layers\n",
    "        self.decoder_layers = nn.ModuleList()\n",
    "        \n",
    "        # First decoder layer takes concatenated code and patient embedding\n",
    "        prev_dim = self.code_dim + embedding_dim\n",
    "        \n",
    "        for i in range(encoder_size, len(hidden_dims)):\n",
    "            layer = nn.Sequential(\n",
    "                nn.Linear(prev_dim, hidden_dims[i]),\n",
    "                nn.BatchNorm1d(hidden_dims[i]),\n",
    "                nn.ReLU() if activation == 'relu' else nn.ELU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            )\n",
    "            self.decoder_layers.append(layer)\n",
    "            prev_dim = hidden_dims[i]\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(prev_dim, input_dim)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        Encode input data to latent representation\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        x : torch.Tensor\n",
    "            Input data\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        torch.Tensor\n",
    "            Encoded representation\n",
    "        \"\"\"\n",
    "        h = x\n",
    "        for layer in self.encoder_layers:\n",
    "            h = layer(h)\n",
    "        return h\n",
    "    \n",
    "    def decode(self, code, patient_emb):\n",
    "        \"\"\"\n",
    "        Decode latent representation to reconstructed input\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        code : torch.Tensor\n",
    "            Encoded representation\n",
    "        patient_emb : torch.Tensor\n",
    "            Patient embedding vectors\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        torch.Tensor\n",
    "            Reconstructed input\n",
    "        \"\"\"\n",
    "        # Concatenate code and patient embedding\n",
    "        h = torch.cat([code, patient_emb], dim=1)\n",
    "        \n",
    "        for layer in self.decoder_layers:\n",
    "            h = layer(h)\n",
    "            \n",
    "        return self.output_layer(h)\n",
    "    \n",
    "    def forward(self, x, patient_ids):\n",
    "        \"\"\"\n",
    "        Forward pass through the model\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        x : torch.Tensor\n",
    "            Input data\n",
    "        patient_ids : torch.Tensor\n",
    "            Patient IDs\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        torch.Tensor\n",
    "            Reconstructed input\n",
    "        \"\"\"\n",
    "        # Get patient embeddings\n",
    "        patient_emb = self.patient_embedding(patient_ids).squeeze(1)\n",
    "        \n",
    "        # Encode input\n",
    "        code = self.encode(x)\n",
    "        \n",
    "        # Decode latent representation\n",
    "        output = self.decode(code, patient_emb)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "class MaskedMSELoss(nn.Module):\n",
    "    \"\"\"\n",
    "    MSE loss that ignores missing values\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(MaskedMSELoss, self).__init__()\n",
    "        \n",
    "    def forward(self, pred, target, mask):\n",
    "        \"\"\"\n",
    "        Calculate MSE loss only on observed values\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        pred : torch.Tensor\n",
    "            Predicted values\n",
    "        target : torch.Tensor\n",
    "            Target values\n",
    "        mask : torch.Tensor\n",
    "            Binary mask (1 for observed, 0 for missing)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        torch.Tensor\n",
    "            Masked MSE loss\n",
    "        \"\"\"\n",
    "        # Apply mask to predictions and targets\n",
    "        masked_pred = pred * mask\n",
    "        masked_target = target * mask\n",
    "        \n",
    "        # Calculate squared error\n",
    "        squared_error = (masked_pred - masked_target) ** 2\n",
    "        \n",
    "        # Sum squared error and count observed values\n",
    "        sum_squared_error = torch.sum(squared_error)\n",
    "        count = torch.sum(mask) + 1e-8  # Add small epsilon to avoid division by zero\n",
    "        \n",
    "        # Return MSE\n",
    "        return sum_squared_error / count\n",
    "\n",
    "\n",
    "class TemporalSimilarityLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Loss component for temporal similarity regularization\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(TemporalSimilarityLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, pred, patient_batch_indices):\n",
    "        \"\"\"\n",
    "        Calculate temporal similarity loss based on batch proximity\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        pred : torch.Tensor\n",
    "            Predicted values\n",
    "        patient_batch_indices : torch.Tensor\n",
    "            Indices grouping patients in the batch\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        torch.Tensor\n",
    "            Temporal similarity loss\n",
    "        \"\"\"\n",
    "        batch_size = pred.size(0)\n",
    "        \n",
    "        # If batch size is too small, return zero loss\n",
    "        if batch_size <= 1:\n",
    "            return torch.tensor(0.0, device=pred.device)\n",
    "        \n",
    "        # Create batch position indices\n",
    "        indices = torch.arange(batch_size, device=pred.device).float()\n",
    "        \n",
    "        # Expand dimensions for pairwise operations\n",
    "        pred_expanded_1 = pred.unsqueeze(1)  # [batch, 1, features]\n",
    "        pred_expanded_2 = pred.unsqueeze(0)  # [1, batch, features]\n",
    "        \n",
    "        indices_1 = indices.unsqueeze(1)  # [batch, 1]\n",
    "        indices_2 = indices.unsqueeze(0)  # [1, batch]\n",
    "        \n",
    "        # Calculate pairwise differences between predictions\n",
    "        pred_diff = torch.sum((pred_expanded_1 - pred_expanded_2) ** 2, dim=2)\n",
    "        \n",
    "        # Create patient similarity mask (1 where same patient, 0 otherwise)\n",
    "        patient_expanded_1 = patient_batch_indices.unsqueeze(1)\n",
    "        patient_expanded_2 = patient_batch_indices.unsqueeze(0)\n",
    "        patient_mask = (patient_expanded_1 == patient_expanded_2).float()\n",
    "        \n",
    "        # Create diagonal mask to exclude self-comparisons\n",
    "        diag_mask = 1.0 - torch.eye(batch_size, device=pred.device)\n",
    "        \n",
    "        # Combine masks\n",
    "        combined_mask = patient_mask * diag_mask\n",
    "        \n",
    "        # If no patient pairs exist, return zero loss\n",
    "        if torch.sum(combined_mask) == 0:\n",
    "            return torch.tensor(0.0, device=pred.device)\n",
    "        \n",
    "        # Calculate temporal similarity weights based on proximity in batch\n",
    "        # (Simple approach: closer indices = more similar)\n",
    "        temporal_diff = torch.abs(indices_1 - indices_2)\n",
    "        similarity_weights = 1.0 / (temporal_diff + 1.0)\n",
    "        \n",
    "        # Apply masks and weights\n",
    "        weighted_diff = pred_diff * similarity_weights * combined_mask\n",
    "        \n",
    "        # Normalize and return loss\n",
    "        return torch.sum(weighted_diff) / (torch.sum(combined_mask) + 1e-8)\n",
    "\n",
    "\n",
    "class DeepAutoencoderImputer:\n",
    "    \"\"\"\n",
    "    Deep Learning-Based Unsupervised Method for Missing Value Imputation\n",
    "    \n",
    "    Based on the papers:\n",
    "    - \"A Deep Learning–Based Unsupervised Method to Impute Missing Values in Patient Records\"\n",
    "    - \"A deep learning–based, unsupervised method to impute missing values in electronic health records\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 embedding_dim=16,\n",
    "                 hidden_layers=(64, 32, 16, 32, 64),\n",
    "                 activation='relu',\n",
    "                 dropout_rate=0.2,\n",
    "                 learning_rate=0.001,\n",
    "                 weight_decay=0.00001,\n",
    "                 temporal_weight=0.3,\n",
    "                 batch_size=16,\n",
    "                 epochs=100,\n",
    "                 patience=10,\n",
    "                 device=None,\n",
    "                 verbose=1):\n",
    "        \"\"\"\n",
    "        Initialize imputer\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        embedding_dim : int\n",
    "            Size of patient embedding vectors\n",
    "        hidden_layers : tuple\n",
    "            Sizes of hidden layers\n",
    "        activation : str\n",
    "            Activation function ('relu' or 'elu')\n",
    "        dropout_rate : float\n",
    "            Dropout rate for regularization\n",
    "        learning_rate : float\n",
    "            Learning rate for optimizer\n",
    "        weight_decay : float\n",
    "            L2 regularization strength\n",
    "        temporal_weight : float\n",
    "            Weight for temporal similarity regularization\n",
    "        batch_size : int\n",
    "            Batch size for training\n",
    "        epochs : int\n",
    "            Maximum number of training epochs\n",
    "        patience : int\n",
    "            Patience for early stopping\n",
    "        device : str or torch.device\n",
    "            Device to use ('cpu', 'cuda', or None for auto-detection)\n",
    "        verbose : int\n",
    "            Verbosity level (0 or 1)\n",
    "        \"\"\"\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.activation = activation\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.temporal_weight = temporal_weight\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Set device\n",
    "        if device is None:\n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        else:\n",
    "            self.device = torch.device(device)\n",
    "            \n",
    "        if self.verbose:\n",
    "            print(f\"Using device: {self.device}\")\n",
    "            \n",
    "            # Print CUDA details if using GPU\n",
    "            if self.device.type == 'cuda':\n",
    "                print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "                print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "                print(f\"CUDA capability: {torch.cuda.get_device_properties(0).major}.{torch.cuda.get_device_properties(0).minor}\")\n",
    "        \n",
    "        # Will be initialized during fitting\n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "        self.columns = None\n",
    "        self.patient_id_col = None\n",
    "        self.time_col = None\n",
    "        self.numerical_cols = []\n",
    "        self.categorical_cols = []\n",
    "        self.ordinal_cols = []\n",
    "        self.cat_encoders = {}\n",
    "        self.columns_to_impute = None\n",
    "        self.history = {'train_loss': [], 'val_loss': []}\n",
    "        \n",
    "    def fit(self, X, patient_id_col, time_col=None, numerical_cols=None, \n",
    "            categorical_cols=None, ordinal_cols=None):\n",
    "        \"\"\"\n",
    "        Fit the imputer model\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : DataFrame\n",
    "            Input data with missing values\n",
    "        patient_id_col : str\n",
    "            Name of the column containing patient IDs\n",
    "        time_col : str, optional\n",
    "            Name of the column containing time information\n",
    "        numerical_cols : list, optional\n",
    "            Names of numerical columns. If None, autodetect.\n",
    "        categorical_cols : list, optional\n",
    "            Names of categorical columns. If None, autodetect.\n",
    "        ordinal_cols : list, optional\n",
    "            Names of ordinal columns. If None, autodetect.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        self : object\n",
    "            Returns self\n",
    "        \"\"\"\n",
    "        self.original_data = X.copy()\n",
    "        self.original_columns = X.columns.tolist()\n",
    "        self.patient_id_col = patient_id_col\n",
    "        self.time_col = time_col\n",
    "        \n",
    "        # Autodetect column types if not provided\n",
    "        if numerical_cols is None:\n",
    "            numerical_cols = X.select_dtypes(include=['float', 'int']).columns.tolist()\n",
    "            # Exclude patient_id_col\n",
    "            if patient_id_col in numerical_cols:\n",
    "                numerical_cols.remove(patient_id_col)\n",
    "        self.numerical_cols = numerical_cols\n",
    "        \n",
    "        if categorical_cols is None:\n",
    "            categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "            # Exclude patient_id_col and time_col\n",
    "            if patient_id_col in categorical_cols:\n",
    "                categorical_cols.remove(patient_id_col)\n",
    "            if time_col and time_col in categorical_cols:\n",
    "                categorical_cols.remove(time_col)\n",
    "        self.categorical_cols = categorical_cols\n",
    "        \n",
    "        if ordinal_cols is None:\n",
    "            ordinal_cols = []\n",
    "        self.ordinal_cols = ordinal_cols\n",
    "        \n",
    "        # Preprocess data\n",
    "        X_processed, missing_mask, cat_indices = self._preprocess_data(X, fit=True)\n",
    "        \n",
    "        # Extract patient IDs\n",
    "        patient_ids = X[patient_id_col].values\n",
    "        \n",
    "        # Train model\n",
    "        self._train_model(X_processed, patient_ids, missing_mask)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _preprocess_data(self, X, fit=True):\n",
    "        \"\"\"\n",
    "        Preprocess data for the imputation model\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : DataFrame\n",
    "            Input data\n",
    "        fit : bool\n",
    "            Whether to fit or transform\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        tuple\n",
    "            (processed data, missing mask, categorical indices)\n",
    "        \"\"\"\n",
    "        # Make a copy of the input data\n",
    "        X_processed = X.copy()\n",
    "\n",
    "        # Track the derived date columns to avoid adding them to columns_to_impute\n",
    "        self.derived_date_cols = []\n",
    "\n",
    "        # Handle datetime column if present\n",
    "        if self.time_col and self.time_col in X.columns and pd.api.types.is_datetime64_any_dtype(X[self.time_col]):\n",
    "            # Extract features from datetime\n",
    "            date_year_col = f'{self.time_col}_year'\n",
    "            date_month_col = f'{self.time_col}_month'\n",
    "            date_day_col = f'{self.time_col}_day'\n",
    "            \n",
    "            X_processed[date_year_col] = X[self.time_col].dt.year\n",
    "            X_processed[date_month_col] = X[self.time_col].dt.month\n",
    "            X_processed[date_day_col] = X[self.time_col].dt.day\n",
    "            \n",
    "            # Store derived date columns\n",
    "            self.derived_date_cols = [date_year_col, date_month_col, date_day_col]\n",
    "            \n",
    "            # Add these new columns to numerical cols but NOT to columns_to_impute\n",
    "            if fit:\n",
    "                for col in self.derived_date_cols:\n",
    "                    if col not in self.numerical_cols:\n",
    "                        self.numerical_cols.append(col)\n",
    "                    \n",
    "            # Drop the original datetime column\n",
    "            X_processed = X_processed.drop(columns=[self.time_col])\n",
    "\n",
    "        # Create missing value mask (1 for observed, 0 for missing)\n",
    "        missing_mask = ~X_processed.isna()\n",
    "\n",
    "        # Scale numerical columns\n",
    "        if self.numerical_cols:\n",
    "            # Use only available numeric columns\n",
    "            numeric_cols_present = [col for col in self.numerical_cols if col in X_processed.columns]\n",
    "            \n",
    "            if fit:\n",
    "                self.num_scaler = StandardScaler()\n",
    "                if numeric_cols_present:\n",
    "                    # Temporarily fill missing values for scaling\n",
    "                    temp_imputer = SimpleImputer(strategy='mean')\n",
    "                    X_temp = pd.DataFrame(\n",
    "                        temp_imputer.fit_transform(X_processed[numeric_cols_present]),\n",
    "                        columns=numeric_cols_present,\n",
    "                        index=X_processed.index\n",
    "                    )\n",
    "                    \n",
    "                    # Fit scaler on non-missing data\n",
    "                    X_numerical_scaled = self.num_scaler.fit_transform(X_temp)\n",
    "                    \n",
    "                    # Update processed data with scaled values\n",
    "                    for i, col in enumerate(numeric_cols_present):\n",
    "                        X_processed[col] = X_numerical_scaled[:, i]\n",
    "            else:\n",
    "                if numeric_cols_present:\n",
    "                    # Temporarily fill missing values for scaling\n",
    "                    temp_imputer = SimpleImputer(strategy='mean')\n",
    "                    X_temp = pd.DataFrame(\n",
    "                        temp_imputer.fit_transform(X_processed[numeric_cols_present]),\n",
    "                        columns=numeric_cols_present,\n",
    "                        index=X_processed.index\n",
    "                    )\n",
    "                    \n",
    "                    # Transform with scaler\n",
    "                    X_numerical_scaled = self.num_scaler.transform(X_temp)\n",
    "                    \n",
    "                    # Update processed data with scaled values\n",
    "                    for i, col in enumerate(numeric_cols_present):\n",
    "                        X_processed[col] = X_numerical_scaled[:, i]\n",
    "\n",
    "        # Encode categorical columns\n",
    "        cat_indices = {}\n",
    "        current_idx = len(self.numerical_cols)\n",
    "\n",
    "        for col in self.categorical_cols:\n",
    "            if col in X_processed.columns:\n",
    "                # Handle categorical data safely\n",
    "                if pd.api.types.is_categorical_dtype(X_processed[col]):\n",
    "                    # Convert to string first to avoid category errors\n",
    "                    filled_col = X_processed[col].astype(str).fillna('MISSING')\n",
    "                else:\n",
    "                    # Fill NaN values with a placeholder\n",
    "                    filled_col = X_processed[col].fillna('MISSING')\n",
    "                \n",
    "                if fit:\n",
    "                    # Handle both older and newer scikit-learn versions\n",
    "                    try:\n",
    "                        # For newer scikit-learn versions\n",
    "                        encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "                    except TypeError:\n",
    "                        # For older scikit-learn versions\n",
    "                        encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "                        \n",
    "                    encoded = encoder.fit_transform(filled_col.values.reshape(-1, 1))\n",
    "                    self.cat_encoders[col] = encoder\n",
    "                else:\n",
    "                    encoder = self.cat_encoders[col]\n",
    "                    encoded = encoder.transform(filled_col.values.reshape(-1, 1))\n",
    "                \n",
    "                # Add encoded columns\n",
    "                encoded_cols = [f\"{col}_{cat}\" for cat in encoder.categories_[0]]\n",
    "                cat_indices[col] = (current_idx, current_idx + len(encoded_cols))\n",
    "                current_idx += len(encoded_cols)\n",
    "                \n",
    "                for i, encoded_col in enumerate(encoded_cols):\n",
    "                    X_processed[encoded_col] = encoded[:, i]\n",
    "                \n",
    "                # Drop original categorical column\n",
    "                X_processed = X_processed.drop(columns=[col])\n",
    "                \n",
    "                # Update missing mask for one-hot encoded columns\n",
    "                for encoded_col in encoded_cols:\n",
    "                    missing_mask[encoded_col] = missing_mask[col]\n",
    "\n",
    "        # Drop non-numeric columns and ensure all data is numeric\n",
    "        X_processed = X_processed.select_dtypes(include=[np.number])\n",
    "        missing_mask = missing_mask[X_processed.columns]\n",
    "\n",
    "        if fit:\n",
    "            self.processed_columns = X_processed.columns.tolist()\n",
    "            \n",
    "        return X_processed, missing_mask, cat_indices\n",
    "    \n",
    "    def _train_model(self, X_processed, patient_ids, missing_mask):\n",
    "        \"\"\"\n",
    "        Train the imputation model\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X_processed : DataFrame\n",
    "            Preprocessed data\n",
    "        patient_ids : ndarray\n",
    "            Patient IDs for each record\n",
    "        missing_mask : DataFrame\n",
    "            Binary mask for observed values\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Convert to numpy arrays\n",
    "        X_np = X_processed.values\n",
    "        mask_np = missing_mask.values\n",
    "        \n",
    "        # Create patient ID mapping\n",
    "        unique_patient_ids = np.unique(patient_ids)\n",
    "        patient_id_to_idx = {id_: i for i, id_ in enumerate(unique_patient_ids)}\n",
    "        \n",
    "        # Convert patient IDs to numeric indices\n",
    "        patient_indices = np.array([patient_id_to_idx.get(id_, len(patient_id_to_idx)) for id_ in patient_ids])\n",
    "        \n",
    "        # Also create a mapping from record index to patient index for temporal loss\n",
    "        record_to_patient_idx = patient_indices.copy()\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        X_tensor = torch.FloatTensor(X_np)\n",
    "        mask_tensor = torch.FloatTensor(mask_np)\n",
    "        patient_tensor = torch.LongTensor(patient_indices)\n",
    "        patient_batch_tensor = torch.LongTensor(record_to_patient_idx)\n",
    "        \n",
    "        # Create dataset and dataloader\n",
    "        dataset = TensorDataset(X_tensor, mask_tensor, patient_tensor, patient_batch_tensor)\n",
    "        \n",
    "        # Split into train and validation sets\n",
    "        train_size = int(0.8 * len(dataset))\n",
    "        val_size = len(dataset) - train_size\n",
    "        train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "            dataset, [train_size, val_size]\n",
    "        )\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=True,\n",
    "            num_workers=0 if self.device.type == 'cuda' else 2  # Use multiple workers on CPU\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=False,\n",
    "            num_workers=0 if self.device.type == 'cuda' else 2\n",
    "        )\n",
    "        \n",
    "        # Initialize model\n",
    "        input_dim = X_np.shape[1]\n",
    "        patient_vocab_size = len(unique_patient_ids)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"Building model with input dimension {input_dim} and {patient_vocab_size} unique patients\")\n",
    "            \n",
    "        self.model = DeepAutoencoderModel(\n",
    "            input_dim=input_dim,\n",
    "            patient_vocab_size=patient_vocab_size,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "            hidden_dims=self.hidden_layers,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            activation=self.activation\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Initialize loss functions\n",
    "        masked_loss_fn = MaskedMSELoss().to(self.device)\n",
    "        temporal_loss_fn = TemporalSimilarityLoss().to(self.device)\n",
    "        \n",
    "        # Initialize optimizer\n",
    "        optimizer = optim.Adam(\n",
    "            self.model.parameters(), \n",
    "            lr=self.learning_rate, \n",
    "            weight_decay=self.weight_decay\n",
    "        )\n",
    "        \n",
    "        # Initialize learning rate scheduler\n",
    "        try:\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer, \n",
    "                mode='min', \n",
    "                factor=0.5, \n",
    "                patience=self.patience // 2, \n",
    "                verbose=self.verbose\n",
    "            )\n",
    "        except TypeError:\n",
    "            print(\"⚠️ 'verbose' not supported in ReduceLROnPlateau, using fallback...\")\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer, \n",
    "                mode='min', \n",
    "                factor=0.5, \n",
    "                patience=self.patience // 2\n",
    "            )\n",
    "        \n",
    "        # Initialize early stopping variables\n",
    "        best_val_loss = float('inf')\n",
    "        best_model_state = None\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Training loop\n",
    "        if self.verbose:\n",
    "            print(f\"Starting training for {self.epochs} epochs\")\n",
    "            \n",
    "        # Use tqdm for progress tracking\n",
    "        pbar = tqdm(range(self.epochs), desc=\"Training\", disable=not self.verbose)\n",
    "        \n",
    "        for epoch in pbar:\n",
    "            # Training phase\n",
    "            self.model.train()\n",
    "            train_loss = 0.0\n",
    "            train_recon_loss = 0.0\n",
    "            train_temporal_loss = 0.0\n",
    "            batch_count = 0\n",
    "            \n",
    "            for X_batch, mask_batch, patient_batch, patient_idx_batch in train_loader:\n",
    "                # Move tensors to device\n",
    "                X_batch = X_batch.to(self.device)\n",
    "                mask_batch = mask_batch.to(self.device)\n",
    "                patient_batch = patient_batch.to(self.device)\n",
    "                patient_idx_batch = patient_idx_batch.to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                output = self.model(X_batch, patient_batch)\n",
    "                \n",
    "                # Calculate loss\n",
    "                recon_loss = masked_loss_fn(output, X_batch, mask_batch)\n",
    "                \n",
    "                if self.temporal_weight > 0:\n",
    "                    temporal_loss = temporal_loss_fn(output, patient_idx_batch)\n",
    "                    loss = recon_loss + self.temporal_weight * temporal_loss\n",
    "                else:\n",
    "                    temporal_loss = torch.tensor(0.0, device=self.device)\n",
    "                    loss = recon_loss\n",
    "                \n",
    "                # Backward pass and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Accumulate losses\n",
    "                train_loss += loss.item()\n",
    "                train_recon_loss += recon_loss.item()\n",
    "                train_temporal_loss += temporal_loss.item()\n",
    "                batch_count += 1\n",
    "            \n",
    "            # Calculate average training losses\n",
    "            avg_train_loss = train_loss / batch_count\n",
    "            avg_train_recon_loss = train_recon_loss / batch_count\n",
    "            avg_train_temporal_loss = train_temporal_loss / batch_count\n",
    "            \n",
    "            # Validation phase\n",
    "            self.model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_batch_count = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for X_batch, mask_batch, patient_batch, patient_idx_batch in val_loader:\n",
    "                    # Move tensors to device\n",
    "                    X_batch = X_batch.to(self.device)\n",
    "                    mask_batch = mask_batch.to(self.device)\n",
    "                    patient_batch = patient_batch.to(self.device)\n",
    "                    patient_idx_batch = patient_idx_batch.to(self.device)\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    output = self.model(X_batch, patient_batch)\n",
    "                    \n",
    "                    # Calculate loss\n",
    "                    recon_loss = masked_loss_fn(output, X_batch, mask_batch)\n",
    "                    \n",
    "                    if self.temporal_weight > 0:\n",
    "                        temporal_loss = temporal_loss_fn(output, patient_idx_batch)\n",
    "                        loss = recon_loss + self.temporal_weight * temporal_loss\n",
    "                    else:\n",
    "                        loss = recon_loss\n",
    "                    \n",
    "                    # Accumulate loss\n",
    "                    val_loss += loss.item()\n",
    "                    val_batch_count += 1\n",
    "            \n",
    "            # Calculate average validation loss\n",
    "            avg_val_loss = val_loss / val_batch_count\n",
    "            \n",
    "            # Update learning rate scheduler\n",
    "            scheduler.step(avg_val_loss)\n",
    "            \n",
    "            # Update history\n",
    "            self.history['train_loss'].append(avg_train_loss)\n",
    "            self.history['val_loss'].append(avg_val_loss)\n",
    "            \n",
    "            # Update progress bar\n",
    "            if self.verbose:\n",
    "                pbar.set_postfix({\n",
    "                    \"train_loss\": f\"{avg_train_loss:.4f}\",\n",
    "                    \"val_loss\": f\"{avg_val_loss:.4f}\",\n",
    "                    \"recon\": f\"{avg_train_recon_loss:.4f}\",\n",
    "                    \"temporal\": f\"{avg_train_temporal_loss:.4f}\"\n",
    "                })\n",
    "            \n",
    "            # Check for early stopping\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                best_model_state = self.model.state_dict()\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= self.patience:\n",
    "                    if self.verbose:\n",
    "                        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                    break\n",
    "        \n",
    "        # Load best model\n",
    "        if best_model_state is not None:\n",
    "            self.model.load_state_dict(best_model_state)\n",
    "            \n",
    "        # Return model to evaluation mode\n",
    "        self.model.eval()\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Impute missing values using trained model\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : DataFrame\n",
    "            Input data with missing values\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        DataFrame\n",
    "            Data with imputed values\n",
    "        \"\"\"\n",
    "        # Check if model is trained\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained. Call fit() first.\")\n",
    "        \n",
    "        # Make a copy of the input data\n",
    "        X_imputed = X.copy()\n",
    "        \n",
    "        # Preprocess data\n",
    "        X_processed, missing_mask, cat_indices = self._preprocess_data(X, fit=False)\n",
    "        \n",
    "        # Get patient IDs\n",
    "        patient_ids = X[self.patient_id_col].values\n",
    "        \n",
    "        # Create patient ID mapping\n",
    "        unique_patient_ids = np.unique(self.original_data[self.patient_id_col])\n",
    "        patient_id_to_idx = {id_: i for i, id_ in enumerate(unique_patient_ids)}\n",
    "        \n",
    "        # Convert patient IDs to numeric indices (with fallback for unseen patients)\n",
    "        patient_indices = np.array([patient_id_to_idx.get(id_, len(patient_id_to_idx)) for id_ in patient_ids])\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        X_tensor = torch.FloatTensor(X_processed.values).to(self.device)\n",
    "        patient_tensor = torch.LongTensor(patient_indices).to(self.device)\n",
    "        \n",
    "        # Perform imputation in batches to avoid memory issues\n",
    "        batch_size = self.batch_size * 2  # Use larger batch size for inference\n",
    "        n_samples = X_tensor.shape[0]\n",
    "        imputed_data = np.zeros_like(X_tensor.cpu().numpy())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(0, n_samples, batch_size):\n",
    "                end_idx = min(i + batch_size, n_samples)\n",
    "                batch_X = X_tensor[i:end_idx]\n",
    "                batch_patient = patient_tensor[i:end_idx]\n",
    "                \n",
    "                # Get model predictions\n",
    "                batch_output = self.model(batch_X, batch_patient)\n",
    "                \n",
    "                # Store predictions\n",
    "                imputed_data[i:end_idx] = batch_output.cpu().numpy()\n",
    "        \n",
    "        # Convert back to DataFrame\n",
    "        imputed_df = pd.DataFrame(imputed_data, columns=X_processed.columns, index=X_processed.index)\n",
    "        \n",
    "        # Handle numerical columns\n",
    "        for col in self.numerical_cols:\n",
    "            if col in X.columns and not col.startswith(f'{self.time_col}_'):\n",
    "                # Get mask for missing values in original data\n",
    "                missing_indices = X[col].isna()\n",
    "                \n",
    "                if missing_indices.any():\n",
    "                    # Only update missing values\n",
    "                    # If column is in columns_to_impute, round to nearest integer\n",
    "                    if self.columns_to_impute and col in self.columns_to_impute:\n",
    "                        X_imputed.loc[missing_indices, col] = np.round(\n",
    "                            imputed_df.loc[missing_indices, col].values\n",
    "                        )\n",
    "                    else:\n",
    "                        X_imputed.loc[missing_indices, col] = imputed_df.loc[missing_indices, col].values\n",
    "        \n",
    "        # Handle categorical columns (need to convert one-hot back to original categories)\n",
    "        for col in self.categorical_cols:\n",
    "            if col in X.columns:\n",
    "                missing_indices = X[col].isna()\n",
    "                \n",
    "                if missing_indices.any() and col in cat_indices:\n",
    "                    # Get the one-hot encoded columns for this categorical variable\n",
    "                    start_idx, end_idx = cat_indices[col]\n",
    "                    encoded_cols = self.processed_columns[start_idx:end_idx]\n",
    "                    \n",
    "                    # Get indices where values are missing\n",
    "                    missing_idx = missing_indices[missing_indices].index\n",
    "                    \n",
    "                    # Extract one-hot encoded values for the missing entries\n",
    "                    one_hot_values = imputed_df.loc[missing_idx, encoded_cols].values\n",
    "                    \n",
    "                    # Get the index of the max value along axis 1\n",
    "                    max_indices = np.argmax(one_hot_values, axis=1)\n",
    "                    \n",
    "                    # Map back to original categories\n",
    "                    categories = self.cat_encoders[col].categories_[0]\n",
    "                    imputed_categories = [categories[idx] for idx in max_indices]\n",
    "                    \n",
    "                    # Handle categorical data types safely\n",
    "                    if pd.api.types.is_categorical_dtype(X[col]):\n",
    "                        # Get the existing categories\n",
    "                        existing_cats = X[col].cat.categories\n",
    "                        \n",
    "                        # Filter out categories that aren't in the existing ones\n",
    "                        valid_categories = []\n",
    "                        for cat in imputed_categories:\n",
    "                            if cat in existing_cats:\n",
    "                                valid_categories.append(cat)\n",
    "                            else:\n",
    "                                # Use the most common category as fallback\n",
    "                                most_common = X[col].value_counts().index[0]\n",
    "                                valid_categories.append(most_common)\n",
    "                        \n",
    "                        # Update missing values\n",
    "                        for idx, cat in zip(missing_idx, valid_categories):\n",
    "                            X_imputed.loc[idx, col] = cat\n",
    "                    else:\n",
    "                        # Update missing values in the original DataFrame\n",
    "                        X_imputed.loc[missing_idx, col] = imputed_categories\n",
    "        \n",
    "        return X_imputed\n",
    "    \n",
    "    def fit_transform(self, X, patient_id_col, time_col=None, numerical_cols=None, \n",
    "                     categorical_cols=None, ordinal_cols=None):\n",
    "        \"\"\"\n",
    "        Fit the model and impute missing values\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : DataFrame\n",
    "            Input data with missing values\n",
    "        patient_id_col : str\n",
    "            Name of the column containing patient IDs\n",
    "        time_col : str, optional\n",
    "            Name of the column containing time information\n",
    "        numerical_cols : list, optional\n",
    "            Names of numerical columns. If None, autodetect.\n",
    "        categorical_cols : list, optional\n",
    "            Names of categorical columns. If None, autodetect.\n",
    "        ordinal_cols : list, optional\n",
    "            Names of ordinal columns. If None, autodetect.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        DataFrame\n",
    "            Data with imputed values\n",
    "        \"\"\"\n",
    "        self.fit(X, patient_id_col, time_col, numerical_cols, categorical_cols, ordinal_cols)\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def plot_loss(self):\n",
    "        \"\"\"\n",
    "        Plot the training and validation loss curves\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        matplotlib figure\n",
    "            Loss curve plot\n",
    "        \"\"\"\n",
    "        if not self.history['train_loss']:\n",
    "            raise ValueError(\"Model has not been trained yet. Call fit() first.\")\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.history['train_loss'], label='Training Loss')\n",
    "        plt.plot(self.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Deep Autoencoder Imputation Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        return plt\n",
    "\n",
    "\n",
    "def apply_deep_autoencoder_imputation(df, columns_to_impute, validation_df=None, validation_masks=None, original_values=None, \n",
    "                                     hidden_layers=(64, 32, 16, 32, 64), latent_dim=8, batch_size=16, epochs=100, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Apply deep autoencoder imputation to data with an interface matching your VAE implementation\n",
    "    \n",
    "        Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Data with missing values\n",
    "    columns_to_impute : list\n",
    "        List of column names to impute\n",
    "    validation_df : pandas.DataFrame, optional\n",
    "        Validation dataset with artificially missing values\n",
    "    validation_masks : dict, optional\n",
    "        Dictionary of masks for validation data\n",
    "    original_values : dict, optional\n",
    "        Dictionary of original values for validation\n",
    "    hidden_layers : tuple\n",
    "        Sizes of hidden layers\n",
    "    latent_dim : int\n",
    "        Dimension of the patient embedding (equivalent to latent_dim in VAE)\n",
    "    batch_size : int\n",
    "        Batch size for training\n",
    "    epochs : int\n",
    "        Number of training epochs\n",
    "    learning_rate : float\n",
    "        Learning rate for optimizer\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    imputed_df : pandas.DataFrame\n",
    "        Data with imputed values\n",
    "    validation_results : dict, optional\n",
    "        Validation results if validation data provided\n",
    "    \"\"\"\n",
    "    # Print column information\n",
    "    print(f\"Data has {len(df)} rows and {len(df.columns)} columns\")\n",
    "    print(f\"Columns to impute: {columns_to_impute}\")\n",
    "\n",
    "    # IMPORTANT: Make a copy of columns_to_impute to avoid modifying the original list\n",
    "    local_columns_to_impute = [col for col in columns_to_impute if col in df.columns]\n",
    "\n",
    "    # Remove any date-derived columns that might have been added from a previous run\n",
    "    date_derived_cols = [col for col in columns_to_impute if col.startswith('qol_date_')]\n",
    "    if date_derived_cols:\n",
    "        print(f\"Warning: Date-derived columns found in columns_to_impute: {date_derived_cols}\")\n",
    "        print(f\"These will not be used for imputation.\")\n",
    "        for col in date_derived_cols:\n",
    "            if col in local_columns_to_impute:\n",
    "                local_columns_to_impute.remove(col)\n",
    "\n",
    "    # Print missingness information\n",
    "    print(\"\\nMissingness rates in columns to impute:\")\n",
    "    for col in local_columns_to_impute:\n",
    "        if col in df.columns:\n",
    "            miss_rate = df[col].isna().mean() * 100\n",
    "            print(f\"{col}: {miss_rate:.2f}%\")\n",
    "        else:\n",
    "            print(f\"{col}: column not found in data\")\n",
    "\n",
    "    # Extract relevant columns including potential predictors\n",
    "    # Use all columns except those with excessive missing values\n",
    "    threshold = 0.5  # Columns with more than 50% missing values are excluded\n",
    "    columns_to_use = [col for col in df.columns \n",
    "                    if df[col].isna().mean() < threshold]\n",
    "\n",
    "    # Ensure all columns_to_impute are included\n",
    "    for col in local_columns_to_impute:\n",
    "        if col not in columns_to_use and col in df.columns:\n",
    "            columns_to_use.append(col)\n",
    "            \n",
    "    # Always include id and qol_date if available\n",
    "    id_col = 'id'\n",
    "    if id_col not in columns_to_use and id_col in df.columns:\n",
    "        columns_to_use.append(id_col)\n",
    "        \n",
    "    time_col = 'qol_date'\n",
    "    if time_col not in columns_to_use and time_col in df.columns:\n",
    "        columns_to_use.append(time_col)\n",
    "\n",
    "    print(f\"\\nUsing {len(columns_to_use)} columns for imputation model\")\n",
    "\n",
    "    # Extract subset of data\n",
    "    X = df[columns_to_use].copy()\n",
    "\n",
    "    # Ensure all columns to impute are numeric\n",
    "    print(\"\\nConverting columns to numeric...\")\n",
    "    with tqdm(local_columns_to_impute) as pbar:\n",
    "        for col in pbar:\n",
    "            pbar.set_description(f\"Processing {col}\")\n",
    "            if col in X.columns:\n",
    "                # Convert to numeric if possible\n",
    "                X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "    # Check CUDA availability\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Initialize deep autoencoder imputer\n",
    "    print(\"\\nInitializing deep autoencoder imputer...\")\n",
    "    imputer = DeepAutoencoderImputer(\n",
    "        embedding_dim=latent_dim,\n",
    "        hidden_layers=hidden_layers,\n",
    "        activation='elu',\n",
    "        dropout_rate=0.3,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=0.0001,\n",
    "        temporal_weight=0.4,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        patience=20,\n",
    "        device=device,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Store the columns to impute in the imputer object\n",
    "    imputer.columns_to_impute = local_columns_to_impute\n",
    "\n",
    "    # Fit and transform\n",
    "    print(\"\\nTraining deep autoencoder imputation model...\")\n",
    "    X_imputed = imputer.fit_transform(\n",
    "        X, \n",
    "        patient_id_col=id_col,  # Use 'id' as the patient ID column\n",
    "        time_col=\"qol_date\",  # Use qol_date for temporal information\n",
    "        numerical_cols=local_columns_to_impute  # Only specify columns to impute as numerical\n",
    "    )\n",
    "\n",
    "    # Create imputed dataframe\n",
    "    print(\"\\nCreating final imputed dataframe...\")\n",
    "    imputed_df = df.copy()\n",
    "\n",
    "    # Copy imputed values to the output dataframe\n",
    "    for col in local_columns_to_impute:\n",
    "        if col in X_imputed.columns and col in imputed_df.columns:\n",
    "            # Get mask for missing values in the original data\n",
    "            missing_mask = df[col].isna()\n",
    "            # Only update missing values\n",
    "            imputed_df.loc[missing_mask, col] = X_imputed.loc[missing_mask, col]\n",
    "\n",
    "    # Print post-imputation statistics\n",
    "    print(\"\\nPost-imputation statistics:\")\n",
    "    for col in local_columns_to_impute:\n",
    "        if col in imputed_df.columns:\n",
    "            # Count originally missing values that have been imputed\n",
    "            missing_before = df[col].isna().sum()\n",
    "            missing_after = imputed_df[col].isna().sum()\n",
    "            num_imputed = missing_before - missing_after\n",
    "            print(f\"{col}: {num_imputed} values imputed\")\n",
    "\n",
    "    # Validate if validation data provided\n",
    "    validation_results = None\n",
    "    if validation_df is not None and validation_masks is not None and original_values is not None:\n",
    "        validation_results = {}\n",
    "        \n",
    "        print(\"\\nPerforming validation on held-out data...\")\n",
    "        \n",
    "        # Extract validation data\n",
    "        X_val = validation_df[columns_to_use].copy()\n",
    "        \n",
    "        # Ensure all validation columns are numeric\n",
    "        for col in X_val.columns:\n",
    "            if col in local_columns_to_impute:\n",
    "                X_val[col] = pd.to_numeric(X_val[col], errors='coerce')\n",
    "            \n",
    "        # Impute validation data\n",
    "        print(\"Imputing validation data...\")\n",
    "        X_val_imputed = imputer.transform(X_val)\n",
    "        \n",
    "        # Compare imputed values to real values\n",
    "        print(\"Calculating validation metrics...\")\n",
    "        with tqdm(local_columns_to_impute, desc=\"Validating results\") as pbar:\n",
    "            for col in pbar:\n",
    "                pbar.set_description(f\"Validating {col}\")\n",
    "                # Get indices where values were artificially set to NaN\n",
    "                if col not in validation_masks:\n",
    "                    validation_results[col] = {\n",
    "                        'error': f\"Column {col} not found in validation masks\"\n",
    "                    }\n",
    "                    continue\n",
    "                    \n",
    "                mask = validation_masks[col] & validation_df[col].isna()\n",
    "                \n",
    "                if mask.sum() == 0:\n",
    "                    validation_results[col] = {\n",
    "                        'error': \"No artificially missing values\"\n",
    "                    }\n",
    "                    continue\n",
    "                \n",
    "                if col not in original_values:\n",
    "                    validation_results[col] = {\n",
    "                        'error': f\"Column {col} not found in original values\"\n",
    "                    }\n",
    "                    continue\n",
    "                    \n",
    "                real_vals = original_values[col][mask]\n",
    "                \n",
    "                if col not in X_val_imputed.columns:\n",
    "                    validation_results[col] = {\n",
    "                        'error': f\"Column {col} not found in imputed values\"\n",
    "                    }\n",
    "                    continue\n",
    "                    \n",
    "                imputed_vals = X_val_imputed.loc[mask, col]\n",
    "                \n",
    "                # Calculate continuous metrics (MAE and RMSE) - NO ROUNDING\n",
    "                mae = mean_absolute_error(real_vals, imputed_vals)\n",
    "                rmse = np.sqrt(mean_squared_error(real_vals, imputed_vals))\n",
    "                \n",
    "                # Calculate classification metrics - WITH ROUNDING\n",
    "                real_vals_class = process_for_classification(real_vals)\n",
    "                imputed_vals_class = process_for_classification(imputed_vals)\n",
    "                \n",
    "                classification_metrics = calculate_classification_metrics(real_vals_class, imputed_vals_class)\n",
    "                \n",
    "                validation_results[col] = {\n",
    "                    'mae': mae,\n",
    "                    'rmse': rmse,\n",
    "                    'accuracy': classification_metrics['accuracy'],\n",
    "                    'auc_multiclass': classification_metrics['auc_multiclass'],\n",
    "                    'avg_sensitivity': classification_metrics['avg_sensitivity'],\n",
    "                    'avg_specificity': classification_metrics['avg_specificity'],\n",
    "                    'avg_ppv': classification_metrics['avg_ppv'],\n",
    "                    'avg_npv': classification_metrics['avg_npv'],\n",
    "                    'precision_macro': classification_metrics['precision_macro'],\n",
    "                    'recall_macro': classification_metrics['recall_macro'],\n",
    "                    'real_distribution': real_vals.describe(),\n",
    "                    'imputed_distribution': pd.Series(imputed_vals).describe()\n",
    "                }\n",
    "                \n",
    "                # Update progress\n",
    "                pbar.set_postfix({\"MAE\": f\"{mae:.4f}\", \"RMSE\": f\"{rmse:.4f}\", \"Acc\": f\"{classification_metrics['accuracy']:.4f}\"})\n",
    "\n",
    "    print(f\"\\nTraining loss plot saved to deep_autoencoder_loss.png\")\n",
    "    print(\"\\nImputation complete!\")\n",
    "\n",
    "    return imputed_df, validation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has 5230 rows and 62 columns\n",
      "Columns to impute: ['gp1', 'gp2', 'gp3', 'gp4', 'gp5', 'gp6', 'gp7', 'gs1', 'gs2', 'gs3', 'gs4', 'gs5', 'gs6', 'gs7', 'ge1', 'ge2', 'ge3', 'ge4', 'ge5', 'ge6', 'gf1', 'gf2', 'gf3', 'gf4', 'gf5', 'gf6', 'gf7', 'a_hn1', 'a_hn2', 'a_hn3', 'a_hn4', 'a_hn5', 'a_hn7', 'a_hn10', 'a_e1', 'a_e2', 'a_e3', 'a_e4', 'a_e5', 'a_e6', 'a_e7', 'a_c6', 'a_c2', 'a_act11']\n",
      "\n",
      "Missingness rates in columns to impute:\n",
      "gp1: 79.87%\n",
      "gp2: 79.89%\n",
      "gp3: 80.31%\n",
      "gp4: 80.02%\n",
      "gp5: 83.15%\n",
      "gp6: 80.19%\n",
      "gp7: 80.27%\n",
      "gs1: 80.23%\n",
      "gs2: 80.04%\n",
      "gs3: 80.25%\n",
      "gs4: 81.30%\n",
      "gs5: 80.94%\n",
      "gs6: 81.72%\n",
      "gs7: 88.45%\n",
      "ge1: 79.89%\n",
      "ge2: 80.52%\n",
      "ge3: 81.24%\n",
      "ge4: 80.15%\n",
      "ge5: 80.21%\n",
      "ge6: 80.11%\n",
      "gf1: 80.44%\n",
      "gf2: 81.11%\n",
      "gf3: 80.06%\n",
      "gf4: 80.75%\n",
      "gf5: 80.04%\n",
      "gf6: 80.31%\n",
      "gf7: 80.13%\n",
      "a_hn1: 80.48%\n",
      "a_hn2: 80.71%\n",
      "a_hn3: 80.92%\n",
      "a_hn4: 80.94%\n",
      "a_hn5: 80.82%\n",
      "a_hn7: 80.80%\n",
      "a_hn10: 80.73%\n",
      "a_e1: 80.23%\n",
      "a_e2: 80.21%\n",
      "a_e3: 80.11%\n",
      "a_e4: 80.21%\n",
      "a_e5: 80.33%\n",
      "a_e6: 80.55%\n",
      "a_e7: 80.17%\n",
      "a_c6: 80.23%\n",
      "a_c2: 80.21%\n",
      "a_act11: 80.13%\n",
      "\n",
      "Using 49 columns for imputation model\n",
      "\n",
      "Converting columns to numeric...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing a_act11: 100%|███████████████████████████████████████████████████████████████████████████| 44/44 [00:00<00:00, 1269.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing deep autoencoder imputer...\n",
      "Using device: cuda\n",
      "CUDA device: Tesla V100-SXM2-32GB\n",
      "CUDA memory: 34.07 GB\n",
      "CUDA capability: 7.0\n",
      "\n",
      "Training deep autoencoder imputation model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with input dimension 72 and 1754 unique patients\n",
      "⚠️ 'verbose' not supported in ReduceLROnPlateau, using fallback...\n",
      "Starting training for 100 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|████████▎| 92/100 [02:19<00:12,  1.52s/it, train_loss=1351.3050, val_loss=206.1499, recon=1100.1293, temporal=627.9392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 93\n",
      "\n",
      "Creating final imputed dataframe...\n",
      "\n",
      "Post-imputation statistics:\n",
      "gp1: 4177 values imputed\n",
      "gp2: 4178 values imputed\n",
      "gp3: 4200 values imputed\n",
      "gp4: 4185 values imputed\n",
      "gp5: 4349 values imputed\n",
      "gp6: 4194 values imputed\n",
      "gp7: 4198 values imputed\n",
      "gs1: 4196 values imputed\n",
      "gs2: 4186 values imputed\n",
      "gs3: 4197 values imputed\n",
      "gs4: 4252 values imputed\n",
      "gs5: 4233 values imputed\n",
      "gs6: 4274 values imputed\n",
      "gs7: 4626 values imputed\n",
      "ge1: 4178 values imputed\n",
      "ge2: 4211 values imputed\n",
      "ge3: 4249 values imputed\n",
      "ge4: 4192 values imputed\n",
      "ge5: 4195 values imputed\n",
      "ge6: 4190 values imputed\n",
      "gf1: 4207 values imputed\n",
      "gf2: 4242 values imputed\n",
      "gf3: 4187 values imputed\n",
      "gf4: 4223 values imputed\n",
      "gf5: 4186 values imputed\n",
      "gf6: 4200 values imputed\n",
      "gf7: 4191 values imputed\n",
      "a_hn1: 4209 values imputed\n",
      "a_hn2: 4221 values imputed\n",
      "a_hn3: 4232 values imputed\n",
      "a_hn4: 4233 values imputed\n",
      "a_hn5: 4227 values imputed\n",
      "a_hn7: 4226 values imputed\n",
      "a_hn10: 4222 values imputed\n",
      "a_e1: 4196 values imputed\n",
      "a_e2: 4195 values imputed\n",
      "a_e3: 4190 values imputed\n",
      "a_e4: 4195 values imputed\n",
      "a_e5: 4201 values imputed\n",
      "a_e6: 4213 values imputed\n",
      "a_e7: 4193 values imputed\n",
      "a_c6: 4196 values imputed\n",
      "a_c2: 4195 values imputed\n",
      "a_act11: 4191 values imputed\n",
      "\n",
      "Training loss plot saved to deep_autoencoder_loss.png\n",
      "\n",
      "Imputation complete!\n"
     ]
    }
   ],
   "source": [
    "ordinal_cols = (\n",
    "    [f\"gp{i}\" for i in range(1, 8)] + [f\"gs{i}\" for i in range(1, 8)] +\n",
    "    [f\"ge{i}\" for i in range(1, 7)] + [f\"gf{i}\" for i in range(1, 8)] +\n",
    "    [f\"a_hn{i}\" for i in range(1, 6)] + [\"a_hn7\", \"a_hn10\"] +\n",
    "    [f\"a_e{i}\" for i in range(1, 8)] + [\"a_c6\", \"a_c2\", \"a_act11\"]\n",
    ")\n",
    "columns_to_impute = ordinal_cols#['ge1', 'ge2', 'ge3', 'ge4', 'ge5', 'ge6']\n",
    "# Apply deep autoencoder imputation with explicit column specifications\n",
    "imputed_df, validation_results = apply_deep_autoencoder_imputation(\n",
    "    df=df, \n",
    "    columns_to_impute=columns_to_impute\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model - Softimpute"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "https://github.com/travisbrady/py-soft-impute/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Travis Brady's SoftImpute implementation to your code\n",
    "def frob(Uold, Dsqold, Vold, U, Dsq, V):\n",
    "    denom = (Dsqold ** 2).sum()\n",
    "    utu = Dsq * (U.T.dot(Uold))\n",
    "    vtv = Dsqold * (Vold.T.dot(V))\n",
    "    uvprod = utu.dot(vtv).diagonal().sum()\n",
    "    num = denom + (Dsqold ** 2).sum() - 2*uvprod\n",
    "    return num / max(denom, 1e-9)\n",
    "\n",
    "\n",
    "class SoftImpute:\n",
    "    def __init__(self, J=2, thresh=1e-05, lambda_=0, maxit=100, random_state=None, verbose=False):\n",
    "        self.J = J\n",
    "        self.thresh = thresh\n",
    "        self.lambda_ = lambda_\n",
    "        self.maxit = maxit\n",
    "        self.rs = np.random.RandomState(random_state)\n",
    "        self.verbose = verbose\n",
    "        self.u = None\n",
    "        self.d = None\n",
    "        self.v = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        n, m = X.shape\n",
    "        xnas = np.isnan(X)\n",
    "        nz = m*n - xnas.sum()\n",
    "        xfill = X.copy()\n",
    "        V = np.zeros((m, self.J))\n",
    "        U = self.rs.normal(0.0, 1.0, (n, self.J))\n",
    "        U, _, _ = np.linalg.svd(U, full_matrices=False)\n",
    "        Dsq = np.ones((self.J, 1))\n",
    "        #xfill[xnas] = 0.0\n",
    "        col_means = np.nanmean(xfill, axis=0)\n",
    "        np.copyto(xfill, col_means, where=np.isnan(xfill))\n",
    "        ratio = 1.0\n",
    "        iters = 0\n",
    "        while ratio > self.thresh and iters < self.maxit:\n",
    "            iters += 1\n",
    "            U_old = U\n",
    "            V_old = V\n",
    "            Dsq_old = Dsq\n",
    "            B = U.T.dot(xfill)\n",
    "            if self.lambda_ > 0:\n",
    "                tmp = (Dsq / (Dsq + self.lambda_))\n",
    "                B = B * tmp\n",
    "            Bsvd = np.linalg.svd(B.T, full_matrices=False)\n",
    "            V = Bsvd[0]\n",
    "            Dsq = Bsvd[1][:, np.newaxis]\n",
    "            U = U.dot(Bsvd[2])\n",
    "            tmp = Dsq * V.T\n",
    "            xhat = U.dot(tmp)\n",
    "            xfill[xnas] = xhat[xnas]\n",
    "            A = xfill.dot(V).T\n",
    "            Asvd = np.linalg.svd(A.T, full_matrices=False)\n",
    "            U = Asvd[0]\n",
    "            Dsq = Asvd[1][:, np.newaxis]\n",
    "            V = V.dot(Asvd[2])\n",
    "            tmp = Dsq * V.T\n",
    "            xhat = U.dot(tmp)\n",
    "            xfill[xnas] = xhat[xnas]\n",
    "            ratio = frob(U_old, Dsq_old, V_old, U, Dsq, V)\n",
    "            if self.verbose:\n",
    "                print('iter: %4d ratio = %.5f' % (iters, ratio))\n",
    "        self.u = U[:, :self.J]\n",
    "        self.d = Dsq[:self.J]\n",
    "        self.v = V[:, :self.J]\n",
    "        return self\n",
    "\n",
    "    def suv(self, vd):\n",
    "        res = self.u.dot(vd.T)\n",
    "        return res\n",
    "\n",
    "    def predict(self, X, copyto=False):\n",
    "        vd = self.v * np.outer(np.ones(self.v.shape[0]), self.d)\n",
    "        X_imp = self.suv(vd)\n",
    "        if copyto:\n",
    "            np.copyto(X, X_imp, where=np.isnan(X))\n",
    "        else:\n",
    "            return X_imp\n",
    "\n",
    "\n",
    "def apply_softimpute_imputation(df, columns_to_impute, validation_df=None, validation_masks=None, original_values=None,\n",
    "                               J=None, thresh=1e-05, lambda_=0, maxit=100, random_state=42):\n",
    "    \"\"\"\n",
    "    Apply SoftImpute imputation using Travis Brady's implementation\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Data with missing values\n",
    "    columns_to_impute : list\n",
    "        List of column names to impute\n",
    "    validation_df : pandas.DataFrame, optional\n",
    "        Validation dataset with artificially missing values\n",
    "    validation_masks : dict, optional\n",
    "        Dictionary of masks for validation data\n",
    "    original_values : dict, optional\n",
    "        Dictionary of original values for validation\n",
    "    J : int, optional\n",
    "        Number of factors/rank. If None, will be estimated\n",
    "    thresh : float\n",
    "        Convergence threshold\n",
    "    lambda_ : float\n",
    "        Regularization parameter\n",
    "    maxit : int\n",
    "        Maximum number of iterations\n",
    "    random_state : int\n",
    "        Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    imputed_df : pandas.DataFrame\n",
    "        Data with imputed values\n",
    "    validation_results : dict, optional\n",
    "        Validation results if validation data provided\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract relevant columns including potential predictors\n",
    "        # Use all columns except those with excessive missing values\n",
    "        threshold = 0.5  # Columns with more than 50% missing values are excluded\n",
    "        columns_to_use = [col for col in df.columns \n",
    "                            if df[col].isna().mean() < threshold]\n",
    "        \n",
    "        # Ensure all columns_to_impute are included\n",
    "        for col in columns_to_impute:\n",
    "            if col not in columns_to_use:\n",
    "                columns_to_use.append(col)\n",
    "        \n",
    "        # Extract subset of data\n",
    "        X = df[columns_to_use].copy()\n",
    "        \n",
    "        # Ensure all columns are numeric\n",
    "        for col in X.columns:\n",
    "            X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "        \n",
    "        print(f\"SoftImpute (Travis Brady): Using {len(columns_to_use)} columns, imputing {len(columns_to_impute)} columns\")\n",
    "        \n",
    "        # Set J (rank) if not provided\n",
    "        if J is None:\n",
    "            J = min(X.shape[0], X.shape[1]) // 4\n",
    "            J = max(2, J)  # Ensure at least rank 2\n",
    "        \n",
    "        print(f\"SoftImpute parameters: J={J}, thresh={thresh}, lambda_={lambda_}, maxit={maxit}\")\n",
    "        \n",
    "        # Scale the data for better numerical stability\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        # Initial imputation with column means for scaling\n",
    "        X_for_scaling = X.copy()\n",
    "        for col in X_for_scaling.columns:\n",
    "            X_for_scaling[col] = X_for_scaling[col].fillna(X_for_scaling[col].mean())\n",
    "        \n",
    "        # Fit scaler and transform\n",
    "        X_scaled = pd.DataFrame(\n",
    "            scaler.fit_transform(X_for_scaling),\n",
    "            columns=X.columns,\n",
    "            index=X.index\n",
    "        )\n",
    "        \n",
    "        # Restore NaN values in scaled data\n",
    "        X_scaled[X.isna()] = np.nan\n",
    "        \n",
    "        # Initialize SoftImpute\n",
    "        imputer = SoftImpute(\n",
    "            J=J,\n",
    "            thresh=thresh,\n",
    "            lambda_=lambda_,\n",
    "            maxit=maxit,\n",
    "            random_state=random_state,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # Fit and predict\n",
    "        print(\"Training SoftImpute imputation model...\")\n",
    "        imputer.fit(X_scaled.values)\n",
    "        X_imputed_scaled = imputer.predict(X_scaled.values)\n",
    "        \n",
    "        # Inverse transform to original scale\n",
    "        X_imputed = pd.DataFrame(\n",
    "            scaler.inverse_transform(X_imputed_scaled),\n",
    "            columns=X.columns,\n",
    "            index=X.index\n",
    "        )\n",
    "        \n",
    "        # Create imputed dataframe - only replace missing values\n",
    "        imputed_df = df.copy()\n",
    "        for col in columns_to_impute:\n",
    "            if col in X_imputed.columns:\n",
    "                missing_mask = df[col].isna()\n",
    "                imputed_df.loc[missing_mask, col] = X_imputed.loc[missing_mask, col]\n",
    "        \n",
    "        # Validate if validation data provided\n",
    "        validation_results = None\n",
    "        if validation_df is not None and validation_masks is not None and original_values is not None:\n",
    "            validation_results = {}\n",
    "            \n",
    "            # Extract validation data\n",
    "            X_val = validation_df[columns_to_use].copy()\n",
    "            \n",
    "            # Ensure all validation columns are numeric\n",
    "            for col in X_val.columns:\n",
    "                X_val[col] = pd.to_numeric(X_val[col], errors='coerce')\n",
    "                \n",
    "            # Scale validation data\n",
    "            X_val_for_scaling = X_val.copy()\n",
    "            for col in X_val_for_scaling.columns:\n",
    "                X_val_for_scaling[col] = X_val_for_scaling[col].fillna(X_val_for_scaling[col].mean())\n",
    "            \n",
    "            X_val_scaled = pd.DataFrame(\n",
    "                scaler.transform(X_val_for_scaling),\n",
    "                columns=X_val.columns,\n",
    "                index=X_val.index\n",
    "            )\n",
    "            \n",
    "            # Restore NaN values\n",
    "            X_val_scaled[X_val.isna()] = np.nan\n",
    "            \n",
    "            # Create a new imputer for validation data\n",
    "            val_imputer = SoftImpute(\n",
    "                J=J,\n",
    "                thresh=thresh,\n",
    "                lambda_=lambda_,\n",
    "                maxit=maxit,\n",
    "                random_state=random_state,\n",
    "                verbose=False  # Less verbose for validation\n",
    "            )\n",
    "            \n",
    "            # Impute validation data\n",
    "            print(\"Imputing validation data...\")\n",
    "            val_imputer.fit(X_val_scaled.values)\n",
    "            X_val_imputed_scaled = val_imputer.predict(X_val_scaled.values)\n",
    "            \n",
    "            # Inverse transform\n",
    "            X_val_imputed = pd.DataFrame(\n",
    "                scaler.inverse_transform(X_val_imputed_scaled),\n",
    "                columns=X_val.columns,\n",
    "                index=X_val.index\n",
    "            )\n",
    "            \n",
    "            # Compare imputed values to real values\n",
    "            with tqdm(columns_to_impute, desc=\"Validating results\") as pbar:\n",
    "                for col in pbar:\n",
    "                    pbar.set_description(f\"Validating {col}\")\n",
    "                    # Get indices where values were artificially set to NaN\n",
    "                    mask = validation_masks[col] & validation_df[col].isna()\n",
    "                    \n",
    "                    if mask.sum() == 0:\n",
    "                        validation_results[col] = {\n",
    "                            'error': \"No artificially missing values\"\n",
    "                        }\n",
    "                        continue\n",
    "                        \n",
    "                    real_vals = original_values[col][mask]\n",
    "                    imputed_vals = X_val_imputed.loc[mask, col]\n",
    "                    \n",
    "                    # Calculate continuous metrics (MAE and RMSE) - NO ROUNDING\n",
    "                    mae = mean_absolute_error(real_vals, imputed_vals)\n",
    "                    rmse = np.sqrt(mean_squared_error(real_vals, imputed_vals))\n",
    "                    \n",
    "                    # Calculate classification metrics - WITH ROUNDING\n",
    "                    real_vals_class = process_for_classification(real_vals)\n",
    "                    imputed_vals_class = process_for_classification(imputed_vals)\n",
    "                    \n",
    "                    classification_metrics = calculate_classification_metrics(real_vals_class, imputed_vals_class)\n",
    "                    \n",
    "                    validation_results[col] = {\n",
    "                        'mae': mae,\n",
    "                        'rmse': rmse,\n",
    "                        'accuracy': classification_metrics['accuracy'],\n",
    "                        'auc_multiclass': classification_metrics['auc_multiclass'],\n",
    "                        'avg_sensitivity': classification_metrics['avg_sensitivity'],\n",
    "                        'avg_specificity': classification_metrics['avg_specificity'],\n",
    "                        'avg_ppv': classification_metrics['avg_ppv'],\n",
    "                        'avg_npv': classification_metrics['avg_npv'],\n",
    "                        'precision_macro': classification_metrics['precision_macro'],\n",
    "                        'recall_macro': classification_metrics['recall_macro'],\n",
    "                        'real_distribution': real_vals.describe(),\n",
    "                        'imputed_distribution': pd.Series(imputed_vals).describe()\n",
    "                    }\n",
    "                    \n",
    "                    # Update progress\n",
    "                    pbar.set_postfix({\"MAE\": f\"{mae:.4f}\", \"RMSE\": f\"{rmse:.4f}\", \"Acc\": f\"{classification_metrics['accuracy']:.4f}\"})\n",
    "        \n",
    "        return imputed_df, validation_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in SoftImpute imputation: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        # Fallback to simple mean imputation\n",
    "        print(\"Falling back to simple mean imputation\")\n",
    "        result_df = df.copy()\n",
    "        for col in columns_to_impute:\n",
    "            if col in result_df.columns:\n",
    "                result_df[col] = pd.to_numeric(result_df[col], errors='coerce')\n",
    "                result_df[col] = result_df[col].fillna(result_df[col].mean())\n",
    "        return result_df, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftImpute (Travis Brady): Using 48 columns, imputing 44 columns\n",
      "SoftImpute parameters: J=12, thresh=1e-05, lambda_=0, maxit=100\n",
      "Training SoftImpute imputation model...\n",
      "iter:    1 ratio = 2.00000\n",
      "iter:    2 ratio = 0.82055\n",
      "iter:    3 ratio = 0.95047\n",
      "iter:    4 ratio = 1.10575\n",
      "iter:    5 ratio = 1.29178\n",
      "iter:    6 ratio = 0.82509\n",
      "iter:    7 ratio = 0.54845\n",
      "iter:    8 ratio = 0.59332\n",
      "iter:    9 ratio = 0.46196\n",
      "iter:   10 ratio = 0.28523\n",
      "iter:   11 ratio = 0.19496\n",
      "iter:   12 ratio = 0.20664\n",
      "iter:   13 ratio = 0.16240\n",
      "iter:   14 ratio = 0.16466\n",
      "iter:   15 ratio = 0.18682\n",
      "iter:   16 ratio = 0.13235\n",
      "iter:   17 ratio = 0.10092\n",
      "iter:   18 ratio = 0.02584\n",
      "iter:   19 ratio = 0.02539\n",
      "iter:   20 ratio = 0.13252\n",
      "iter:   21 ratio = 0.21987\n",
      "iter:   22 ratio = 0.15191\n",
      "iter:   23 ratio = 0.11367\n",
      "iter:   24 ratio = 0.08670\n",
      "iter:   25 ratio = 0.00067\n",
      "iter:   26 ratio = 0.03285\n",
      "iter:   27 ratio = 0.01068\n",
      "iter:   28 ratio = -0.00153\n"
     ]
    }
   ],
   "source": [
    "ordinal_cols = (\n",
    "    [f\"gp{i}\" for i in range(1, 8)] + [f\"gs{i}\" for i in range(1, 8)] +\n",
    "    [f\"ge{i}\" for i in range(1, 7)] + [f\"gf{i}\" for i in range(1, 8)] +\n",
    "    [f\"a_hn{i}\" for i in range(1, 6)] + [\"a_hn7\", \"a_hn10\"] +\n",
    "    [f\"a_e{i}\" for i in range(1, 8)] + [\"a_c6\", \"a_c2\", \"a_act11\"]\n",
    ")\n",
    "columns_to_impute = ordinal_cols#['ge1', 'ge2', 'ge3', 'ge4', 'ge5', 'ge6']\n",
    "# Apply deep autoencoder imputation with explicit column specifications\n",
    "imputed_df, validation_results = apply_softimpute_imputation(\n",
    "    df=df, \n",
    "    columns_to_impute=columns_to_impute\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model - KNN imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this import at the top of your file\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "def apply_knn_imputation(df, columns_to_impute, validation_df=None, validation_masks=None, original_values=None,\n",
    "                        n_neighbors=5, weights='uniform', metric='nan_euclidean'):\n",
    "    \"\"\"\n",
    "    Apply KNN imputation using scikit-learn's KNNImputer\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Data with missing values\n",
    "    columns_to_impute : list\n",
    "        List of column names to impute\n",
    "    validation_df : pandas.DataFrame, optional\n",
    "        Validation dataset with artificially missing values\n",
    "    validation_masks : dict, optional\n",
    "        Dictionary of masks for validation data\n",
    "    original_values : dict, optional\n",
    "        Dictionary of original values for validation\n",
    "    n_neighbors : int\n",
    "        Number of neighboring samples to use for imputation\n",
    "    weights : str or callable\n",
    "        Weight function used in prediction. Possible values:\n",
    "        - 'uniform': uniform weights (default)\n",
    "        - 'distance': weight points by the inverse of their distance\n",
    "    metric : str\n",
    "        Distance metric for searching neighbors. Possible values:\n",
    "        - 'nan_euclidean': euclidean distance ignoring NaNs (default)\n",
    "        - 'euclidean': standard euclidean distance\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    imputed_df : pandas.DataFrame\n",
    "        Data with imputed values\n",
    "    validation_results : dict, optional\n",
    "        Validation results if validation data provided\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract relevant columns including potential predictors\n",
    "        # Use all columns except those with excessive missing values\n",
    "        threshold = 0.5  # Columns with more than 50% missing values are excluded\n",
    "        columns_to_use = [col for col in df.columns \n",
    "                            if df[col].isna().mean() < threshold]\n",
    "        \n",
    "        # Ensure all columns_to_impute are included\n",
    "        for col in columns_to_impute:\n",
    "            if col not in columns_to_use:\n",
    "                columns_to_use.append(col)\n",
    "        \n",
    "        # Extract subset of data\n",
    "        X = df[columns_to_use].copy()\n",
    "        \n",
    "        # Ensure all columns are numeric\n",
    "        for col in X.columns:\n",
    "            X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "        \n",
    "        print(f\"KNN Imputation: Using {len(columns_to_use)} columns, imputing {len(columns_to_impute)} columns\")\n",
    "        \n",
    "        # Adjust n_neighbors based on available data\n",
    "        # For each column to impute, check how many complete cases we have\n",
    "        min_complete_cases = float('inf')\n",
    "        for col in columns_to_impute:\n",
    "            if col in X.columns:\n",
    "                # Count rows where this column has data and at least one other column has data\n",
    "                col_observed = X[col].notna()\n",
    "                other_cols = [c for c in X.columns if c != col]\n",
    "                if other_cols:\n",
    "                    other_observed = X[other_cols].notna().any(axis=1)\n",
    "                    complete_cases = (col_observed & other_observed).sum()\n",
    "                else:\n",
    "                    complete_cases = col_observed.sum()\n",
    "                min_complete_cases = min(min_complete_cases, complete_cases)\n",
    "        \n",
    "        # Adjust n_neighbors to be at most the number of complete cases - 1\n",
    "        if min_complete_cases != float('inf') and min_complete_cases > 0:\n",
    "            n_neighbors = min(n_neighbors, max(1, min_complete_cases - 1))\n",
    "        \n",
    "        print(f\"KNN parameters: n_neighbors={n_neighbors}, weights='{weights}', metric='{metric}'\")\n",
    "        \n",
    "        # Initialize KNNImputer\n",
    "        imputer = KNNImputer(\n",
    "            n_neighbors=n_neighbors,\n",
    "            weights=weights,\n",
    "            metric=metric,\n",
    "            keep_empty_features=True  # Keep features that are all NaN\n",
    "        )\n",
    "        \n",
    "        # Fit and transform\n",
    "        print(\"Training KNN imputation model...\")\n",
    "        X_imputed_array = imputer.fit_transform(X.values)\n",
    "        \n",
    "        # Convert back to DataFrame\n",
    "        X_imputed = pd.DataFrame(X_imputed_array, columns=X.columns, index=X.index)\n",
    "        \n",
    "        # Create imputed dataframe - only replace missing values\n",
    "        imputed_df = df.copy()\n",
    "        for col in columns_to_impute:\n",
    "            if col in X_imputed.columns:\n",
    "                missing_mask = df[col].isna()\n",
    "                imputed_df.loc[missing_mask, col] = X_imputed.loc[missing_mask, col]\n",
    "        \n",
    "        # Print imputation statistics\n",
    "        print(\"KNN Imputation completed successfully!\")\n",
    "        for col in columns_to_impute:\n",
    "            if col in df.columns:\n",
    "                original_missing = df[col].isna().sum()\n",
    "                final_missing = imputed_df[col].isna().sum()\n",
    "                imputed_count = original_missing - final_missing\n",
    "                print(f\"  {col}: {imputed_count} values imputed\")\n",
    "        \n",
    "        # Validate if validation data provided\n",
    "        validation_results = None\n",
    "        if validation_df is not None and validation_masks is not None and original_values is not None:\n",
    "            validation_results = {}\n",
    "            \n",
    "            # Extract validation data\n",
    "            X_val = validation_df[columns_to_use].copy()\n",
    "            \n",
    "            # Ensure all validation columns are numeric\n",
    "            for col in X_val.columns:\n",
    "                X_val[col] = pd.to_numeric(X_val[col], errors='coerce')\n",
    "            \n",
    "            # Check validation data for n_neighbors adjustment\n",
    "            val_min_complete_cases = float('inf')\n",
    "            for col in columns_to_impute:\n",
    "                if col in X_val.columns:\n",
    "                    col_observed = X_val[col].notna()\n",
    "                    other_cols = [c for c in X_val.columns if c != col]\n",
    "                    if other_cols:\n",
    "                        other_observed = X_val[other_cols].notna().any(axis=1)\n",
    "                        complete_cases = (col_observed & other_observed).sum()\n",
    "                    else:\n",
    "                        complete_cases = col_observed.sum()\n",
    "                    val_min_complete_cases = min(val_min_complete_cases, complete_cases)\n",
    "            \n",
    "            # Adjust n_neighbors for validation\n",
    "            val_n_neighbors = n_neighbors\n",
    "            if val_min_complete_cases != float('inf') and val_min_complete_cases > 0:\n",
    "                val_n_neighbors = min(n_neighbors, max(1, val_min_complete_cases - 1))\n",
    "            \n",
    "            # Create a new imputer for validation data\n",
    "            val_imputer = KNNImputer(\n",
    "                n_neighbors=val_n_neighbors,\n",
    "                weights=weights,\n",
    "                metric=metric,\n",
    "                keep_empty_features=True\n",
    "            )\n",
    "            \n",
    "            # Impute validation data\n",
    "            print(\"Imputing validation data...\")\n",
    "            X_val_imputed_array = val_imputer.fit_transform(X_val.values)\n",
    "            X_val_imputed = pd.DataFrame(X_val_imputed_array, columns=X_val.columns, index=X_val.index)\n",
    "            \n",
    "            # Compare imputed values to real values\n",
    "            with tqdm(columns_to_impute, desc=\"Validating results\") as pbar:\n",
    "                for col in pbar:\n",
    "                    pbar.set_description(f\"Validating {col}\")\n",
    "                    # Get indices where values were artificially set to NaN\n",
    "                    mask = validation_masks[col] & validation_df[col].isna()\n",
    "                    \n",
    "                    if mask.sum() == 0:\n",
    "                        validation_results[col] = {\n",
    "                            'error': \"No artificially missing values\"\n",
    "                        }\n",
    "                        continue\n",
    "                        \n",
    "                    real_vals = original_values[col][mask]\n",
    "                    imputed_vals = X_val_imputed.loc[mask, col]\n",
    "                    \n",
    "                    # Calculate MAE and RMSE\n",
    "                    mae = mean_absolute_error(real_vals, imputed_vals)\n",
    "                    rmse = np.sqrt(mean_squared_error(real_vals, imputed_vals))\n",
    "                    \n",
    "                    # Calculate classification metrics - WITH ROUNDING\n",
    "                    real_vals_class = process_for_classification(real_vals)\n",
    "                    imputed_vals_class = process_for_classification(imputed_vals)\n",
    "                    \n",
    "                    classification_metrics = calculate_classification_metrics(real_vals_class, imputed_vals_class)\n",
    "                    \n",
    "                    validation_results[col] = {\n",
    "                        'mae': mae,\n",
    "                        'rmse': rmse,\n",
    "                        'accuracy': classification_metrics['accuracy'],\n",
    "                        'auc_multiclass': classification_metrics['auc_multiclass'],\n",
    "                        'avg_sensitivity': classification_metrics['avg_sensitivity'],\n",
    "                        'avg_specificity': classification_metrics['avg_specificity'],\n",
    "                        'avg_ppv': classification_metrics['avg_ppv'],\n",
    "                        'avg_npv': classification_metrics['avg_npv'],\n",
    "                        'precision_macro': classification_metrics['precision_macro'],\n",
    "                        'recall_macro': classification_metrics['recall_macro'],\n",
    "                        'real_distribution': real_vals.describe(),\n",
    "                        'imputed_distribution': pd.Series(imputed_vals).describe()\n",
    "                    }\n",
    "                    \n",
    "                    # Update progress\n",
    "                    pbar.set_postfix({\"MAE\": f\"{mae:.4f}\", \"RMSE\": f\"{rmse:.4f}\", \"Acc\": f\"{classification_metrics['accuracy']:.4f}\"})\n",
    "        \n",
    "        return imputed_df, validation_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in KNN imputation: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        # Fallback to simple mean imputation\n",
    "        print(\"Falling back to simple mean imputation\")\n",
    "        result_df = df.copy()\n",
    "        for col in columns_to_impute:\n",
    "            if col in result_df.columns:\n",
    "                result_df[col] = pd.to_numeric(result_df[col], errors='coerce')\n",
    "                result_df[col] = result_df[col].fillna(result_df[col].mean())\n",
    "        return result_df, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Imputation: Using 48 columns, imputing 44 columns\n",
      "KNN parameters: n_neighbors=5, weights='uniform', metric='nan_euclidean'\n",
      "Training KNN imputation model...\n",
      "KNN Imputation completed successfully!\n",
      "  gp1: 4177 values imputed\n",
      "  gp2: 4178 values imputed\n",
      "  gp3: 4200 values imputed\n",
      "  gp4: 4185 values imputed\n",
      "  gp5: 4349 values imputed\n",
      "  gp6: 4194 values imputed\n",
      "  gp7: 4198 values imputed\n",
      "  gs1: 4196 values imputed\n",
      "  gs2: 4186 values imputed\n",
      "  gs3: 4197 values imputed\n",
      "  gs4: 4252 values imputed\n",
      "  gs5: 4233 values imputed\n",
      "  gs6: 4274 values imputed\n",
      "  gs7: 4626 values imputed\n",
      "  ge1: 4178 values imputed\n",
      "  ge2: 4211 values imputed\n",
      "  ge3: 4249 values imputed\n",
      "  ge4: 4192 values imputed\n",
      "  ge5: 4195 values imputed\n",
      "  ge6: 4190 values imputed\n",
      "  gf1: 4207 values imputed\n",
      "  gf2: 4242 values imputed\n",
      "  gf3: 4187 values imputed\n",
      "  gf4: 4223 values imputed\n",
      "  gf5: 4186 values imputed\n",
      "  gf6: 4200 values imputed\n",
      "  gf7: 4191 values imputed\n",
      "  a_hn1: 4209 values imputed\n",
      "  a_hn2: 4221 values imputed\n",
      "  a_hn3: 4232 values imputed\n",
      "  a_hn4: 4233 values imputed\n",
      "  a_hn5: 4227 values imputed\n",
      "  a_hn7: 4226 values imputed\n",
      "  a_hn10: 4222 values imputed\n",
      "  a_e1: 4196 values imputed\n",
      "  a_e2: 4195 values imputed\n",
      "  a_e3: 4190 values imputed\n",
      "  a_e4: 4195 values imputed\n",
      "  a_e5: 4201 values imputed\n",
      "  a_e6: 4213 values imputed\n",
      "  a_e7: 4193 values imputed\n",
      "  a_c6: 4196 values imputed\n",
      "  a_c2: 4195 values imputed\n",
      "  a_act11: 4191 values imputed\n"
     ]
    }
   ],
   "source": [
    "ordinal_cols = (\n",
    "    [f\"gp{i}\" for i in range(1, 8)] + [f\"gs{i}\" for i in range(1, 8)] +\n",
    "    [f\"ge{i}\" for i in range(1, 7)] + [f\"gf{i}\" for i in range(1, 8)] +\n",
    "    [f\"a_hn{i}\" for i in range(1, 6)] + [\"a_hn7\", \"a_hn10\"] +\n",
    "    [f\"a_e{i}\" for i in range(1, 8)] + [\"a_c6\", \"a_c2\", \"a_act11\"]\n",
    ")\n",
    "columns_to_impute = ordinal_cols#['ge1', 'ge2', 'ge3', 'ge4', 'ge5', 'ge6']\n",
    "# Apply deep autoencoder imputation with explicit column specifications\n",
    "imputed_df, validation_results = apply_knn_imputation(\n",
    "    df=df, \n",
    "    columns_to_impute=columns_to_impute\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qol_date</th>\n",
       "      <th>age_diagnosis</th>\n",
       "      <th>gender</th>\n",
       "      <th>overall_primary_tumour</th>\n",
       "      <th>overall_regional_ln</th>\n",
       "      <th>overall_distant_metastasis</th>\n",
       "      <th>neotx___notx</th>\n",
       "      <th>neotx___chemo</th>\n",
       "      <th>neotx___rads</th>\n",
       "      <th>...</th>\n",
       "      <th>a_e4</th>\n",
       "      <th>a_e5</th>\n",
       "      <th>a_e6</th>\n",
       "      <th>a_e7</th>\n",
       "      <th>a_c6</th>\n",
       "      <th>a_c2</th>\n",
       "      <th>a_act11</th>\n",
       "      <th>readmission_30d</th>\n",
       "      <th>postop_comp</th>\n",
       "      <th>los</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>2007-01-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id   qol_date  age_diagnosis gender overall_primary_tumour  \\\n",
       "0    1        NaT            NaN    1.0                    nan   \n",
       "14   1        NaT            NaN    NaN                      2   \n",
       "18   2        NaT            NaN    NaN                      3   \n",
       "22   2        NaT            NaN    1.0                    nan   \n",
       "25   2 2007-01-12            NaN    NaN                    nan   \n",
       "\n",
       "   overall_regional_ln overall_distant_metastasis neotx___notx neotx___chemo  \\\n",
       "0                  nan                        nan          NaN           NaN   \n",
       "14                   0                        nan          NaN           NaN   \n",
       "18                   1                        0.0          NaN           NaN   \n",
       "22                 nan                        nan          NaN           NaN   \n",
       "25                 nan                        nan          NaN           NaN   \n",
       "\n",
       "   neotx___rads  ... a_e4 a_e5 a_e6 a_e7 a_c6  a_c2  a_act11  readmission_30d  \\\n",
       "0           NaN  ...  NaN  NaN  NaN  NaN  NaN   NaN      NaN              NaN   \n",
       "14          NaN  ...  NaN  NaN  NaN  NaN  NaN   NaN      NaN              NaN   \n",
       "18          NaN  ...  NaN  NaN  NaN  NaN  NaN   NaN      NaN              NaN   \n",
       "22          NaN  ...  NaN  NaN  NaN  NaN  NaN   NaN      NaN              NaN   \n",
       "25          NaN  ...  3.0  0.0  4.0  0.0  4.0   0.0      1.0              NaN   \n",
       "\n",
       "    postop_comp  los  \n",
       "0           0.0  NaN  \n",
       "14          NaN  NaN  \n",
       "18          NaN  NaN  \n",
       "22          NaN  NaN  \n",
       "25          NaN  NaN  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = df.copy()  # Save the full dataset\n",
    "df = df.head(50)         # Use only the first 50 rows for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qol_date</th>\n",
       "      <th>age_diagnosis</th>\n",
       "      <th>gender</th>\n",
       "      <th>overall_primary_tumour</th>\n",
       "      <th>overall_regional_ln</th>\n",
       "      <th>overall_distant_metastasis</th>\n",
       "      <th>neotx___notx</th>\n",
       "      <th>neotx___chemo</th>\n",
       "      <th>neotx___rads</th>\n",
       "      <th>...</th>\n",
       "      <th>a_e4</th>\n",
       "      <th>a_e5</th>\n",
       "      <th>a_e6</th>\n",
       "      <th>a_e7</th>\n",
       "      <th>a_c6</th>\n",
       "      <th>a_c2</th>\n",
       "      <th>a_act11</th>\n",
       "      <th>readmission_30d</th>\n",
       "      <th>postop_comp</th>\n",
       "      <th>los</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>2007-01-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id   qol_date  age_diagnosis gender overall_primary_tumour  \\\n",
       "0    1        NaT            NaN    1.0                    nan   \n",
       "14   1        NaT            NaN    NaN                      2   \n",
       "18   2        NaT            NaN    NaN                      3   \n",
       "22   2        NaT            NaN    1.0                    nan   \n",
       "25   2 2007-01-12            NaN    NaN                    nan   \n",
       "\n",
       "   overall_regional_ln overall_distant_metastasis neotx___notx neotx___chemo  \\\n",
       "0                  nan                        nan          NaN           NaN   \n",
       "14                   0                        nan          NaN           NaN   \n",
       "18                   1                        0.0          NaN           NaN   \n",
       "22                 nan                        nan          NaN           NaN   \n",
       "25                 nan                        nan          NaN           NaN   \n",
       "\n",
       "   neotx___rads  ... a_e4 a_e5 a_e6 a_e7 a_c6  a_c2  a_act11  readmission_30d  \\\n",
       "0           NaN  ...  NaN  NaN  NaN  NaN  NaN   NaN      NaN              NaN   \n",
       "14          NaN  ...  NaN  NaN  NaN  NaN  NaN   NaN      NaN              NaN   \n",
       "18          NaN  ...  NaN  NaN  NaN  NaN  NaN   NaN      NaN              NaN   \n",
       "22          NaN  ...  NaN  NaN  NaN  NaN  NaN   NaN      NaN              NaN   \n",
       "25          NaN  ...  3.0  0.0  4.0  0.0  4.0   0.0      1.0              NaN   \n",
       "\n",
       "    postop_comp  los  \n",
       "0           0.0  NaN  \n",
       "14          NaN  NaN  \n",
       "18          NaN  NaN  \n",
       "22          NaN  NaN  \n",
       "25          NaN  NaN  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Timepoint: baseline_arm_1 ---\n",
      "\n",
      "--- Timepoint: surgery_arm_1 ---\n",
      "Not enough data to correlate gp1 with gp2 (n=0)\n",
      "Not enough data to correlate gp1 with gp3 (n=0)\n",
      "Not enough data to correlate gp1 with gp4 (n=0)\n",
      "Not enough data to correlate gp1 with gp5 (n=0)\n",
      "Not enough data to correlate gp1 with gp6 (n=0)\n",
      "Not enough data to correlate gp1 with gp7 (n=0)\n",
      "Not enough data to correlate gp1 with gs1 (n=0)\n",
      "Not enough data to correlate gp1 with gs2 (n=0)\n",
      "Not enough data to correlate gp1 with gs3 (n=0)\n",
      "Not enough data to correlate gp1 with gs4 (n=0)\n",
      "Not enough data to correlate gp1 with gs5 (n=0)\n",
      "Not enough data to correlate gp1 with gs6 (n=0)\n",
      "Not enough data to correlate gp1 with gs7 (n=0)\n",
      "Not enough data to correlate gp1 with ge1 (n=0)\n",
      "Not enough data to correlate gp1 with ge2 (n=0)\n",
      "Not enough data to correlate gp1 with ge3 (n=0)\n",
      "Not enough data to correlate gp1 with ge4 (n=0)\n",
      "Not enough data to correlate gp1 with ge5 (n=0)\n",
      "Not enough data to correlate gp1 with ge6 (n=0)\n",
      "Not enough data to correlate gp1 with gf1 (n=0)\n",
      "Not enough data to correlate gp1 with gf2 (n=0)\n",
      "Not enough data to correlate gp1 with gf3 (n=0)\n",
      "Not enough data to correlate gp1 with gf4 (n=0)\n",
      "Not enough data to correlate gp1 with gf5 (n=0)\n",
      "Not enough data to correlate gp1 with gf6 (n=0)\n",
      "Not enough data to correlate gp1 with gf7 (n=0)\n",
      "Not enough data to correlate gp1 with a_hn1 (n=0)\n",
      "Not enough data to correlate gp1 with a_hn2 (n=0)\n",
      "Not enough data to correlate gp1 with a_hn3 (n=0)\n",
      "Not enough data to correlate gp1 with a_hn4 (n=0)\n",
      "Not enough data to correlate gp1 with a_hn5 (n=0)\n",
      "Not enough data to correlate gp1 with a_hn7 (n=0)\n",
      "Not enough data to correlate gp1 with a_hn10 (n=0)\n",
      "Not enough data to correlate gp1 with a_e1 (n=0)\n",
      "Not enough data to correlate gp1 with a_e2 (n=0)\n",
      "Not enough data to correlate gp1 with a_e3 (n=0)\n",
      "Not enough data to correlate gp1 with a_e4 (n=0)\n",
      "Not enough data to correlate gp1 with a_e5 (n=0)\n",
      "Not enough data to correlate gp1 with a_e6 (n=0)\n",
      "Not enough data to correlate gp1 with a_e7 (n=0)\n",
      "Not enough data to correlate gp1 with a_c6 (n=0)\n",
      "Not enough data to correlate gp1 with a_c2 (n=0)\n",
      "Not enough data to correlate gp1 with a_act11 (n=0)\n",
      "Not enough data to correlate gp2 with gp1 (n=0)\n",
      "Not enough data to correlate gp2 with gp3 (n=0)\n",
      "Not enough data to correlate gp2 with gp4 (n=0)\n",
      "Not enough data to correlate gp2 with gp5 (n=0)\n",
      "Not enough data to correlate gp2 with gp6 (n=0)\n",
      "Not enough data to correlate gp2 with gp7 (n=0)\n",
      "Not enough data to correlate gp2 with gs1 (n=0)\n",
      "Not enough data to correlate gp2 with gs2 (n=0)\n",
      "Not enough data to correlate gp2 with gs3 (n=0)\n",
      "Not enough data to correlate gp2 with gs4 (n=0)\n",
      "Not enough data to correlate gp2 with gs5 (n=0)\n",
      "Not enough data to correlate gp2 with gs6 (n=0)\n",
      "Not enough data to correlate gp2 with gs7 (n=0)\n",
      "Not enough data to correlate gp2 with ge1 (n=0)\n",
      "Not enough data to correlate gp2 with ge2 (n=0)\n",
      "Not enough data to correlate gp2 with ge3 (n=0)\n",
      "Not enough data to correlate gp2 with ge4 (n=0)\n",
      "Not enough data to correlate gp2 with ge5 (n=0)\n",
      "Not enough data to correlate gp2 with ge6 (n=0)\n",
      "Not enough data to correlate gp2 with gf1 (n=0)\n",
      "Not enough data to correlate gp2 with gf2 (n=0)\n",
      "Not enough data to correlate gp2 with gf3 (n=0)\n",
      "Not enough data to correlate gp2 with gf4 (n=0)\n",
      "Not enough data to correlate gp2 with gf5 (n=0)\n",
      "Not enough data to correlate gp2 with gf6 (n=0)\n",
      "Not enough data to correlate gp2 with gf7 (n=0)\n",
      "Not enough data to correlate gp2 with a_hn1 (n=0)\n",
      "Not enough data to correlate gp2 with a_hn2 (n=0)\n",
      "Not enough data to correlate gp2 with a_hn3 (n=0)\n",
      "Not enough data to correlate gp2 with a_hn4 (n=0)\n",
      "Not enough data to correlate gp2 with a_hn5 (n=0)\n",
      "Not enough data to correlate gp2 with a_hn7 (n=0)\n",
      "Not enough data to correlate gp2 with a_hn10 (n=0)\n",
      "Not enough data to correlate gp2 with a_e1 (n=0)\n",
      "Not enough data to correlate gp2 with a_e2 (n=0)\n",
      "Not enough data to correlate gp2 with a_e3 (n=0)\n",
      "Not enough data to correlate gp2 with a_e4 (n=0)\n",
      "Not enough data to correlate gp2 with a_e5 (n=0)\n",
      "Not enough data to correlate gp2 with a_e6 (n=0)\n",
      "Not enough data to correlate gp2 with a_e7 (n=0)\n",
      "Not enough data to correlate gp2 with a_c6 (n=0)\n",
      "Not enough data to correlate gp2 with a_c2 (n=0)\n",
      "Not enough data to correlate gp2 with a_act11 (n=0)\n",
      "Not enough data to correlate gp3 with gp1 (n=0)\n",
      "Not enough data to correlate gp3 with gp2 (n=0)\n",
      "Not enough data to correlate gp3 with gp4 (n=0)\n",
      "Not enough data to correlate gp3 with gp5 (n=0)\n",
      "Not enough data to correlate gp3 with gp6 (n=0)\n",
      "Not enough data to correlate gp3 with gp7 (n=0)\n",
      "Not enough data to correlate gp3 with gs1 (n=0)\n",
      "Not enough data to correlate gp3 with gs2 (n=0)\n",
      "Not enough data to correlate gp3 with gs3 (n=0)\n",
      "Not enough data to correlate gp3 with gs4 (n=0)\n",
      "Not enough data to correlate gp3 with gs5 (n=0)\n",
      "Not enough data to correlate gp3 with gs6 (n=0)\n",
      "Not enough data to correlate gp3 with gs7 (n=0)\n",
      "Not enough data to correlate gp3 with ge1 (n=0)\n",
      "Not enough data to correlate gp3 with ge2 (n=0)\n",
      "Not enough data to correlate gp3 with ge3 (n=0)\n",
      "Not enough data to correlate gp3 with ge4 (n=0)\n",
      "Not enough data to correlate gp3 with ge5 (n=0)\n",
      "Not enough data to correlate gp3 with ge6 (n=0)\n",
      "Not enough data to correlate gp3 with gf1 (n=0)\n",
      "Not enough data to correlate gp3 with gf2 (n=0)\n",
      "Not enough data to correlate gp3 with gf3 (n=0)\n",
      "Not enough data to correlate gp3 with gf4 (n=0)\n",
      "Not enough data to correlate gp3 with gf5 (n=0)\n",
      "Not enough data to correlate gp3 with gf6 (n=0)\n",
      "Not enough data to correlate gp3 with gf7 (n=0)\n",
      "Not enough data to correlate gp3 with a_hn1 (n=0)\n",
      "Not enough data to correlate gp3 with a_hn2 (n=0)\n",
      "Not enough data to correlate gp3 with a_hn3 (n=0)\n",
      "Not enough data to correlate gp3 with a_hn4 (n=0)\n",
      "Not enough data to correlate gp3 with a_hn5 (n=0)\n",
      "Not enough data to correlate gp3 with a_hn7 (n=0)\n",
      "Not enough data to correlate gp3 with a_hn10 (n=0)\n",
      "Not enough data to correlate gp3 with a_e1 (n=0)\n",
      "Not enough data to correlate gp3 with a_e2 (n=0)\n",
      "Not enough data to correlate gp3 with a_e3 (n=0)\n",
      "Not enough data to correlate gp3 with a_e4 (n=0)\n",
      "Not enough data to correlate gp3 with a_e5 (n=0)\n",
      "Not enough data to correlate gp3 with a_e6 (n=0)\n",
      "Not enough data to correlate gp3 with a_e7 (n=0)\n",
      "Not enough data to correlate gp3 with a_c6 (n=0)\n",
      "Not enough data to correlate gp3 with a_c2 (n=0)\n",
      "Not enough data to correlate gp3 with a_act11 (n=0)\n",
      "Not enough data to correlate gp4 with gp1 (n=0)\n",
      "Not enough data to correlate gp4 with gp2 (n=0)\n",
      "Not enough data to correlate gp4 with gp3 (n=0)\n",
      "Not enough data to correlate gp4 with gp5 (n=0)\n",
      "Not enough data to correlate gp4 with gp6 (n=0)\n",
      "Not enough data to correlate gp4 with gp7 (n=0)\n",
      "Not enough data to correlate gp4 with gs1 (n=0)\n",
      "Not enough data to correlate gp4 with gs2 (n=0)\n",
      "Not enough data to correlate gp4 with gs3 (n=0)\n",
      "Not enough data to correlate gp4 with gs4 (n=0)\n",
      "Not enough data to correlate gp4 with gs5 (n=0)\n",
      "Not enough data to correlate gp4 with gs6 (n=0)\n",
      "Not enough data to correlate gp4 with gs7 (n=0)\n",
      "Not enough data to correlate gp4 with ge1 (n=0)\n",
      "Not enough data to correlate gp4 with ge2 (n=0)\n",
      "Not enough data to correlate gp4 with ge3 (n=0)\n",
      "Not enough data to correlate gp4 with ge4 (n=0)\n",
      "Not enough data to correlate gp4 with ge5 (n=0)\n",
      "Not enough data to correlate gp4 with ge6 (n=0)\n",
      "Not enough data to correlate gp4 with gf1 (n=0)\n",
      "Not enough data to correlate gp4 with gf2 (n=0)\n",
      "Not enough data to correlate gp4 with gf3 (n=0)\n",
      "Not enough data to correlate gp4 with gf4 (n=0)\n",
      "Not enough data to correlate gp4 with gf5 (n=0)\n",
      "Not enough data to correlate gp4 with gf6 (n=0)\n",
      "Not enough data to correlate gp4 with gf7 (n=0)\n",
      "Not enough data to correlate gp4 with a_hn1 (n=0)\n",
      "Not enough data to correlate gp4 with a_hn2 (n=0)\n",
      "Not enough data to correlate gp4 with a_hn3 (n=0)\n",
      "Not enough data to correlate gp4 with a_hn4 (n=0)\n",
      "Not enough data to correlate gp4 with a_hn5 (n=0)\n",
      "Not enough data to correlate gp4 with a_hn7 (n=0)\n",
      "Not enough data to correlate gp4 with a_hn10 (n=0)\n",
      "Not enough data to correlate gp4 with a_e1 (n=0)\n",
      "Not enough data to correlate gp4 with a_e2 (n=0)\n",
      "Not enough data to correlate gp4 with a_e3 (n=0)\n",
      "Not enough data to correlate gp4 with a_e4 (n=0)\n",
      "Not enough data to correlate gp4 with a_e5 (n=0)\n",
      "Not enough data to correlate gp4 with a_e6 (n=0)\n",
      "Not enough data to correlate gp4 with a_e7 (n=0)\n",
      "Not enough data to correlate gp4 with a_c6 (n=0)\n",
      "Not enough data to correlate gp4 with a_c2 (n=0)\n",
      "Not enough data to correlate gp4 with a_act11 (n=0)\n",
      "Not enough data to correlate gp5 with gp1 (n=0)\n",
      "Not enough data to correlate gp5 with gp2 (n=0)\n",
      "Not enough data to correlate gp5 with gp3 (n=0)\n",
      "Not enough data to correlate gp5 with gp4 (n=0)\n",
      "Not enough data to correlate gp5 with gp6 (n=0)\n",
      "Not enough data to correlate gp5 with gp7 (n=0)\n",
      "Not enough data to correlate gp5 with gs1 (n=0)\n",
      "Not enough data to correlate gp5 with gs2 (n=0)\n",
      "Not enough data to correlate gp5 with gs3 (n=0)\n",
      "Not enough data to correlate gp5 with gs4 (n=0)\n",
      "Not enough data to correlate gp5 with gs5 (n=0)\n",
      "Not enough data to correlate gp5 with gs6 (n=0)\n",
      "Not enough data to correlate gp5 with gs7 (n=0)\n",
      "Not enough data to correlate gp5 with ge1 (n=0)\n",
      "Not enough data to correlate gp5 with ge2 (n=0)\n",
      "Not enough data to correlate gp5 with ge3 (n=0)\n",
      "Not enough data to correlate gp5 with ge4 (n=0)\n",
      "Not enough data to correlate gp5 with ge5 (n=0)\n",
      "Not enough data to correlate gp5 with ge6 (n=0)\n",
      "Not enough data to correlate gp5 with gf1 (n=0)\n",
      "Not enough data to correlate gp5 with gf2 (n=0)\n",
      "Not enough data to correlate gp5 with gf3 (n=0)\n",
      "Not enough data to correlate gp5 with gf4 (n=0)\n",
      "Not enough data to correlate gp5 with gf5 (n=0)\n",
      "Not enough data to correlate gp5 with gf6 (n=0)\n",
      "Not enough data to correlate gp5 with gf7 (n=0)\n",
      "Not enough data to correlate gp5 with a_hn1 (n=0)\n",
      "Not enough data to correlate gp5 with a_hn2 (n=0)\n",
      "Not enough data to correlate gp5 with a_hn3 (n=0)\n",
      "Not enough data to correlate gp5 with a_hn4 (n=0)\n",
      "Not enough data to correlate gp5 with a_hn5 (n=0)\n",
      "Not enough data to correlate gp5 with a_hn7 (n=0)\n",
      "Not enough data to correlate gp5 with a_hn10 (n=0)\n",
      "Not enough data to correlate gp5 with a_e1 (n=0)\n",
      "Not enough data to correlate gp5 with a_e2 (n=0)\n",
      "Not enough data to correlate gp5 with a_e3 (n=0)\n",
      "Not enough data to correlate gp5 with a_e4 (n=0)\n",
      "Not enough data to correlate gp5 with a_e5 (n=0)\n",
      "Not enough data to correlate gp5 with a_e6 (n=0)\n",
      "Not enough data to correlate gp5 with a_e7 (n=0)\n",
      "Not enough data to correlate gp5 with a_c6 (n=0)\n",
      "Not enough data to correlate gp5 with a_c2 (n=0)\n",
      "Not enough data to correlate gp5 with a_act11 (n=0)\n",
      "Not enough data to correlate gp6 with gp1 (n=0)\n",
      "Not enough data to correlate gp6 with gp2 (n=0)\n",
      "Not enough data to correlate gp6 with gp3 (n=0)\n",
      "Not enough data to correlate gp6 with gp4 (n=0)\n",
      "Not enough data to correlate gp6 with gp5 (n=0)\n",
      "Not enough data to correlate gp6 with gp7 (n=0)\n",
      "Not enough data to correlate gp6 with gs1 (n=0)\n",
      "Not enough data to correlate gp6 with gs2 (n=0)\n",
      "Not enough data to correlate gp6 with gs3 (n=0)\n",
      "Not enough data to correlate gp6 with gs4 (n=0)\n",
      "Not enough data to correlate gp6 with gs5 (n=0)\n",
      "Not enough data to correlate gp6 with gs6 (n=0)\n",
      "Not enough data to correlate gp6 with gs7 (n=0)\n",
      "Not enough data to correlate gp6 with ge1 (n=0)\n",
      "Not enough data to correlate gp6 with ge2 (n=0)\n",
      "Not enough data to correlate gp6 with ge3 (n=0)\n",
      "Not enough data to correlate gp6 with ge4 (n=0)\n",
      "Not enough data to correlate gp6 with ge5 (n=0)\n",
      "Not enough data to correlate gp6 with ge6 (n=0)\n",
      "Not enough data to correlate gp6 with gf1 (n=0)\n",
      "Not enough data to correlate gp6 with gf2 (n=0)\n",
      "Not enough data to correlate gp6 with gf3 (n=0)\n",
      "Not enough data to correlate gp6 with gf4 (n=0)\n",
      "Not enough data to correlate gp6 with gf5 (n=0)\n",
      "Not enough data to correlate gp6 with gf6 (n=0)\n",
      "Not enough data to correlate gp6 with gf7 (n=0)\n",
      "Not enough data to correlate gp6 with a_hn1 (n=0)\n",
      "Not enough data to correlate gp6 with a_hn2 (n=0)\n",
      "Not enough data to correlate gp6 with a_hn3 (n=0)\n",
      "Not enough data to correlate gp6 with a_hn4 (n=0)\n",
      "Not enough data to correlate gp6 with a_hn5 (n=0)\n",
      "Not enough data to correlate gp6 with a_hn7 (n=0)\n",
      "Not enough data to correlate gp6 with a_hn10 (n=0)\n",
      "Not enough data to correlate gp6 with a_e1 (n=0)\n",
      "Not enough data to correlate gp6 with a_e2 (n=0)\n",
      "Not enough data to correlate gp6 with a_e3 (n=0)\n",
      "Not enough data to correlate gp6 with a_e4 (n=0)\n",
      "Not enough data to correlate gp6 with a_e5 (n=0)\n",
      "Not enough data to correlate gp6 with a_e6 (n=0)\n",
      "Not enough data to correlate gp6 with a_e7 (n=0)\n",
      "Not enough data to correlate gp6 with a_c6 (n=0)\n",
      "Not enough data to correlate gp6 with a_c2 (n=0)\n",
      "Not enough data to correlate gp6 with a_act11 (n=0)\n",
      "Not enough data to correlate gp7 with gp1 (n=0)\n",
      "Not enough data to correlate gp7 with gp2 (n=0)\n",
      "Not enough data to correlate gp7 with gp3 (n=0)\n",
      "Not enough data to correlate gp7 with gp4 (n=0)\n",
      "Not enough data to correlate gp7 with gp5 (n=0)\n",
      "Not enough data to correlate gp7 with gp6 (n=0)\n",
      "Not enough data to correlate gp7 with gs1 (n=0)\n",
      "Not enough data to correlate gp7 with gs2 (n=0)\n",
      "Not enough data to correlate gp7 with gs3 (n=0)\n",
      "Not enough data to correlate gp7 with gs4 (n=0)\n",
      "Not enough data to correlate gp7 with gs5 (n=0)\n",
      "Not enough data to correlate gp7 with gs6 (n=0)\n",
      "Not enough data to correlate gp7 with gs7 (n=0)\n",
      "Not enough data to correlate gp7 with ge1 (n=0)\n",
      "Not enough data to correlate gp7 with ge2 (n=0)\n",
      "Not enough data to correlate gp7 with ge3 (n=0)\n",
      "Not enough data to correlate gp7 with ge4 (n=0)\n",
      "Not enough data to correlate gp7 with ge5 (n=0)\n",
      "Not enough data to correlate gp7 with ge6 (n=0)\n",
      "Not enough data to correlate gp7 with gf1 (n=0)\n",
      "Not enough data to correlate gp7 with gf2 (n=0)\n",
      "Not enough data to correlate gp7 with gf3 (n=0)\n",
      "Not enough data to correlate gp7 with gf4 (n=0)\n",
      "Not enough data to correlate gp7 with gf5 (n=0)\n",
      "Not enough data to correlate gp7 with gf6 (n=0)\n",
      "Not enough data to correlate gp7 with gf7 (n=0)\n",
      "Not enough data to correlate gp7 with a_hn1 (n=0)\n",
      "Not enough data to correlate gp7 with a_hn2 (n=0)\n",
      "Not enough data to correlate gp7 with a_hn3 (n=0)\n",
      "Not enough data to correlate gp7 with a_hn4 (n=0)\n",
      "Not enough data to correlate gp7 with a_hn5 (n=0)\n",
      "Not enough data to correlate gp7 with a_hn7 (n=0)\n",
      "Not enough data to correlate gp7 with a_hn10 (n=0)\n",
      "Not enough data to correlate gp7 with a_e1 (n=0)\n",
      "Not enough data to correlate gp7 with a_e2 (n=0)\n",
      "Not enough data to correlate gp7 with a_e3 (n=0)\n",
      "Not enough data to correlate gp7 with a_e4 (n=0)\n",
      "Not enough data to correlate gp7 with a_e5 (n=0)\n",
      "Not enough data to correlate gp7 with a_e6 (n=0)\n",
      "Not enough data to correlate gp7 with a_e7 (n=0)\n",
      "Not enough data to correlate gp7 with a_c6 (n=0)\n",
      "Not enough data to correlate gp7 with a_c2 (n=0)\n",
      "Not enough data to correlate gp7 with a_act11 (n=0)\n",
      "Not enough data to correlate gs1 with gp1 (n=0)\n",
      "Not enough data to correlate gs1 with gp2 (n=0)\n",
      "Not enough data to correlate gs1 with gp3 (n=0)\n",
      "Not enough data to correlate gs1 with gp4 (n=0)\n",
      "Not enough data to correlate gs1 with gp5 (n=0)\n",
      "Not enough data to correlate gs1 with gp6 (n=0)\n",
      "Not enough data to correlate gs1 with gp7 (n=0)\n",
      "Not enough data to correlate gs1 with gs2 (n=0)\n",
      "Not enough data to correlate gs1 with gs3 (n=0)\n",
      "Not enough data to correlate gs1 with gs4 (n=0)\n",
      "Not enough data to correlate gs1 with gs5 (n=0)\n",
      "Not enough data to correlate gs1 with gs6 (n=0)\n",
      "Not enough data to correlate gs1 with gs7 (n=0)\n",
      "Not enough data to correlate gs1 with ge1 (n=0)\n",
      "Not enough data to correlate gs1 with ge2 (n=0)\n",
      "Not enough data to correlate gs1 with ge3 (n=0)\n",
      "Not enough data to correlate gs1 with ge4 (n=0)\n",
      "Not enough data to correlate gs1 with ge5 (n=0)\n",
      "Not enough data to correlate gs1 with ge6 (n=0)\n",
      "Not enough data to correlate gs1 with gf1 (n=0)\n",
      "Not enough data to correlate gs1 with gf2 (n=0)\n",
      "Not enough data to correlate gs1 with gf3 (n=0)\n",
      "Not enough data to correlate gs1 with gf4 (n=0)\n",
      "Not enough data to correlate gs1 with gf5 (n=0)\n",
      "Not enough data to correlate gs1 with gf6 (n=0)\n",
      "Not enough data to correlate gs1 with gf7 (n=0)\n",
      "Not enough data to correlate gs1 with a_hn1 (n=0)\n",
      "Not enough data to correlate gs1 with a_hn2 (n=0)\n",
      "Not enough data to correlate gs1 with a_hn3 (n=0)\n",
      "Not enough data to correlate gs1 with a_hn4 (n=0)\n",
      "Not enough data to correlate gs1 with a_hn5 (n=0)\n",
      "Not enough data to correlate gs1 with a_hn7 (n=0)\n",
      "Not enough data to correlate gs1 with a_hn10 (n=0)\n",
      "Not enough data to correlate gs1 with a_e1 (n=0)\n",
      "Not enough data to correlate gs1 with a_e2 (n=0)\n",
      "Not enough data to correlate gs1 with a_e3 (n=0)\n",
      "Not enough data to correlate gs1 with a_e4 (n=0)\n",
      "Not enough data to correlate gs1 with a_e5 (n=0)\n",
      "Not enough data to correlate gs1 with a_e6 (n=0)\n",
      "Not enough data to correlate gs1 with a_e7 (n=0)\n",
      "Not enough data to correlate gs1 with a_c6 (n=0)\n",
      "Not enough data to correlate gs1 with a_c2 (n=0)\n",
      "Not enough data to correlate gs1 with a_act11 (n=0)\n",
      "Not enough data to correlate gs2 with gp1 (n=0)\n",
      "Not enough data to correlate gs2 with gp2 (n=0)\n",
      "Not enough data to correlate gs2 with gp3 (n=0)\n",
      "Not enough data to correlate gs2 with gp4 (n=0)\n",
      "Not enough data to correlate gs2 with gp5 (n=0)\n",
      "Not enough data to correlate gs2 with gp6 (n=0)\n",
      "Not enough data to correlate gs2 with gp7 (n=0)\n",
      "Not enough data to correlate gs2 with gs1 (n=0)\n",
      "Not enough data to correlate gs2 with gs3 (n=0)\n",
      "Not enough data to correlate gs2 with gs4 (n=0)\n",
      "Not enough data to correlate gs2 with gs5 (n=0)\n",
      "Not enough data to correlate gs2 with gs6 (n=0)\n",
      "Not enough data to correlate gs2 with gs7 (n=0)\n",
      "Not enough data to correlate gs2 with ge1 (n=0)\n",
      "Not enough data to correlate gs2 with ge2 (n=0)\n",
      "Not enough data to correlate gs2 with ge3 (n=0)\n",
      "Not enough data to correlate gs2 with ge4 (n=0)\n",
      "Not enough data to correlate gs2 with ge5 (n=0)\n",
      "Not enough data to correlate gs2 with ge6 (n=0)\n",
      "Not enough data to correlate gs2 with gf1 (n=0)\n",
      "Not enough data to correlate gs2 with gf2 (n=0)\n",
      "Not enough data to correlate gs2 with gf3 (n=0)\n",
      "Not enough data to correlate gs2 with gf4 (n=0)\n",
      "Not enough data to correlate gs2 with gf5 (n=0)\n",
      "Not enough data to correlate gs2 with gf6 (n=0)\n",
      "Not enough data to correlate gs2 with gf7 (n=0)\n",
      "Not enough data to correlate gs2 with a_hn1 (n=0)\n",
      "Not enough data to correlate gs2 with a_hn2 (n=0)\n",
      "Not enough data to correlate gs2 with a_hn3 (n=0)\n",
      "Not enough data to correlate gs2 with a_hn4 (n=0)\n",
      "Not enough data to correlate gs2 with a_hn5 (n=0)\n",
      "Not enough data to correlate gs2 with a_hn7 (n=0)\n",
      "Not enough data to correlate gs2 with a_hn10 (n=0)\n",
      "Not enough data to correlate gs2 with a_e1 (n=0)\n",
      "Not enough data to correlate gs2 with a_e2 (n=0)\n",
      "Not enough data to correlate gs2 with a_e3 (n=0)\n",
      "Not enough data to correlate gs2 with a_e4 (n=0)\n",
      "Not enough data to correlate gs2 with a_e5 (n=0)\n",
      "Not enough data to correlate gs2 with a_e6 (n=0)\n",
      "Not enough data to correlate gs2 with a_e7 (n=0)\n",
      "Not enough data to correlate gs2 with a_c6 (n=0)\n",
      "Not enough data to correlate gs2 with a_c2 (n=0)\n",
      "Not enough data to correlate gs2 with a_act11 (n=0)\n",
      "Not enough data to correlate gs3 with gp1 (n=0)\n",
      "Not enough data to correlate gs3 with gp2 (n=0)\n",
      "Not enough data to correlate gs3 with gp3 (n=0)\n",
      "Not enough data to correlate gs3 with gp4 (n=0)\n",
      "Not enough data to correlate gs3 with gp5 (n=0)\n",
      "Not enough data to correlate gs3 with gp6 (n=0)\n",
      "Not enough data to correlate gs3 with gp7 (n=0)\n",
      "Not enough data to correlate gs3 with gs1 (n=0)\n",
      "Not enough data to correlate gs3 with gs2 (n=0)\n",
      "Not enough data to correlate gs3 with gs4 (n=0)\n",
      "Not enough data to correlate gs3 with gs5 (n=0)\n",
      "Not enough data to correlate gs3 with gs6 (n=0)\n",
      "Not enough data to correlate gs3 with gs7 (n=0)\n",
      "Not enough data to correlate gs3 with ge1 (n=0)\n",
      "Not enough data to correlate gs3 with ge2 (n=0)\n",
      "Not enough data to correlate gs3 with ge3 (n=0)\n",
      "Not enough data to correlate gs3 with ge4 (n=0)\n",
      "Not enough data to correlate gs3 with ge5 (n=0)\n",
      "Not enough data to correlate gs3 with ge6 (n=0)\n",
      "Not enough data to correlate gs3 with gf1 (n=0)\n",
      "Not enough data to correlate gs3 with gf2 (n=0)\n",
      "Not enough data to correlate gs3 with gf3 (n=0)\n",
      "Not enough data to correlate gs3 with gf4 (n=0)\n",
      "Not enough data to correlate gs3 with gf5 (n=0)\n",
      "Not enough data to correlate gs3 with gf6 (n=0)\n",
      "Not enough data to correlate gs3 with gf7 (n=0)\n",
      "Not enough data to correlate gs3 with a_hn1 (n=0)\n",
      "Not enough data to correlate gs3 with a_hn2 (n=0)\n",
      "Not enough data to correlate gs3 with a_hn3 (n=0)\n",
      "Not enough data to correlate gs3 with a_hn4 (n=0)\n",
      "Not enough data to correlate gs3 with a_hn5 (n=0)\n",
      "Not enough data to correlate gs3 with a_hn7 (n=0)\n",
      "Not enough data to correlate gs3 with a_hn10 (n=0)\n",
      "Not enough data to correlate gs3 with a_e1 (n=0)\n",
      "Not enough data to correlate gs3 with a_e2 (n=0)\n",
      "Not enough data to correlate gs3 with a_e3 (n=0)\n",
      "Not enough data to correlate gs3 with a_e4 (n=0)\n",
      "Not enough data to correlate gs3 with a_e5 (n=0)\n",
      "Not enough data to correlate gs3 with a_e6 (n=0)\n",
      "Not enough data to correlate gs3 with a_e7 (n=0)\n",
      "Not enough data to correlate gs3 with a_c6 (n=0)\n",
      "Not enough data to correlate gs3 with a_c2 (n=0)\n",
      "Not enough data to correlate gs3 with a_act11 (n=0)\n",
      "Not enough data to correlate gs4 with gp1 (n=0)\n",
      "Not enough data to correlate gs4 with gp2 (n=0)\n",
      "Not enough data to correlate gs4 with gp3 (n=0)\n",
      "Not enough data to correlate gs4 with gp4 (n=0)\n",
      "Not enough data to correlate gs4 with gp5 (n=0)\n",
      "Not enough data to correlate gs4 with gp6 (n=0)\n",
      "Not enough data to correlate gs4 with gp7 (n=0)\n",
      "Not enough data to correlate gs4 with gs1 (n=0)\n",
      "Not enough data to correlate gs4 with gs2 (n=0)\n",
      "Not enough data to correlate gs4 with gs3 (n=0)\n",
      "Not enough data to correlate gs4 with gs5 (n=0)\n",
      "Not enough data to correlate gs4 with gs6 (n=0)\n",
      "Not enough data to correlate gs4 with gs7 (n=0)\n",
      "Not enough data to correlate gs4 with ge1 (n=0)\n",
      "Not enough data to correlate gs4 with ge2 (n=0)\n",
      "Not enough data to correlate gs4 with ge3 (n=0)\n",
      "Not enough data to correlate gs4 with ge4 (n=0)\n",
      "Not enough data to correlate gs4 with ge5 (n=0)\n",
      "Not enough data to correlate gs4 with ge6 (n=0)\n",
      "Not enough data to correlate gs4 with gf1 (n=0)\n",
      "Not enough data to correlate gs4 with gf2 (n=0)\n",
      "Not enough data to correlate gs4 with gf3 (n=0)\n",
      "Not enough data to correlate gs4 with gf4 (n=0)\n",
      "Not enough data to correlate gs4 with gf5 (n=0)\n",
      "Not enough data to correlate gs4 with gf6 (n=0)\n",
      "Not enough data to correlate gs4 with gf7 (n=0)\n",
      "Not enough data to correlate gs4 with a_hn1 (n=0)\n",
      "Not enough data to correlate gs4 with a_hn2 (n=0)\n",
      "Not enough data to correlate gs4 with a_hn3 (n=0)\n",
      "Not enough data to correlate gs4 with a_hn4 (n=0)\n",
      "Not enough data to correlate gs4 with a_hn5 (n=0)\n",
      "Not enough data to correlate gs4 with a_hn7 (n=0)\n",
      "Not enough data to correlate gs4 with a_hn10 (n=0)\n",
      "Not enough data to correlate gs4 with a_e1 (n=0)\n",
      "Not enough data to correlate gs4 with a_e2 (n=0)\n",
      "Not enough data to correlate gs4 with a_e3 (n=0)\n",
      "Not enough data to correlate gs4 with a_e4 (n=0)\n",
      "Not enough data to correlate gs4 with a_e5 (n=0)\n",
      "Not enough data to correlate gs4 with a_e6 (n=0)\n",
      "Not enough data to correlate gs4 with a_e7 (n=0)\n",
      "Not enough data to correlate gs4 with a_c6 (n=0)\n",
      "Not enough data to correlate gs4 with a_c2 (n=0)\n",
      "Not enough data to correlate gs4 with a_act11 (n=0)\n",
      "Not enough data to correlate gs5 with gp1 (n=0)\n",
      "Not enough data to correlate gs5 with gp2 (n=0)\n",
      "Not enough data to correlate gs5 with gp3 (n=0)\n",
      "Not enough data to correlate gs5 with gp4 (n=0)\n",
      "Not enough data to correlate gs5 with gp5 (n=0)\n",
      "Not enough data to correlate gs5 with gp6 (n=0)\n",
      "Not enough data to correlate gs5 with gp7 (n=0)\n",
      "Not enough data to correlate gs5 with gs1 (n=0)\n",
      "Not enough data to correlate gs5 with gs2 (n=0)\n",
      "Not enough data to correlate gs5 with gs3 (n=0)\n",
      "Not enough data to correlate gs5 with gs4 (n=0)\n",
      "Not enough data to correlate gs5 with gs6 (n=0)\n",
      "Not enough data to correlate gs5 with gs7 (n=0)\n",
      "Not enough data to correlate gs5 with ge1 (n=0)\n",
      "Not enough data to correlate gs5 with ge2 (n=0)\n",
      "Not enough data to correlate gs5 with ge3 (n=0)\n",
      "Not enough data to correlate gs5 with ge4 (n=0)\n",
      "Not enough data to correlate gs5 with ge5 (n=0)\n",
      "Not enough data to correlate gs5 with ge6 (n=0)\n",
      "Not enough data to correlate gs5 with gf1 (n=0)\n",
      "Not enough data to correlate gs5 with gf2 (n=0)\n",
      "Not enough data to correlate gs5 with gf3 (n=0)\n",
      "Not enough data to correlate gs5 with gf4 (n=0)\n",
      "Not enough data to correlate gs5 with gf5 (n=0)\n",
      "Not enough data to correlate gs5 with gf6 (n=0)\n",
      "Not enough data to correlate gs5 with gf7 (n=0)\n",
      "Not enough data to correlate gs5 with a_hn1 (n=0)\n",
      "Not enough data to correlate gs5 with a_hn2 (n=0)\n",
      "Not enough data to correlate gs5 with a_hn3 (n=0)\n",
      "Not enough data to correlate gs5 with a_hn4 (n=0)\n",
      "Not enough data to correlate gs5 with a_hn5 (n=0)\n",
      "Not enough data to correlate gs5 with a_hn7 (n=0)\n",
      "Not enough data to correlate gs5 with a_hn10 (n=0)\n",
      "Not enough data to correlate gs5 with a_e1 (n=0)\n",
      "Not enough data to correlate gs5 with a_e2 (n=0)\n",
      "Not enough data to correlate gs5 with a_e3 (n=0)\n",
      "Not enough data to correlate gs5 with a_e4 (n=0)\n",
      "Not enough data to correlate gs5 with a_e5 (n=0)\n",
      "Not enough data to correlate gs5 with a_e6 (n=0)\n",
      "Not enough data to correlate gs5 with a_e7 (n=0)\n",
      "Not enough data to correlate gs5 with a_c6 (n=0)\n",
      "Not enough data to correlate gs5 with a_c2 (n=0)\n",
      "Not enough data to correlate gs5 with a_act11 (n=0)\n",
      "Not enough data to correlate gs6 with gp1 (n=0)\n",
      "Not enough data to correlate gs6 with gp2 (n=0)\n",
      "Not enough data to correlate gs6 with gp3 (n=0)\n",
      "Not enough data to correlate gs6 with gp4 (n=0)\n",
      "Not enough data to correlate gs6 with gp5 (n=0)\n",
      "Not enough data to correlate gs6 with gp6 (n=0)\n",
      "Not enough data to correlate gs6 with gp7 (n=0)\n",
      "Not enough data to correlate gs6 with gs1 (n=0)\n",
      "Not enough data to correlate gs6 with gs2 (n=0)\n",
      "Not enough data to correlate gs6 with gs3 (n=0)\n",
      "Not enough data to correlate gs6 with gs4 (n=0)\n",
      "Not enough data to correlate gs6 with gs5 (n=0)\n",
      "Not enough data to correlate gs6 with gs7 (n=0)\n",
      "Not enough data to correlate gs6 with ge1 (n=0)\n",
      "Not enough data to correlate gs6 with ge2 (n=0)\n",
      "Not enough data to correlate gs6 with ge3 (n=0)\n",
      "Not enough data to correlate gs6 with ge4 (n=0)\n",
      "Not enough data to correlate gs6 with ge5 (n=0)\n",
      "Not enough data to correlate gs6 with ge6 (n=0)\n",
      "Not enough data to correlate gs6 with gf1 (n=0)\n",
      "Not enough data to correlate gs6 with gf2 (n=0)\n",
      "Not enough data to correlate gs6 with gf3 (n=0)\n",
      "Not enough data to correlate gs6 with gf4 (n=0)\n",
      "Not enough data to correlate gs6 with gf5 (n=0)\n",
      "Not enough data to correlate gs6 with gf6 (n=0)\n",
      "Not enough data to correlate gs6 with gf7 (n=0)\n",
      "Not enough data to correlate gs6 with a_hn1 (n=0)\n",
      "Not enough data to correlate gs6 with a_hn2 (n=0)\n",
      "Not enough data to correlate gs6 with a_hn3 (n=0)\n",
      "Not enough data to correlate gs6 with a_hn4 (n=0)\n",
      "Not enough data to correlate gs6 with a_hn5 (n=0)\n",
      "Not enough data to correlate gs6 with a_hn7 (n=0)\n",
      "Not enough data to correlate gs6 with a_hn10 (n=0)\n",
      "Not enough data to correlate gs6 with a_e1 (n=0)\n",
      "Not enough data to correlate gs6 with a_e2 (n=0)\n",
      "Not enough data to correlate gs6 with a_e3 (n=0)\n",
      "Not enough data to correlate gs6 with a_e4 (n=0)\n",
      "Not enough data to correlate gs6 with a_e5 (n=0)\n",
      "Not enough data to correlate gs6 with a_e6 (n=0)\n",
      "Not enough data to correlate gs6 with a_e7 (n=0)\n",
      "Not enough data to correlate gs6 with a_c6 (n=0)\n",
      "Not enough data to correlate gs6 with a_c2 (n=0)\n",
      "Not enough data to correlate gs6 with a_act11 (n=0)\n",
      "Not enough data to correlate gs7 with gp1 (n=0)\n",
      "Not enough data to correlate gs7 with gp2 (n=0)\n",
      "Not enough data to correlate gs7 with gp3 (n=0)\n",
      "Not enough data to correlate gs7 with gp4 (n=0)\n",
      "Not enough data to correlate gs7 with gp5 (n=0)\n",
      "Not enough data to correlate gs7 with gp6 (n=0)\n",
      "Not enough data to correlate gs7 with gp7 (n=0)\n",
      "Not enough data to correlate gs7 with gs1 (n=0)\n",
      "Not enough data to correlate gs7 with gs2 (n=0)\n",
      "Not enough data to correlate gs7 with gs3 (n=0)\n",
      "Not enough data to correlate gs7 with gs4 (n=0)\n",
      "Not enough data to correlate gs7 with gs5 (n=0)\n",
      "Not enough data to correlate gs7 with gs6 (n=0)\n",
      "Not enough data to correlate gs7 with ge1 (n=0)\n",
      "Not enough data to correlate gs7 with ge2 (n=0)\n",
      "Not enough data to correlate gs7 with ge3 (n=0)\n",
      "Not enough data to correlate gs7 with ge4 (n=0)\n",
      "Not enough data to correlate gs7 with ge5 (n=0)\n",
      "Not enough data to correlate gs7 with ge6 (n=0)\n",
      "Not enough data to correlate gs7 with gf1 (n=0)\n",
      "Not enough data to correlate gs7 with gf2 (n=0)\n",
      "Not enough data to correlate gs7 with gf3 (n=0)\n",
      "Not enough data to correlate gs7 with gf4 (n=0)\n",
      "Not enough data to correlate gs7 with gf5 (n=0)\n",
      "Not enough data to correlate gs7 with gf6 (n=0)\n",
      "Not enough data to correlate gs7 with gf7 (n=0)\n",
      "Not enough data to correlate gs7 with a_hn1 (n=0)\n",
      "Not enough data to correlate gs7 with a_hn2 (n=0)\n",
      "Not enough data to correlate gs7 with a_hn3 (n=0)\n",
      "Not enough data to correlate gs7 with a_hn4 (n=0)\n",
      "Not enough data to correlate gs7 with a_hn5 (n=0)\n",
      "Not enough data to correlate gs7 with a_hn7 (n=0)\n",
      "Not enough data to correlate gs7 with a_hn10 (n=0)\n",
      "Not enough data to correlate gs7 with a_e1 (n=0)\n",
      "Not enough data to correlate gs7 with a_e2 (n=0)\n",
      "Not enough data to correlate gs7 with a_e3 (n=0)\n",
      "Not enough data to correlate gs7 with a_e4 (n=0)\n",
      "Not enough data to correlate gs7 with a_e5 (n=0)\n",
      "Not enough data to correlate gs7 with a_e6 (n=0)\n",
      "Not enough data to correlate gs7 with a_e7 (n=0)\n",
      "Not enough data to correlate gs7 with a_c6 (n=0)\n",
      "Not enough data to correlate gs7 with a_c2 (n=0)\n",
      "Not enough data to correlate gs7 with a_act11 (n=0)\n",
      "Not enough data to correlate ge1 with gp1 (n=0)\n",
      "Not enough data to correlate ge1 with gp2 (n=0)\n",
      "Not enough data to correlate ge1 with gp3 (n=0)\n",
      "Not enough data to correlate ge1 with gp4 (n=0)\n",
      "Not enough data to correlate ge1 with gp5 (n=0)\n",
      "Not enough data to correlate ge1 with gp6 (n=0)\n",
      "Not enough data to correlate ge1 with gp7 (n=0)\n",
      "Not enough data to correlate ge1 with gs1 (n=0)\n",
      "Not enough data to correlate ge1 with gs2 (n=0)\n",
      "Not enough data to correlate ge1 with gs3 (n=0)\n",
      "Not enough data to correlate ge1 with gs4 (n=0)\n",
      "Not enough data to correlate ge1 with gs5 (n=0)\n",
      "Not enough data to correlate ge1 with gs6 (n=0)\n",
      "Not enough data to correlate ge1 with gs7 (n=0)\n",
      "Not enough data to correlate ge1 with ge2 (n=0)\n",
      "Not enough data to correlate ge1 with ge3 (n=0)\n",
      "Not enough data to correlate ge1 with ge4 (n=0)\n",
      "Not enough data to correlate ge1 with ge5 (n=0)\n",
      "Not enough data to correlate ge1 with ge6 (n=0)\n",
      "Not enough data to correlate ge1 with gf1 (n=0)\n",
      "Not enough data to correlate ge1 with gf2 (n=0)\n",
      "Not enough data to correlate ge1 with gf3 (n=0)\n",
      "Not enough data to correlate ge1 with gf4 (n=0)\n",
      "Not enough data to correlate ge1 with gf5 (n=0)\n",
      "Not enough data to correlate ge1 with gf6 (n=0)\n",
      "Not enough data to correlate ge1 with gf7 (n=0)\n",
      "Not enough data to correlate ge1 with a_hn1 (n=0)\n",
      "Not enough data to correlate ge1 with a_hn2 (n=0)\n",
      "Not enough data to correlate ge1 with a_hn3 (n=0)\n",
      "Not enough data to correlate ge1 with a_hn4 (n=0)\n",
      "Not enough data to correlate ge1 with a_hn5 (n=0)\n",
      "Not enough data to correlate ge1 with a_hn7 (n=0)\n",
      "Not enough data to correlate ge1 with a_hn10 (n=0)\n",
      "Not enough data to correlate ge1 with a_e1 (n=0)\n",
      "Not enough data to correlate ge1 with a_e2 (n=0)\n",
      "Not enough data to correlate ge1 with a_e3 (n=0)\n",
      "Not enough data to correlate ge1 with a_e4 (n=0)\n",
      "Not enough data to correlate ge1 with a_e5 (n=0)\n",
      "Not enough data to correlate ge1 with a_e6 (n=0)\n",
      "Not enough data to correlate ge1 with a_e7 (n=0)\n",
      "Not enough data to correlate ge1 with a_c6 (n=0)\n",
      "Not enough data to correlate ge1 with a_c2 (n=0)\n",
      "Not enough data to correlate ge1 with a_act11 (n=0)\n",
      "Not enough data to correlate ge2 with gp1 (n=0)\n",
      "Not enough data to correlate ge2 with gp2 (n=0)\n",
      "Not enough data to correlate ge2 with gp3 (n=0)\n",
      "Not enough data to correlate ge2 with gp4 (n=0)\n",
      "Not enough data to correlate ge2 with gp5 (n=0)\n",
      "Not enough data to correlate ge2 with gp6 (n=0)\n",
      "Not enough data to correlate ge2 with gp7 (n=0)\n",
      "Not enough data to correlate ge2 with gs1 (n=0)\n",
      "Not enough data to correlate ge2 with gs2 (n=0)\n",
      "Not enough data to correlate ge2 with gs3 (n=0)\n",
      "Not enough data to correlate ge2 with gs4 (n=0)\n",
      "Not enough data to correlate ge2 with gs5 (n=0)\n",
      "Not enough data to correlate ge2 with gs6 (n=0)\n",
      "Not enough data to correlate ge2 with gs7 (n=0)\n",
      "Not enough data to correlate ge2 with ge1 (n=0)\n",
      "Not enough data to correlate ge2 with ge3 (n=0)\n",
      "Not enough data to correlate ge2 with ge4 (n=0)\n",
      "Not enough data to correlate ge2 with ge5 (n=0)\n",
      "Not enough data to correlate ge2 with ge6 (n=0)\n",
      "Not enough data to correlate ge2 with gf1 (n=0)\n",
      "Not enough data to correlate ge2 with gf2 (n=0)\n",
      "Not enough data to correlate ge2 with gf3 (n=0)\n",
      "Not enough data to correlate ge2 with gf4 (n=0)\n",
      "Not enough data to correlate ge2 with gf5 (n=0)\n",
      "Not enough data to correlate ge2 with gf6 (n=0)\n",
      "Not enough data to correlate ge2 with gf7 (n=0)\n",
      "Not enough data to correlate ge2 with a_hn1 (n=0)\n",
      "Not enough data to correlate ge2 with a_hn2 (n=0)\n",
      "Not enough data to correlate ge2 with a_hn3 (n=0)\n",
      "Not enough data to correlate ge2 with a_hn4 (n=0)\n",
      "Not enough data to correlate ge2 with a_hn5 (n=0)\n",
      "Not enough data to correlate ge2 with a_hn7 (n=0)\n",
      "Not enough data to correlate ge2 with a_hn10 (n=0)\n",
      "Not enough data to correlate ge2 with a_e1 (n=0)\n",
      "Not enough data to correlate ge2 with a_e2 (n=0)\n",
      "Not enough data to correlate ge2 with a_e3 (n=0)\n",
      "Not enough data to correlate ge2 with a_e4 (n=0)\n",
      "Not enough data to correlate ge2 with a_e5 (n=0)\n",
      "Not enough data to correlate ge2 with a_e6 (n=0)\n",
      "Not enough data to correlate ge2 with a_e7 (n=0)\n",
      "Not enough data to correlate ge2 with a_c6 (n=0)\n",
      "Not enough data to correlate ge2 with a_c2 (n=0)\n",
      "Not enough data to correlate ge2 with a_act11 (n=0)\n",
      "Not enough data to correlate ge3 with gp1 (n=0)\n",
      "Not enough data to correlate ge3 with gp2 (n=0)\n",
      "Not enough data to correlate ge3 with gp3 (n=0)\n",
      "Not enough data to correlate ge3 with gp4 (n=0)\n",
      "Not enough data to correlate ge3 with gp5 (n=0)\n",
      "Not enough data to correlate ge3 with gp6 (n=0)\n",
      "Not enough data to correlate ge3 with gp7 (n=0)\n",
      "Not enough data to correlate ge3 with gs1 (n=0)\n",
      "Not enough data to correlate ge3 with gs2 (n=0)\n",
      "Not enough data to correlate ge3 with gs3 (n=0)\n",
      "Not enough data to correlate ge3 with gs4 (n=0)\n",
      "Not enough data to correlate ge3 with gs5 (n=0)\n",
      "Not enough data to correlate ge3 with gs6 (n=0)\n",
      "Not enough data to correlate ge3 with gs7 (n=0)\n",
      "Not enough data to correlate ge3 with ge1 (n=0)\n",
      "Not enough data to correlate ge3 with ge2 (n=0)\n",
      "Not enough data to correlate ge3 with ge4 (n=0)\n",
      "Not enough data to correlate ge3 with ge5 (n=0)\n",
      "Not enough data to correlate ge3 with ge6 (n=0)\n",
      "Not enough data to correlate ge3 with gf1 (n=0)\n",
      "Not enough data to correlate ge3 with gf2 (n=0)\n",
      "Not enough data to correlate ge3 with gf3 (n=0)\n",
      "Not enough data to correlate ge3 with gf4 (n=0)\n",
      "Not enough data to correlate ge3 with gf5 (n=0)\n",
      "Not enough data to correlate ge3 with gf6 (n=0)\n",
      "Not enough data to correlate ge3 with gf7 (n=0)\n",
      "Not enough data to correlate ge3 with a_hn1 (n=0)\n",
      "Not enough data to correlate ge3 with a_hn2 (n=0)\n",
      "Not enough data to correlate ge3 with a_hn3 (n=0)\n",
      "Not enough data to correlate ge3 with a_hn4 (n=0)\n",
      "Not enough data to correlate ge3 with a_hn5 (n=0)\n",
      "Not enough data to correlate ge3 with a_hn7 (n=0)\n",
      "Not enough data to correlate ge3 with a_hn10 (n=0)\n",
      "Not enough data to correlate ge3 with a_e1 (n=0)\n",
      "Not enough data to correlate ge3 with a_e2 (n=0)\n",
      "Not enough data to correlate ge3 with a_e3 (n=0)\n",
      "Not enough data to correlate ge3 with a_e4 (n=0)\n",
      "Not enough data to correlate ge3 with a_e5 (n=0)\n",
      "Not enough data to correlate ge3 with a_e6 (n=0)\n",
      "Not enough data to correlate ge3 with a_e7 (n=0)\n",
      "Not enough data to correlate ge3 with a_c6 (n=0)\n",
      "Not enough data to correlate ge3 with a_c2 (n=0)\n",
      "Not enough data to correlate ge3 with a_act11 (n=0)\n",
      "Not enough data to correlate ge4 with gp1 (n=0)\n",
      "Not enough data to correlate ge4 with gp2 (n=0)\n",
      "Not enough data to correlate ge4 with gp3 (n=0)\n",
      "Not enough data to correlate ge4 with gp4 (n=0)\n",
      "Not enough data to correlate ge4 with gp5 (n=0)\n",
      "Not enough data to correlate ge4 with gp6 (n=0)\n",
      "Not enough data to correlate ge4 with gp7 (n=0)\n",
      "Not enough data to correlate ge4 with gs1 (n=0)\n",
      "Not enough data to correlate ge4 with gs2 (n=0)\n",
      "Not enough data to correlate ge4 with gs3 (n=0)\n",
      "Not enough data to correlate ge4 with gs4 (n=0)\n",
      "Not enough data to correlate ge4 with gs5 (n=0)\n",
      "Not enough data to correlate ge4 with gs6 (n=0)\n",
      "Not enough data to correlate ge4 with gs7 (n=0)\n",
      "Not enough data to correlate ge4 with ge1 (n=0)\n",
      "Not enough data to correlate ge4 with ge2 (n=0)\n",
      "Not enough data to correlate ge4 with ge3 (n=0)\n",
      "Not enough data to correlate ge4 with ge5 (n=0)\n",
      "Not enough data to correlate ge4 with ge6 (n=0)\n",
      "Not enough data to correlate ge4 with gf1 (n=0)\n",
      "Not enough data to correlate ge4 with gf2 (n=0)\n",
      "Not enough data to correlate ge4 with gf3 (n=0)\n",
      "Not enough data to correlate ge4 with gf4 (n=0)\n",
      "Not enough data to correlate ge4 with gf5 (n=0)\n",
      "Not enough data to correlate ge4 with gf6 (n=0)\n",
      "Not enough data to correlate ge4 with gf7 (n=0)\n",
      "Not enough data to correlate ge4 with a_hn1 (n=0)\n",
      "Not enough data to correlate ge4 with a_hn2 (n=0)\n",
      "Not enough data to correlate ge4 with a_hn3 (n=0)\n",
      "Not enough data to correlate ge4 with a_hn4 (n=0)\n",
      "Not enough data to correlate ge4 with a_hn5 (n=0)\n",
      "Not enough data to correlate ge4 with a_hn7 (n=0)\n",
      "Not enough data to correlate ge4 with a_hn10 (n=0)\n",
      "Not enough data to correlate ge4 with a_e1 (n=0)\n",
      "Not enough data to correlate ge4 with a_e2 (n=0)\n",
      "Not enough data to correlate ge4 with a_e3 (n=0)\n",
      "Not enough data to correlate ge4 with a_e4 (n=0)\n",
      "Not enough data to correlate ge4 with a_e5 (n=0)\n",
      "Not enough data to correlate ge4 with a_e6 (n=0)\n",
      "Not enough data to correlate ge4 with a_e7 (n=0)\n",
      "Not enough data to correlate ge4 with a_c6 (n=0)\n",
      "Not enough data to correlate ge4 with a_c2 (n=0)\n",
      "Not enough data to correlate ge4 with a_act11 (n=0)\n",
      "Not enough data to correlate ge5 with gp1 (n=0)\n",
      "Not enough data to correlate ge5 with gp2 (n=0)\n",
      "Not enough data to correlate ge5 with gp3 (n=0)\n",
      "Not enough data to correlate ge5 with gp4 (n=0)\n",
      "Not enough data to correlate ge5 with gp5 (n=0)\n",
      "Not enough data to correlate ge5 with gp6 (n=0)\n",
      "Not enough data to correlate ge5 with gp7 (n=0)\n",
      "Not enough data to correlate ge5 with gs1 (n=0)\n",
      "Not enough data to correlate ge5 with gs2 (n=0)\n",
      "Not enough data to correlate ge5 with gs3 (n=0)\n",
      "Not enough data to correlate ge5 with gs4 (n=0)\n",
      "Not enough data to correlate ge5 with gs5 (n=0)\n",
      "Not enough data to correlate ge5 with gs6 (n=0)\n",
      "Not enough data to correlate ge5 with gs7 (n=0)\n",
      "Not enough data to correlate ge5 with ge1 (n=0)\n",
      "Not enough data to correlate ge5 with ge2 (n=0)\n",
      "Not enough data to correlate ge5 with ge3 (n=0)\n",
      "Not enough data to correlate ge5 with ge4 (n=0)\n",
      "Not enough data to correlate ge5 with ge6 (n=0)\n",
      "Not enough data to correlate ge5 with gf1 (n=0)\n",
      "Not enough data to correlate ge5 with gf2 (n=0)\n",
      "Not enough data to correlate ge5 with gf3 (n=0)\n",
      "Not enough data to correlate ge5 with gf4 (n=0)\n",
      "Not enough data to correlate ge5 with gf5 (n=0)\n",
      "Not enough data to correlate ge5 with gf6 (n=0)\n",
      "Not enough data to correlate ge5 with gf7 (n=0)\n",
      "Not enough data to correlate ge5 with a_hn1 (n=0)\n",
      "Not enough data to correlate ge5 with a_hn2 (n=0)\n",
      "Not enough data to correlate ge5 with a_hn3 (n=0)\n",
      "Not enough data to correlate ge5 with a_hn4 (n=0)\n",
      "Not enough data to correlate ge5 with a_hn5 (n=0)\n",
      "Not enough data to correlate ge5 with a_hn7 (n=0)\n",
      "Not enough data to correlate ge5 with a_hn10 (n=0)\n",
      "Not enough data to correlate ge5 with a_e1 (n=0)\n",
      "Not enough data to correlate ge5 with a_e2 (n=0)\n",
      "Not enough data to correlate ge5 with a_e3 (n=0)\n",
      "Not enough data to correlate ge5 with a_e4 (n=0)\n",
      "Not enough data to correlate ge5 with a_e5 (n=0)\n",
      "Not enough data to correlate ge5 with a_e6 (n=0)\n",
      "Not enough data to correlate ge5 with a_e7 (n=0)\n",
      "Not enough data to correlate ge5 with a_c6 (n=0)\n",
      "Not enough data to correlate ge5 with a_c2 (n=0)\n",
      "Not enough data to correlate ge5 with a_act11 (n=0)\n",
      "Not enough data to correlate ge6 with gp1 (n=0)\n",
      "Not enough data to correlate ge6 with gp2 (n=0)\n",
      "Not enough data to correlate ge6 with gp3 (n=0)\n",
      "Not enough data to correlate ge6 with gp4 (n=0)\n",
      "Not enough data to correlate ge6 with gp5 (n=0)\n",
      "Not enough data to correlate ge6 with gp6 (n=0)\n",
      "Not enough data to correlate ge6 with gp7 (n=0)\n",
      "Not enough data to correlate ge6 with gs1 (n=0)\n",
      "Not enough data to correlate ge6 with gs2 (n=0)\n",
      "Not enough data to correlate ge6 with gs3 (n=0)\n",
      "Not enough data to correlate ge6 with gs4 (n=0)\n",
      "Not enough data to correlate ge6 with gs5 (n=0)\n",
      "Not enough data to correlate ge6 with gs6 (n=0)\n",
      "Not enough data to correlate ge6 with gs7 (n=0)\n",
      "Not enough data to correlate ge6 with ge1 (n=0)\n",
      "Not enough data to correlate ge6 with ge2 (n=0)\n",
      "Not enough data to correlate ge6 with ge3 (n=0)\n",
      "Not enough data to correlate ge6 with ge4 (n=0)\n",
      "Not enough data to correlate ge6 with ge5 (n=0)\n",
      "Not enough data to correlate ge6 with gf1 (n=0)\n",
      "Not enough data to correlate ge6 with gf2 (n=0)\n",
      "Not enough data to correlate ge6 with gf3 (n=0)\n",
      "Not enough data to correlate ge6 with gf4 (n=0)\n",
      "Not enough data to correlate ge6 with gf5 (n=0)\n",
      "Not enough data to correlate ge6 with gf6 (n=0)\n",
      "Not enough data to correlate ge6 with gf7 (n=0)\n",
      "Not enough data to correlate ge6 with a_hn1 (n=0)\n",
      "Not enough data to correlate ge6 with a_hn2 (n=0)\n",
      "Not enough data to correlate ge6 with a_hn3 (n=0)\n",
      "Not enough data to correlate ge6 with a_hn4 (n=0)\n",
      "Not enough data to correlate ge6 with a_hn5 (n=0)\n",
      "Not enough data to correlate ge6 with a_hn7 (n=0)\n",
      "Not enough data to correlate ge6 with a_hn10 (n=0)\n",
      "Not enough data to correlate ge6 with a_e1 (n=0)\n",
      "Not enough data to correlate ge6 with a_e2 (n=0)\n",
      "Not enough data to correlate ge6 with a_e3 (n=0)\n",
      "Not enough data to correlate ge6 with a_e4 (n=0)\n",
      "Not enough data to correlate ge6 with a_e5 (n=0)\n",
      "Not enough data to correlate ge6 with a_e6 (n=0)\n",
      "Not enough data to correlate ge6 with a_e7 (n=0)\n",
      "Not enough data to correlate ge6 with a_c6 (n=0)\n",
      "Not enough data to correlate ge6 with a_c2 (n=0)\n",
      "Not enough data to correlate ge6 with a_act11 (n=0)\n",
      "Not enough data to correlate gf1 with gp1 (n=0)\n",
      "Not enough data to correlate gf1 with gp2 (n=0)\n",
      "Not enough data to correlate gf1 with gp3 (n=0)\n",
      "Not enough data to correlate gf1 with gp4 (n=0)\n",
      "Not enough data to correlate gf1 with gp5 (n=0)\n",
      "Not enough data to correlate gf1 with gp6 (n=0)\n",
      "Not enough data to correlate gf1 with gp7 (n=0)\n",
      "Not enough data to correlate gf1 with gs1 (n=0)\n",
      "Not enough data to correlate gf1 with gs2 (n=0)\n",
      "Not enough data to correlate gf1 with gs3 (n=0)\n",
      "Not enough data to correlate gf1 with gs4 (n=0)\n",
      "Not enough data to correlate gf1 with gs5 (n=0)\n",
      "Not enough data to correlate gf1 with gs6 (n=0)\n",
      "Not enough data to correlate gf1 with gs7 (n=0)\n",
      "Not enough data to correlate gf1 with ge1 (n=0)\n",
      "Not enough data to correlate gf1 with ge2 (n=0)\n",
      "Not enough data to correlate gf1 with ge3 (n=0)\n",
      "Not enough data to correlate gf1 with ge4 (n=0)\n",
      "Not enough data to correlate gf1 with ge5 (n=0)\n",
      "Not enough data to correlate gf1 with ge6 (n=0)\n",
      "Not enough data to correlate gf1 with gf2 (n=0)\n",
      "Not enough data to correlate gf1 with gf3 (n=0)\n",
      "Not enough data to correlate gf1 with gf4 (n=0)\n",
      "Not enough data to correlate gf1 with gf5 (n=0)\n",
      "Not enough data to correlate gf1 with gf6 (n=0)\n",
      "Not enough data to correlate gf1 with gf7 (n=0)\n",
      "Not enough data to correlate gf1 with a_hn1 (n=0)\n",
      "Not enough data to correlate gf1 with a_hn2 (n=0)\n",
      "Not enough data to correlate gf1 with a_hn3 (n=0)\n",
      "Not enough data to correlate gf1 with a_hn4 (n=0)\n",
      "Not enough data to correlate gf1 with a_hn5 (n=0)\n",
      "Not enough data to correlate gf1 with a_hn7 (n=0)\n",
      "Not enough data to correlate gf1 with a_hn10 (n=0)\n",
      "Not enough data to correlate gf1 with a_e1 (n=0)\n",
      "Not enough data to correlate gf1 with a_e2 (n=0)\n",
      "Not enough data to correlate gf1 with a_e3 (n=0)\n",
      "Not enough data to correlate gf1 with a_e4 (n=0)\n",
      "Not enough data to correlate gf1 with a_e5 (n=0)\n",
      "Not enough data to correlate gf1 with a_e6 (n=0)\n",
      "Not enough data to correlate gf1 with a_e7 (n=0)\n",
      "Not enough data to correlate gf1 with a_c6 (n=0)\n",
      "Not enough data to correlate gf1 with a_c2 (n=0)\n",
      "Not enough data to correlate gf1 with a_act11 (n=0)\n",
      "Not enough data to correlate gf2 with gp1 (n=0)\n",
      "Not enough data to correlate gf2 with gp2 (n=0)\n",
      "Not enough data to correlate gf2 with gp3 (n=0)\n",
      "Not enough data to correlate gf2 with gp4 (n=0)\n",
      "Not enough data to correlate gf2 with gp5 (n=0)\n",
      "Not enough data to correlate gf2 with gp6 (n=0)\n",
      "Not enough data to correlate gf2 with gp7 (n=0)\n",
      "Not enough data to correlate gf2 with gs1 (n=0)\n",
      "Not enough data to correlate gf2 with gs2 (n=0)\n",
      "Not enough data to correlate gf2 with gs3 (n=0)\n",
      "Not enough data to correlate gf2 with gs4 (n=0)\n",
      "Not enough data to correlate gf2 with gs5 (n=0)\n",
      "Not enough data to correlate gf2 with gs6 (n=0)\n",
      "Not enough data to correlate gf2 with gs7 (n=0)\n",
      "Not enough data to correlate gf2 with ge1 (n=0)\n",
      "Not enough data to correlate gf2 with ge2 (n=0)\n",
      "Not enough data to correlate gf2 with ge3 (n=0)\n",
      "Not enough data to correlate gf2 with ge4 (n=0)\n",
      "Not enough data to correlate gf2 with ge5 (n=0)\n",
      "Not enough data to correlate gf2 with ge6 (n=0)\n",
      "Not enough data to correlate gf2 with gf1 (n=0)\n",
      "Not enough data to correlate gf2 with gf3 (n=0)\n",
      "Not enough data to correlate gf2 with gf4 (n=0)\n",
      "Not enough data to correlate gf2 with gf5 (n=0)\n",
      "Not enough data to correlate gf2 with gf6 (n=0)\n",
      "Not enough data to correlate gf2 with gf7 (n=0)\n",
      "Not enough data to correlate gf2 with a_hn1 (n=0)\n",
      "Not enough data to correlate gf2 with a_hn2 (n=0)\n",
      "Not enough data to correlate gf2 with a_hn3 (n=0)\n",
      "Not enough data to correlate gf2 with a_hn4 (n=0)\n",
      "Not enough data to correlate gf2 with a_hn5 (n=0)\n",
      "Not enough data to correlate gf2 with a_hn7 (n=0)\n",
      "Not enough data to correlate gf2 with a_hn10 (n=0)\n",
      "Not enough data to correlate gf2 with a_e1 (n=0)\n",
      "Not enough data to correlate gf2 with a_e2 (n=0)\n",
      "Not enough data to correlate gf2 with a_e3 (n=0)\n",
      "Not enough data to correlate gf2 with a_e4 (n=0)\n",
      "Not enough data to correlate gf2 with a_e5 (n=0)\n",
      "Not enough data to correlate gf2 with a_e6 (n=0)\n",
      "Not enough data to correlate gf2 with a_e7 (n=0)\n",
      "Not enough data to correlate gf2 with a_c6 (n=0)\n",
      "Not enough data to correlate gf2 with a_c2 (n=0)\n",
      "Not enough data to correlate gf2 with a_act11 (n=0)\n",
      "Not enough data to correlate gf3 with gp1 (n=0)\n",
      "Not enough data to correlate gf3 with gp2 (n=0)\n",
      "Not enough data to correlate gf3 with gp3 (n=0)\n",
      "Not enough data to correlate gf3 with gp4 (n=0)\n",
      "Not enough data to correlate gf3 with gp5 (n=0)\n",
      "Not enough data to correlate gf3 with gp6 (n=0)\n",
      "Not enough data to correlate gf3 with gp7 (n=0)\n",
      "Not enough data to correlate gf3 with gs1 (n=0)\n",
      "Not enough data to correlate gf3 with gs2 (n=0)\n",
      "Not enough data to correlate gf3 with gs3 (n=0)\n",
      "Not enough data to correlate gf3 with gs4 (n=0)\n",
      "Not enough data to correlate gf3 with gs5 (n=0)\n",
      "Not enough data to correlate gf3 with gs6 (n=0)\n",
      "Not enough data to correlate gf3 with gs7 (n=0)\n",
      "Not enough data to correlate gf3 with ge1 (n=0)\n",
      "Not enough data to correlate gf3 with ge2 (n=0)\n",
      "Not enough data to correlate gf3 with ge3 (n=0)\n",
      "Not enough data to correlate gf3 with ge4 (n=0)\n",
      "Not enough data to correlate gf3 with ge5 (n=0)\n",
      "Not enough data to correlate gf3 with ge6 (n=0)\n",
      "Not enough data to correlate gf3 with gf1 (n=0)\n",
      "Not enough data to correlate gf3 with gf2 (n=0)\n",
      "Not enough data to correlate gf3 with gf4 (n=0)\n",
      "Not enough data to correlate gf3 with gf5 (n=0)\n",
      "Not enough data to correlate gf3 with gf6 (n=0)\n",
      "Not enough data to correlate gf3 with gf7 (n=0)\n",
      "Not enough data to correlate gf3 with a_hn1 (n=0)\n",
      "Not enough data to correlate gf3 with a_hn2 (n=0)\n",
      "Not enough data to correlate gf3 with a_hn3 (n=0)\n",
      "Not enough data to correlate gf3 with a_hn4 (n=0)\n",
      "Not enough data to correlate gf3 with a_hn5 (n=0)\n",
      "Not enough data to correlate gf3 with a_hn7 (n=0)\n",
      "Not enough data to correlate gf3 with a_hn10 (n=0)\n",
      "Not enough data to correlate gf3 with a_e1 (n=0)\n",
      "Not enough data to correlate gf3 with a_e2 (n=0)\n",
      "Not enough data to correlate gf3 with a_e3 (n=0)\n",
      "Not enough data to correlate gf3 with a_e4 (n=0)\n",
      "Not enough data to correlate gf3 with a_e5 (n=0)\n",
      "Not enough data to correlate gf3 with a_e6 (n=0)\n",
      "Not enough data to correlate gf3 with a_e7 (n=0)\n",
      "Not enough data to correlate gf3 with a_c6 (n=0)\n",
      "Not enough data to correlate gf3 with a_c2 (n=0)\n",
      "Not enough data to correlate gf3 with a_act11 (n=0)\n",
      "Not enough data to correlate gf4 with gp1 (n=0)\n",
      "Not enough data to correlate gf4 with gp2 (n=0)\n",
      "Not enough data to correlate gf4 with gp3 (n=0)\n",
      "Not enough data to correlate gf4 with gp4 (n=0)\n",
      "Not enough data to correlate gf4 with gp5 (n=0)\n",
      "Not enough data to correlate gf4 with gp6 (n=0)\n",
      "Not enough data to correlate gf4 with gp7 (n=0)\n",
      "Not enough data to correlate gf4 with gs1 (n=0)\n",
      "Not enough data to correlate gf4 with gs2 (n=0)\n",
      "Not enough data to correlate gf4 with gs3 (n=0)\n",
      "Not enough data to correlate gf4 with gs4 (n=0)\n",
      "Not enough data to correlate gf4 with gs5 (n=0)\n",
      "Not enough data to correlate gf4 with gs6 (n=0)\n",
      "Not enough data to correlate gf4 with gs7 (n=0)\n",
      "Not enough data to correlate gf4 with ge1 (n=0)\n",
      "Not enough data to correlate gf4 with ge2 (n=0)\n",
      "Not enough data to correlate gf4 with ge3 (n=0)\n",
      "Not enough data to correlate gf4 with ge4 (n=0)\n",
      "Not enough data to correlate gf4 with ge5 (n=0)\n",
      "Not enough data to correlate gf4 with ge6 (n=0)\n",
      "Not enough data to correlate gf4 with gf1 (n=0)\n",
      "Not enough data to correlate gf4 with gf2 (n=0)\n",
      "Not enough data to correlate gf4 with gf3 (n=0)\n",
      "Not enough data to correlate gf4 with gf5 (n=0)\n",
      "Not enough data to correlate gf4 with gf6 (n=0)\n",
      "Not enough data to correlate gf4 with gf7 (n=0)\n",
      "Not enough data to correlate gf4 with a_hn1 (n=0)\n",
      "Not enough data to correlate gf4 with a_hn2 (n=0)\n",
      "Not enough data to correlate gf4 with a_hn3 (n=0)\n",
      "Not enough data to correlate gf4 with a_hn4 (n=0)\n",
      "Not enough data to correlate gf4 with a_hn5 (n=0)\n",
      "Not enough data to correlate gf4 with a_hn7 (n=0)\n",
      "Not enough data to correlate gf4 with a_hn10 (n=0)\n",
      "Not enough data to correlate gf4 with a_e1 (n=0)\n",
      "Not enough data to correlate gf4 with a_e2 (n=0)\n",
      "Not enough data to correlate gf4 with a_e3 (n=0)\n",
      "Not enough data to correlate gf4 with a_e4 (n=0)\n",
      "Not enough data to correlate gf4 with a_e5 (n=0)\n",
      "Not enough data to correlate gf4 with a_e6 (n=0)\n",
      "Not enough data to correlate gf4 with a_e7 (n=0)\n",
      "Not enough data to correlate gf4 with a_c6 (n=0)\n",
      "Not enough data to correlate gf4 with a_c2 (n=0)\n",
      "Not enough data to correlate gf4 with a_act11 (n=0)\n",
      "Not enough data to correlate gf5 with gp1 (n=0)\n",
      "Not enough data to correlate gf5 with gp2 (n=0)\n",
      "Not enough data to correlate gf5 with gp3 (n=0)\n",
      "Not enough data to correlate gf5 with gp4 (n=0)\n",
      "Not enough data to correlate gf5 with gp5 (n=0)\n",
      "Not enough data to correlate gf5 with gp6 (n=0)\n",
      "Not enough data to correlate gf5 with gp7 (n=0)\n",
      "Not enough data to correlate gf5 with gs1 (n=0)\n",
      "Not enough data to correlate gf5 with gs2 (n=0)\n",
      "Not enough data to correlate gf5 with gs3 (n=0)\n",
      "Not enough data to correlate gf5 with gs4 (n=0)\n",
      "Not enough data to correlate gf5 with gs5 (n=0)\n",
      "Not enough data to correlate gf5 with gs6 (n=0)\n",
      "Not enough data to correlate gf5 with gs7 (n=0)\n",
      "Not enough data to correlate gf5 with ge1 (n=0)\n",
      "Not enough data to correlate gf5 with ge2 (n=0)\n",
      "Not enough data to correlate gf5 with ge3 (n=0)\n",
      "Not enough data to correlate gf5 with ge4 (n=0)\n",
      "Not enough data to correlate gf5 with ge5 (n=0)\n",
      "Not enough data to correlate gf5 with ge6 (n=0)\n",
      "Not enough data to correlate gf5 with gf1 (n=0)\n",
      "Not enough data to correlate gf5 with gf2 (n=0)\n",
      "Not enough data to correlate gf5 with gf3 (n=0)\n",
      "Not enough data to correlate gf5 with gf4 (n=0)\n",
      "Not enough data to correlate gf5 with gf6 (n=0)\n",
      "Not enough data to correlate gf5 with gf7 (n=0)\n",
      "Not enough data to correlate gf5 with a_hn1 (n=0)\n",
      "Not enough data to correlate gf5 with a_hn2 (n=0)\n",
      "Not enough data to correlate gf5 with a_hn3 (n=0)\n",
      "Not enough data to correlate gf5 with a_hn4 (n=0)\n",
      "Not enough data to correlate gf5 with a_hn5 (n=0)\n",
      "Not enough data to correlate gf5 with a_hn7 (n=0)\n",
      "Not enough data to correlate gf5 with a_hn10 (n=0)\n",
      "Not enough data to correlate gf5 with a_e1 (n=0)\n",
      "Not enough data to correlate gf5 with a_e2 (n=0)\n",
      "Not enough data to correlate gf5 with a_e3 (n=0)\n",
      "Not enough data to correlate gf5 with a_e4 (n=0)\n",
      "Not enough data to correlate gf5 with a_e5 (n=0)\n",
      "Not enough data to correlate gf5 with a_e6 (n=0)\n",
      "Not enough data to correlate gf5 with a_e7 (n=0)\n",
      "Not enough data to correlate gf5 with a_c6 (n=0)\n",
      "Not enough data to correlate gf5 with a_c2 (n=0)\n",
      "Not enough data to correlate gf5 with a_act11 (n=0)\n",
      "Not enough data to correlate gf6 with gp1 (n=0)\n",
      "Not enough data to correlate gf6 with gp2 (n=0)\n",
      "Not enough data to correlate gf6 with gp3 (n=0)\n",
      "Not enough data to correlate gf6 with gp4 (n=0)\n",
      "Not enough data to correlate gf6 with gp5 (n=0)\n",
      "Not enough data to correlate gf6 with gp6 (n=0)\n",
      "Not enough data to correlate gf6 with gp7 (n=0)\n",
      "Not enough data to correlate gf6 with gs1 (n=0)\n",
      "Not enough data to correlate gf6 with gs2 (n=0)\n",
      "Not enough data to correlate gf6 with gs3 (n=0)\n",
      "Not enough data to correlate gf6 with gs4 (n=0)\n",
      "Not enough data to correlate gf6 with gs5 (n=0)\n",
      "Not enough data to correlate gf6 with gs6 (n=0)\n",
      "Not enough data to correlate gf6 with gs7 (n=0)\n",
      "Not enough data to correlate gf6 with ge1 (n=0)\n",
      "Not enough data to correlate gf6 with ge2 (n=0)\n",
      "Not enough data to correlate gf6 with ge3 (n=0)\n",
      "Not enough data to correlate gf6 with ge4 (n=0)\n",
      "Not enough data to correlate gf6 with ge5 (n=0)\n",
      "Not enough data to correlate gf6 with ge6 (n=0)\n",
      "Not enough data to correlate gf6 with gf1 (n=0)\n",
      "Not enough data to correlate gf6 with gf2 (n=0)\n",
      "Not enough data to correlate gf6 with gf3 (n=0)\n",
      "Not enough data to correlate gf6 with gf4 (n=0)\n",
      "Not enough data to correlate gf6 with gf5 (n=0)\n",
      "Not enough data to correlate gf6 with gf7 (n=0)\n",
      "Not enough data to correlate gf6 with a_hn1 (n=0)\n",
      "Not enough data to correlate gf6 with a_hn2 (n=0)\n",
      "Not enough data to correlate gf6 with a_hn3 (n=0)\n",
      "Not enough data to correlate gf6 with a_hn4 (n=0)\n",
      "Not enough data to correlate gf6 with a_hn5 (n=0)\n",
      "Not enough data to correlate gf6 with a_hn7 (n=0)\n",
      "Not enough data to correlate gf6 with a_hn10 (n=0)\n",
      "Not enough data to correlate gf6 with a_e1 (n=0)\n",
      "Not enough data to correlate gf6 with a_e2 (n=0)\n",
      "Not enough data to correlate gf6 with a_e3 (n=0)\n",
      "Not enough data to correlate gf6 with a_e4 (n=0)\n",
      "Not enough data to correlate gf6 with a_e5 (n=0)\n",
      "Not enough data to correlate gf6 with a_e6 (n=0)\n",
      "Not enough data to correlate gf6 with a_e7 (n=0)\n",
      "Not enough data to correlate gf6 with a_c6 (n=0)\n",
      "Not enough data to correlate gf6 with a_c2 (n=0)\n",
      "Not enough data to correlate gf6 with a_act11 (n=0)\n",
      "Not enough data to correlate gf7 with gp1 (n=0)\n",
      "Not enough data to correlate gf7 with gp2 (n=0)\n",
      "Not enough data to correlate gf7 with gp3 (n=0)\n",
      "Not enough data to correlate gf7 with gp4 (n=0)\n",
      "Not enough data to correlate gf7 with gp5 (n=0)\n",
      "Not enough data to correlate gf7 with gp6 (n=0)\n",
      "Not enough data to correlate gf7 with gp7 (n=0)\n",
      "Not enough data to correlate gf7 with gs1 (n=0)\n",
      "Not enough data to correlate gf7 with gs2 (n=0)\n",
      "Not enough data to correlate gf7 with gs3 (n=0)\n",
      "Not enough data to correlate gf7 with gs4 (n=0)\n",
      "Not enough data to correlate gf7 with gs5 (n=0)\n",
      "Not enough data to correlate gf7 with gs6 (n=0)\n",
      "Not enough data to correlate gf7 with gs7 (n=0)\n",
      "Not enough data to correlate gf7 with ge1 (n=0)\n",
      "Not enough data to correlate gf7 with ge2 (n=0)\n",
      "Not enough data to correlate gf7 with ge3 (n=0)\n",
      "Not enough data to correlate gf7 with ge4 (n=0)\n",
      "Not enough data to correlate gf7 with ge5 (n=0)\n",
      "Not enough data to correlate gf7 with ge6 (n=0)\n",
      "Not enough data to correlate gf7 with gf1 (n=0)\n",
      "Not enough data to correlate gf7 with gf2 (n=0)\n",
      "Not enough data to correlate gf7 with gf3 (n=0)\n",
      "Not enough data to correlate gf7 with gf4 (n=0)\n",
      "Not enough data to correlate gf7 with gf5 (n=0)\n",
      "Not enough data to correlate gf7 with gf6 (n=0)\n",
      "Not enough data to correlate gf7 with a_hn1 (n=0)\n",
      "Not enough data to correlate gf7 with a_hn2 (n=0)\n",
      "Not enough data to correlate gf7 with a_hn3 (n=0)\n",
      "Not enough data to correlate gf7 with a_hn4 (n=0)\n",
      "Not enough data to correlate gf7 with a_hn5 (n=0)\n",
      "Not enough data to correlate gf7 with a_hn7 (n=0)\n",
      "Not enough data to correlate gf7 with a_hn10 (n=0)\n",
      "Not enough data to correlate gf7 with a_e1 (n=0)\n",
      "Not enough data to correlate gf7 with a_e2 (n=0)\n",
      "Not enough data to correlate gf7 with a_e3 (n=0)\n",
      "Not enough data to correlate gf7 with a_e4 (n=0)\n",
      "Not enough data to correlate gf7 with a_e5 (n=0)\n",
      "Not enough data to correlate gf7 with a_e6 (n=0)\n",
      "Not enough data to correlate gf7 with a_e7 (n=0)\n",
      "Not enough data to correlate gf7 with a_c6 (n=0)\n",
      "Not enough data to correlate gf7 with a_c2 (n=0)\n",
      "Not enough data to correlate gf7 with a_act11 (n=0)\n",
      "Not enough data to correlate a_hn1 with gp1 (n=0)\n",
      "Not enough data to correlate a_hn1 with gp2 (n=0)\n",
      "Not enough data to correlate a_hn1 with gp3 (n=0)\n",
      "Not enough data to correlate a_hn1 with gp4 (n=0)\n",
      "Not enough data to correlate a_hn1 with gp5 (n=0)\n",
      "Not enough data to correlate a_hn1 with gp6 (n=0)\n",
      "Not enough data to correlate a_hn1 with gp7 (n=0)\n",
      "Not enough data to correlate a_hn1 with gs1 (n=0)\n",
      "Not enough data to correlate a_hn1 with gs2 (n=0)\n",
      "Not enough data to correlate a_hn1 with gs3 (n=0)\n",
      "Not enough data to correlate a_hn1 with gs4 (n=0)\n",
      "Not enough data to correlate a_hn1 with gs5 (n=0)\n",
      "Not enough data to correlate a_hn1 with gs6 (n=0)\n",
      "Not enough data to correlate a_hn1 with gs7 (n=0)\n",
      "Not enough data to correlate a_hn1 with ge1 (n=0)\n",
      "Not enough data to correlate a_hn1 with ge2 (n=0)\n",
      "Not enough data to correlate a_hn1 with ge3 (n=0)\n",
      "Not enough data to correlate a_hn1 with ge4 (n=0)\n",
      "Not enough data to correlate a_hn1 with ge5 (n=0)\n",
      "Not enough data to correlate a_hn1 with ge6 (n=0)\n",
      "Not enough data to correlate a_hn1 with gf1 (n=0)\n",
      "Not enough data to correlate a_hn1 with gf2 (n=0)\n",
      "Not enough data to correlate a_hn1 with gf3 (n=0)\n",
      "Not enough data to correlate a_hn1 with gf4 (n=0)\n",
      "Not enough data to correlate a_hn1 with gf5 (n=0)\n",
      "Not enough data to correlate a_hn1 with gf6 (n=0)\n",
      "Not enough data to correlate a_hn1 with gf7 (n=0)\n",
      "Not enough data to correlate a_hn1 with a_hn2 (n=0)\n",
      "Not enough data to correlate a_hn1 with a_hn3 (n=0)\n",
      "Not enough data to correlate a_hn1 with a_hn4 (n=0)\n",
      "Not enough data to correlate a_hn1 with a_hn5 (n=0)\n",
      "Not enough data to correlate a_hn1 with a_hn7 (n=0)\n",
      "Not enough data to correlate a_hn1 with a_hn10 (n=0)\n",
      "Not enough data to correlate a_hn1 with a_e1 (n=0)\n",
      "Not enough data to correlate a_hn1 with a_e2 (n=0)\n",
      "Not enough data to correlate a_hn1 with a_e3 (n=0)\n",
      "Not enough data to correlate a_hn1 with a_e4 (n=0)\n",
      "Not enough data to correlate a_hn1 with a_e5 (n=0)\n",
      "Not enough data to correlate a_hn1 with a_e6 (n=0)\n",
      "Not enough data to correlate a_hn1 with a_e7 (n=0)\n",
      "Not enough data to correlate a_hn1 with a_c6 (n=0)\n",
      "Not enough data to correlate a_hn1 with a_c2 (n=0)\n",
      "Not enough data to correlate a_hn1 with a_act11 (n=0)\n",
      "Not enough data to correlate a_hn2 with gp1 (n=0)\n",
      "Not enough data to correlate a_hn2 with gp2 (n=0)\n",
      "Not enough data to correlate a_hn2 with gp3 (n=0)\n",
      "Not enough data to correlate a_hn2 with gp4 (n=0)\n",
      "Not enough data to correlate a_hn2 with gp5 (n=0)\n",
      "Not enough data to correlate a_hn2 with gp6 (n=0)\n",
      "Not enough data to correlate a_hn2 with gp7 (n=0)\n",
      "Not enough data to correlate a_hn2 with gs1 (n=0)\n",
      "Not enough data to correlate a_hn2 with gs2 (n=0)\n",
      "Not enough data to correlate a_hn2 with gs3 (n=0)\n",
      "Not enough data to correlate a_hn2 with gs4 (n=0)\n",
      "Not enough data to correlate a_hn2 with gs5 (n=0)\n",
      "Not enough data to correlate a_hn2 with gs6 (n=0)\n",
      "Not enough data to correlate a_hn2 with gs7 (n=0)\n",
      "Not enough data to correlate a_hn2 with ge1 (n=0)\n",
      "Not enough data to correlate a_hn2 with ge2 (n=0)\n",
      "Not enough data to correlate a_hn2 with ge3 (n=0)\n",
      "Not enough data to correlate a_hn2 with ge4 (n=0)\n",
      "Not enough data to correlate a_hn2 with ge5 (n=0)\n",
      "Not enough data to correlate a_hn2 with ge6 (n=0)\n",
      "Not enough data to correlate a_hn2 with gf1 (n=0)\n",
      "Not enough data to correlate a_hn2 with gf2 (n=0)\n",
      "Not enough data to correlate a_hn2 with gf3 (n=0)\n",
      "Not enough data to correlate a_hn2 with gf4 (n=0)\n",
      "Not enough data to correlate a_hn2 with gf5 (n=0)\n",
      "Not enough data to correlate a_hn2 with gf6 (n=0)\n",
      "Not enough data to correlate a_hn2 with gf7 (n=0)\n",
      "Not enough data to correlate a_hn2 with a_hn1 (n=0)\n",
      "Not enough data to correlate a_hn2 with a_hn3 (n=0)\n",
      "Not enough data to correlate a_hn2 with a_hn4 (n=0)\n",
      "Not enough data to correlate a_hn2 with a_hn5 (n=0)\n",
      "Not enough data to correlate a_hn2 with a_hn7 (n=0)\n",
      "Not enough data to correlate a_hn2 with a_hn10 (n=0)\n",
      "Not enough data to correlate a_hn2 with a_e1 (n=0)\n",
      "Not enough data to correlate a_hn2 with a_e2 (n=0)\n",
      "Not enough data to correlate a_hn2 with a_e3 (n=0)\n",
      "Not enough data to correlate a_hn2 with a_e4 (n=0)\n",
      "Not enough data to correlate a_hn2 with a_e5 (n=0)\n",
      "Not enough data to correlate a_hn2 with a_e6 (n=0)\n",
      "Not enough data to correlate a_hn2 with a_e7 (n=0)\n",
      "Not enough data to correlate a_hn2 with a_c6 (n=0)\n",
      "Not enough data to correlate a_hn2 with a_c2 (n=0)\n",
      "Not enough data to correlate a_hn2 with a_act11 (n=0)\n",
      "Not enough data to correlate a_hn3 with gp1 (n=0)\n",
      "Not enough data to correlate a_hn3 with gp2 (n=0)\n",
      "Not enough data to correlate a_hn3 with gp3 (n=0)\n",
      "Not enough data to correlate a_hn3 with gp4 (n=0)\n",
      "Not enough data to correlate a_hn3 with gp5 (n=0)\n",
      "Not enough data to correlate a_hn3 with gp6 (n=0)\n",
      "Not enough data to correlate a_hn3 with gp7 (n=0)\n",
      "Not enough data to correlate a_hn3 with gs1 (n=0)\n",
      "Not enough data to correlate a_hn3 with gs2 (n=0)\n",
      "Not enough data to correlate a_hn3 with gs3 (n=0)\n",
      "Not enough data to correlate a_hn3 with gs4 (n=0)\n",
      "Not enough data to correlate a_hn3 with gs5 (n=0)\n",
      "Not enough data to correlate a_hn3 with gs6 (n=0)\n",
      "Not enough data to correlate a_hn3 with gs7 (n=0)\n",
      "Not enough data to correlate a_hn3 with ge1 (n=0)\n",
      "Not enough data to correlate a_hn3 with ge2 (n=0)\n",
      "Not enough data to correlate a_hn3 with ge3 (n=0)\n",
      "Not enough data to correlate a_hn3 with ge4 (n=0)\n",
      "Not enough data to correlate a_hn3 with ge5 (n=0)\n",
      "Not enough data to correlate a_hn3 with ge6 (n=0)\n",
      "Not enough data to correlate a_hn3 with gf1 (n=0)\n",
      "Not enough data to correlate a_hn3 with gf2 (n=0)\n",
      "Not enough data to correlate a_hn3 with gf3 (n=0)\n",
      "Not enough data to correlate a_hn3 with gf4 (n=0)\n",
      "Not enough data to correlate a_hn3 with gf5 (n=0)\n",
      "Not enough data to correlate a_hn3 with gf6 (n=0)\n",
      "Not enough data to correlate a_hn3 with gf7 (n=0)\n",
      "Not enough data to correlate a_hn3 with a_hn1 (n=0)\n",
      "Not enough data to correlate a_hn3 with a_hn2 (n=0)\n",
      "Not enough data to correlate a_hn3 with a_hn4 (n=0)\n",
      "Not enough data to correlate a_hn3 with a_hn5 (n=0)\n",
      "Not enough data to correlate a_hn3 with a_hn7 (n=0)\n",
      "Not enough data to correlate a_hn3 with a_hn10 (n=0)\n",
      "Not enough data to correlate a_hn3 with a_e1 (n=0)\n",
      "Not enough data to correlate a_hn3 with a_e2 (n=0)\n",
      "Not enough data to correlate a_hn3 with a_e3 (n=0)\n",
      "Not enough data to correlate a_hn3 with a_e4 (n=0)\n",
      "Not enough data to correlate a_hn3 with a_e5 (n=0)\n",
      "Not enough data to correlate a_hn3 with a_e6 (n=0)\n",
      "Not enough data to correlate a_hn3 with a_e7 (n=0)\n",
      "Not enough data to correlate a_hn3 with a_c6 (n=0)\n",
      "Not enough data to correlate a_hn3 with a_c2 (n=0)\n",
      "Not enough data to correlate a_hn3 with a_act11 (n=0)\n",
      "Not enough data to correlate a_hn4 with gp1 (n=0)\n",
      "Not enough data to correlate a_hn4 with gp2 (n=0)\n",
      "Not enough data to correlate a_hn4 with gp3 (n=0)\n",
      "Not enough data to correlate a_hn4 with gp4 (n=0)\n",
      "Not enough data to correlate a_hn4 with gp5 (n=0)\n",
      "Not enough data to correlate a_hn4 with gp6 (n=0)\n",
      "Not enough data to correlate a_hn4 with gp7 (n=0)\n",
      "Not enough data to correlate a_hn4 with gs1 (n=0)\n",
      "Not enough data to correlate a_hn4 with gs2 (n=0)\n",
      "Not enough data to correlate a_hn4 with gs3 (n=0)\n",
      "Not enough data to correlate a_hn4 with gs4 (n=0)\n",
      "Not enough data to correlate a_hn4 with gs5 (n=0)\n",
      "Not enough data to correlate a_hn4 with gs6 (n=0)\n",
      "Not enough data to correlate a_hn4 with gs7 (n=0)\n",
      "Not enough data to correlate a_hn4 with ge1 (n=0)\n",
      "Not enough data to correlate a_hn4 with ge2 (n=0)\n",
      "Not enough data to correlate a_hn4 with ge3 (n=0)\n",
      "Not enough data to correlate a_hn4 with ge4 (n=0)\n",
      "Not enough data to correlate a_hn4 with ge5 (n=0)\n",
      "Not enough data to correlate a_hn4 with ge6 (n=0)\n",
      "Not enough data to correlate a_hn4 with gf1 (n=0)\n",
      "Not enough data to correlate a_hn4 with gf2 (n=0)\n",
      "Not enough data to correlate a_hn4 with gf3 (n=0)\n",
      "Not enough data to correlate a_hn4 with gf4 (n=0)\n",
      "Not enough data to correlate a_hn4 with gf5 (n=0)\n",
      "Not enough data to correlate a_hn4 with gf6 (n=0)\n",
      "Not enough data to correlate a_hn4 with gf7 (n=0)\n",
      "Not enough data to correlate a_hn4 with a_hn1 (n=0)\n",
      "Not enough data to correlate a_hn4 with a_hn2 (n=0)\n",
      "Not enough data to correlate a_hn4 with a_hn3 (n=0)\n",
      "Not enough data to correlate a_hn4 with a_hn5 (n=0)\n",
      "Not enough data to correlate a_hn4 with a_hn7 (n=0)\n",
      "Not enough data to correlate a_hn4 with a_hn10 (n=0)\n",
      "Not enough data to correlate a_hn4 with a_e1 (n=0)\n",
      "Not enough data to correlate a_hn4 with a_e2 (n=0)\n",
      "Not enough data to correlate a_hn4 with a_e3 (n=0)\n",
      "Not enough data to correlate a_hn4 with a_e4 (n=0)\n",
      "Not enough data to correlate a_hn4 with a_e5 (n=0)\n",
      "Not enough data to correlate a_hn4 with a_e6 (n=0)\n",
      "Not enough data to correlate a_hn4 with a_e7 (n=0)\n",
      "Not enough data to correlate a_hn4 with a_c6 (n=0)\n",
      "Not enough data to correlate a_hn4 with a_c2 (n=0)\n",
      "Not enough data to correlate a_hn4 with a_act11 (n=0)\n",
      "Not enough data to correlate a_hn5 with gp1 (n=0)\n",
      "Not enough data to correlate a_hn5 with gp2 (n=0)\n",
      "Not enough data to correlate a_hn5 with gp3 (n=0)\n",
      "Not enough data to correlate a_hn5 with gp4 (n=0)\n",
      "Not enough data to correlate a_hn5 with gp5 (n=0)\n",
      "Not enough data to correlate a_hn5 with gp6 (n=0)\n",
      "Not enough data to correlate a_hn5 with gp7 (n=0)\n",
      "Not enough data to correlate a_hn5 with gs1 (n=0)\n",
      "Not enough data to correlate a_hn5 with gs2 (n=0)\n",
      "Not enough data to correlate a_hn5 with gs3 (n=0)\n",
      "Not enough data to correlate a_hn5 with gs4 (n=0)\n",
      "Not enough data to correlate a_hn5 with gs5 (n=0)\n",
      "Not enough data to correlate a_hn5 with gs6 (n=0)\n",
      "Not enough data to correlate a_hn5 with gs7 (n=0)\n",
      "Not enough data to correlate a_hn5 with ge1 (n=0)\n",
      "Not enough data to correlate a_hn5 with ge2 (n=0)\n",
      "Not enough data to correlate a_hn5 with ge3 (n=0)\n",
      "Not enough data to correlate a_hn5 with ge4 (n=0)\n",
      "Not enough data to correlate a_hn5 with ge5 (n=0)\n",
      "Not enough data to correlate a_hn5 with ge6 (n=0)\n",
      "Not enough data to correlate a_hn5 with gf1 (n=0)\n",
      "Not enough data to correlate a_hn5 with gf2 (n=0)\n",
      "Not enough data to correlate a_hn5 with gf3 (n=0)\n",
      "Not enough data to correlate a_hn5 with gf4 (n=0)\n",
      "Not enough data to correlate a_hn5 with gf5 (n=0)\n",
      "Not enough data to correlate a_hn5 with gf6 (n=0)\n",
      "Not enough data to correlate a_hn5 with gf7 (n=0)\n",
      "Not enough data to correlate a_hn5 with a_hn1 (n=0)\n",
      "Not enough data to correlate a_hn5 with a_hn2 (n=0)\n",
      "Not enough data to correlate a_hn5 with a_hn3 (n=0)\n",
      "Not enough data to correlate a_hn5 with a_hn4 (n=0)\n",
      "Not enough data to correlate a_hn5 with a_hn7 (n=0)\n",
      "Not enough data to correlate a_hn5 with a_hn10 (n=0)\n",
      "Not enough data to correlate a_hn5 with a_e1 (n=0)\n",
      "Not enough data to correlate a_hn5 with a_e2 (n=0)\n",
      "Not enough data to correlate a_hn5 with a_e3 (n=0)\n",
      "Not enough data to correlate a_hn5 with a_e4 (n=0)\n",
      "Not enough data to correlate a_hn5 with a_e5 (n=0)\n",
      "Not enough data to correlate a_hn5 with a_e6 (n=0)\n",
      "Not enough data to correlate a_hn5 with a_e7 (n=0)\n",
      "Not enough data to correlate a_hn5 with a_c6 (n=0)\n",
      "Not enough data to correlate a_hn5 with a_c2 (n=0)\n",
      "Not enough data to correlate a_hn5 with a_act11 (n=0)\n",
      "Not enough data to correlate a_hn7 with gp1 (n=0)\n",
      "Not enough data to correlate a_hn7 with gp2 (n=0)\n",
      "Not enough data to correlate a_hn7 with gp3 (n=0)\n",
      "Not enough data to correlate a_hn7 with gp4 (n=0)\n",
      "Not enough data to correlate a_hn7 with gp5 (n=0)\n",
      "Not enough data to correlate a_hn7 with gp6 (n=0)\n",
      "Not enough data to correlate a_hn7 with gp7 (n=0)\n",
      "Not enough data to correlate a_hn7 with gs1 (n=0)\n",
      "Not enough data to correlate a_hn7 with gs2 (n=0)\n",
      "Not enough data to correlate a_hn7 with gs3 (n=0)\n",
      "Not enough data to correlate a_hn7 with gs4 (n=0)\n",
      "Not enough data to correlate a_hn7 with gs5 (n=0)\n",
      "Not enough data to correlate a_hn7 with gs6 (n=0)\n",
      "Not enough data to correlate a_hn7 with gs7 (n=0)\n",
      "Not enough data to correlate a_hn7 with ge1 (n=0)\n",
      "Not enough data to correlate a_hn7 with ge2 (n=0)\n",
      "Not enough data to correlate a_hn7 with ge3 (n=0)\n",
      "Not enough data to correlate a_hn7 with ge4 (n=0)\n",
      "Not enough data to correlate a_hn7 with ge5 (n=0)\n",
      "Not enough data to correlate a_hn7 with ge6 (n=0)\n",
      "Not enough data to correlate a_hn7 with gf1 (n=0)\n",
      "Not enough data to correlate a_hn7 with gf2 (n=0)\n",
      "Not enough data to correlate a_hn7 with gf3 (n=0)\n",
      "Not enough data to correlate a_hn7 with gf4 (n=0)\n",
      "Not enough data to correlate a_hn7 with gf5 (n=0)\n",
      "Not enough data to correlate a_hn7 with gf6 (n=0)\n",
      "Not enough data to correlate a_hn7 with gf7 (n=0)\n",
      "Not enough data to correlate a_hn7 with a_hn1 (n=0)\n",
      "Not enough data to correlate a_hn7 with a_hn2 (n=0)\n",
      "Not enough data to correlate a_hn7 with a_hn3 (n=0)\n",
      "Not enough data to correlate a_hn7 with a_hn4 (n=0)\n",
      "Not enough data to correlate a_hn7 with a_hn5 (n=0)\n",
      "Not enough data to correlate a_hn7 with a_hn10 (n=0)\n",
      "Not enough data to correlate a_hn7 with a_e1 (n=0)\n",
      "Not enough data to correlate a_hn7 with a_e2 (n=0)\n",
      "Not enough data to correlate a_hn7 with a_e3 (n=0)\n",
      "Not enough data to correlate a_hn7 with a_e4 (n=0)\n",
      "Not enough data to correlate a_hn7 with a_e5 (n=0)\n",
      "Not enough data to correlate a_hn7 with a_e6 (n=0)\n",
      "Not enough data to correlate a_hn7 with a_e7 (n=0)\n",
      "Not enough data to correlate a_hn7 with a_c6 (n=0)\n",
      "Not enough data to correlate a_hn7 with a_c2 (n=0)\n",
      "Not enough data to correlate a_hn7 with a_act11 (n=0)\n",
      "Not enough data to correlate a_hn10 with gp1 (n=0)\n",
      "Not enough data to correlate a_hn10 with gp2 (n=0)\n",
      "Not enough data to correlate a_hn10 with gp3 (n=0)\n",
      "Not enough data to correlate a_hn10 with gp4 (n=0)\n",
      "Not enough data to correlate a_hn10 with gp5 (n=0)\n",
      "Not enough data to correlate a_hn10 with gp6 (n=0)\n",
      "Not enough data to correlate a_hn10 with gp7 (n=0)\n",
      "Not enough data to correlate a_hn10 with gs1 (n=0)\n",
      "Not enough data to correlate a_hn10 with gs2 (n=0)\n",
      "Not enough data to correlate a_hn10 with gs3 (n=0)\n",
      "Not enough data to correlate a_hn10 with gs4 (n=0)\n",
      "Not enough data to correlate a_hn10 with gs5 (n=0)\n",
      "Not enough data to correlate a_hn10 with gs6 (n=0)\n",
      "Not enough data to correlate a_hn10 with gs7 (n=0)\n",
      "Not enough data to correlate a_hn10 with ge1 (n=0)\n",
      "Not enough data to correlate a_hn10 with ge2 (n=0)\n",
      "Not enough data to correlate a_hn10 with ge3 (n=0)\n",
      "Not enough data to correlate a_hn10 with ge4 (n=0)\n",
      "Not enough data to correlate a_hn10 with ge5 (n=0)\n",
      "Not enough data to correlate a_hn10 with ge6 (n=0)\n",
      "Not enough data to correlate a_hn10 with gf1 (n=0)\n",
      "Not enough data to correlate a_hn10 with gf2 (n=0)\n",
      "Not enough data to correlate a_hn10 with gf3 (n=0)\n",
      "Not enough data to correlate a_hn10 with gf4 (n=0)\n",
      "Not enough data to correlate a_hn10 with gf5 (n=0)\n",
      "Not enough data to correlate a_hn10 with gf6 (n=0)\n",
      "Not enough data to correlate a_hn10 with gf7 (n=0)\n",
      "Not enough data to correlate a_hn10 with a_hn1 (n=0)\n",
      "Not enough data to correlate a_hn10 with a_hn2 (n=0)\n",
      "Not enough data to correlate a_hn10 with a_hn3 (n=0)\n",
      "Not enough data to correlate a_hn10 with a_hn4 (n=0)\n",
      "Not enough data to correlate a_hn10 with a_hn5 (n=0)\n",
      "Not enough data to correlate a_hn10 with a_hn7 (n=0)\n",
      "Not enough data to correlate a_hn10 with a_e1 (n=0)\n",
      "Not enough data to correlate a_hn10 with a_e2 (n=0)\n",
      "Not enough data to correlate a_hn10 with a_e3 (n=0)\n",
      "Not enough data to correlate a_hn10 with a_e4 (n=0)\n",
      "Not enough data to correlate a_hn10 with a_e5 (n=0)\n",
      "Not enough data to correlate a_hn10 with a_e6 (n=0)\n",
      "Not enough data to correlate a_hn10 with a_e7 (n=0)\n",
      "Not enough data to correlate a_hn10 with a_c6 (n=0)\n",
      "Not enough data to correlate a_hn10 with a_c2 (n=0)\n",
      "Not enough data to correlate a_hn10 with a_act11 (n=0)\n",
      "Not enough data to correlate a_e1 with gp1 (n=0)\n",
      "Not enough data to correlate a_e1 with gp2 (n=0)\n",
      "Not enough data to correlate a_e1 with gp3 (n=0)\n",
      "Not enough data to correlate a_e1 with gp4 (n=0)\n",
      "Not enough data to correlate a_e1 with gp5 (n=0)\n",
      "Not enough data to correlate a_e1 with gp6 (n=0)\n",
      "Not enough data to correlate a_e1 with gp7 (n=0)\n",
      "Not enough data to correlate a_e1 with gs1 (n=0)\n",
      "Not enough data to correlate a_e1 with gs2 (n=0)\n",
      "Not enough data to correlate a_e1 with gs3 (n=0)\n",
      "Not enough data to correlate a_e1 with gs4 (n=0)\n",
      "Not enough data to correlate a_e1 with gs5 (n=0)\n",
      "Not enough data to correlate a_e1 with gs6 (n=0)\n",
      "Not enough data to correlate a_e1 with gs7 (n=0)\n",
      "Not enough data to correlate a_e1 with ge1 (n=0)\n",
      "Not enough data to correlate a_e1 with ge2 (n=0)\n",
      "Not enough data to correlate a_e1 with ge3 (n=0)\n",
      "Not enough data to correlate a_e1 with ge4 (n=0)\n",
      "Not enough data to correlate a_e1 with ge5 (n=0)\n",
      "Not enough data to correlate a_e1 with ge6 (n=0)\n",
      "Not enough data to correlate a_e1 with gf1 (n=0)\n",
      "Not enough data to correlate a_e1 with gf2 (n=0)\n",
      "Not enough data to correlate a_e1 with gf3 (n=0)\n",
      "Not enough data to correlate a_e1 with gf4 (n=0)\n",
      "Not enough data to correlate a_e1 with gf5 (n=0)\n",
      "Not enough data to correlate a_e1 with gf6 (n=0)\n",
      "Not enough data to correlate a_e1 with gf7 (n=0)\n",
      "Not enough data to correlate a_e1 with a_hn1 (n=0)\n",
      "Not enough data to correlate a_e1 with a_hn2 (n=0)\n",
      "Not enough data to correlate a_e1 with a_hn3 (n=0)\n",
      "Not enough data to correlate a_e1 with a_hn4 (n=0)\n",
      "Not enough data to correlate a_e1 with a_hn5 (n=0)\n",
      "Not enough data to correlate a_e1 with a_hn7 (n=0)\n",
      "Not enough data to correlate a_e1 with a_hn10 (n=0)\n",
      "Not enough data to correlate a_e1 with a_e2 (n=0)\n",
      "Not enough data to correlate a_e1 with a_e3 (n=0)\n",
      "Not enough data to correlate a_e1 with a_e4 (n=0)\n",
      "Not enough data to correlate a_e1 with a_e5 (n=0)\n",
      "Not enough data to correlate a_e1 with a_e6 (n=0)\n",
      "Not enough data to correlate a_e1 with a_e7 (n=0)\n",
      "Not enough data to correlate a_e1 with a_c6 (n=0)\n",
      "Not enough data to correlate a_e1 with a_c2 (n=0)\n",
      "Not enough data to correlate a_e1 with a_act11 (n=0)\n",
      "Not enough data to correlate a_e2 with gp1 (n=0)\n",
      "Not enough data to correlate a_e2 with gp2 (n=0)\n",
      "Not enough data to correlate a_e2 with gp3 (n=0)\n",
      "Not enough data to correlate a_e2 with gp4 (n=0)\n",
      "Not enough data to correlate a_e2 with gp5 (n=0)\n",
      "Not enough data to correlate a_e2 with gp6 (n=0)\n",
      "Not enough data to correlate a_e2 with gp7 (n=0)\n",
      "Not enough data to correlate a_e2 with gs1 (n=0)\n",
      "Not enough data to correlate a_e2 with gs2 (n=0)\n",
      "Not enough data to correlate a_e2 with gs3 (n=0)\n",
      "Not enough data to correlate a_e2 with gs4 (n=0)\n",
      "Not enough data to correlate a_e2 with gs5 (n=0)\n",
      "Not enough data to correlate a_e2 with gs6 (n=0)\n",
      "Not enough data to correlate a_e2 with gs7 (n=0)\n",
      "Not enough data to correlate a_e2 with ge1 (n=0)\n",
      "Not enough data to correlate a_e2 with ge2 (n=0)\n",
      "Not enough data to correlate a_e2 with ge3 (n=0)\n",
      "Not enough data to correlate a_e2 with ge4 (n=0)\n",
      "Not enough data to correlate a_e2 with ge5 (n=0)\n",
      "Not enough data to correlate a_e2 with ge6 (n=0)\n",
      "Not enough data to correlate a_e2 with gf1 (n=0)\n",
      "Not enough data to correlate a_e2 with gf2 (n=0)\n",
      "Not enough data to correlate a_e2 with gf3 (n=0)\n",
      "Not enough data to correlate a_e2 with gf4 (n=0)\n",
      "Not enough data to correlate a_e2 with gf5 (n=0)\n",
      "Not enough data to correlate a_e2 with gf6 (n=0)\n",
      "Not enough data to correlate a_e2 with gf7 (n=0)\n",
      "Not enough data to correlate a_e2 with a_hn1 (n=0)\n",
      "Not enough data to correlate a_e2 with a_hn2 (n=0)\n",
      "Not enough data to correlate a_e2 with a_hn3 (n=0)\n",
      "Not enough data to correlate a_e2 with a_hn4 (n=0)\n",
      "Not enough data to correlate a_e2 with a_hn5 (n=0)\n",
      "Not enough data to correlate a_e2 with a_hn7 (n=0)\n",
      "Not enough data to correlate a_e2 with a_hn10 (n=0)\n",
      "Not enough data to correlate a_e2 with a_e1 (n=0)\n",
      "Not enough data to correlate a_e2 with a_e3 (n=0)\n",
      "Not enough data to correlate a_e2 with a_e4 (n=0)\n",
      "Not enough data to correlate a_e2 with a_e5 (n=0)\n",
      "Not enough data to correlate a_e2 with a_e6 (n=0)\n",
      "Not enough data to correlate a_e2 with a_e7 (n=0)\n",
      "Not enough data to correlate a_e2 with a_c6 (n=0)\n",
      "Not enough data to correlate a_e2 with a_c2 (n=0)\n",
      "Not enough data to correlate a_e2 with a_act11 (n=0)\n",
      "Not enough data to correlate a_e3 with gp1 (n=0)\n",
      "Not enough data to correlate a_e3 with gp2 (n=0)\n",
      "Not enough data to correlate a_e3 with gp3 (n=0)\n",
      "Not enough data to correlate a_e3 with gp4 (n=0)\n",
      "Not enough data to correlate a_e3 with gp5 (n=0)\n",
      "Not enough data to correlate a_e3 with gp6 (n=0)\n",
      "Not enough data to correlate a_e3 with gp7 (n=0)\n",
      "Not enough data to correlate a_e3 with gs1 (n=0)\n",
      "Not enough data to correlate a_e3 with gs2 (n=0)\n",
      "Not enough data to correlate a_e3 with gs3 (n=0)\n",
      "Not enough data to correlate a_e3 with gs4 (n=0)\n",
      "Not enough data to correlate a_e3 with gs5 (n=0)\n",
      "Not enough data to correlate a_e3 with gs6 (n=0)\n",
      "Not enough data to correlate a_e3 with gs7 (n=0)\n",
      "Not enough data to correlate a_e3 with ge1 (n=0)\n",
      "Not enough data to correlate a_e3 with ge2 (n=0)\n",
      "Not enough data to correlate a_e3 with ge3 (n=0)\n",
      "Not enough data to correlate a_e3 with ge4 (n=0)\n",
      "Not enough data to correlate a_e3 with ge5 (n=0)\n",
      "Not enough data to correlate a_e3 with ge6 (n=0)\n",
      "Not enough data to correlate a_e3 with gf1 (n=0)\n",
      "Not enough data to correlate a_e3 with gf2 (n=0)\n",
      "Not enough data to correlate a_e3 with gf3 (n=0)\n",
      "Not enough data to correlate a_e3 with gf4 (n=0)\n",
      "Not enough data to correlate a_e3 with gf5 (n=0)\n",
      "Not enough data to correlate a_e3 with gf6 (n=0)\n",
      "Not enough data to correlate a_e3 with gf7 (n=0)\n",
      "Not enough data to correlate a_e3 with a_hn1 (n=0)\n",
      "Not enough data to correlate a_e3 with a_hn2 (n=0)\n",
      "Not enough data to correlate a_e3 with a_hn3 (n=0)\n",
      "Not enough data to correlate a_e3 with a_hn4 (n=0)\n",
      "Not enough data to correlate a_e3 with a_hn5 (n=0)\n",
      "Not enough data to correlate a_e3 with a_hn7 (n=0)\n",
      "Not enough data to correlate a_e3 with a_hn10 (n=0)\n",
      "Not enough data to correlate a_e3 with a_e1 (n=0)\n",
      "Not enough data to correlate a_e3 with a_e2 (n=0)\n",
      "Not enough data to correlate a_e3 with a_e4 (n=0)\n",
      "Not enough data to correlate a_e3 with a_e5 (n=0)\n",
      "Not enough data to correlate a_e3 with a_e6 (n=0)\n",
      "Not enough data to correlate a_e3 with a_e7 (n=0)\n",
      "Not enough data to correlate a_e3 with a_c6 (n=0)\n",
      "Not enough data to correlate a_e3 with a_c2 (n=0)\n",
      "Not enough data to correlate a_e3 with a_act11 (n=0)\n",
      "Not enough data to correlate a_e4 with gp1 (n=0)\n",
      "Not enough data to correlate a_e4 with gp2 (n=0)\n",
      "Not enough data to correlate a_e4 with gp3 (n=0)\n",
      "Not enough data to correlate a_e4 with gp4 (n=0)\n",
      "Not enough data to correlate a_e4 with gp5 (n=0)\n",
      "Not enough data to correlate a_e4 with gp6 (n=0)\n",
      "Not enough data to correlate a_e4 with gp7 (n=0)\n",
      "Not enough data to correlate a_e4 with gs1 (n=0)\n",
      "Not enough data to correlate a_e4 with gs2 (n=0)\n",
      "Not enough data to correlate a_e4 with gs3 (n=0)\n",
      "Not enough data to correlate a_e4 with gs4 (n=0)\n",
      "Not enough data to correlate a_e4 with gs5 (n=0)\n",
      "Not enough data to correlate a_e4 with gs6 (n=0)\n",
      "Not enough data to correlate a_e4 with gs7 (n=0)\n",
      "Not enough data to correlate a_e4 with ge1 (n=0)\n",
      "Not enough data to correlate a_e4 with ge2 (n=0)\n",
      "Not enough data to correlate a_e4 with ge3 (n=0)\n",
      "Not enough data to correlate a_e4 with ge4 (n=0)\n",
      "Not enough data to correlate a_e4 with ge5 (n=0)\n",
      "Not enough data to correlate a_e4 with ge6 (n=0)\n",
      "Not enough data to correlate a_e4 with gf1 (n=0)\n",
      "Not enough data to correlate a_e4 with gf2 (n=0)\n",
      "Not enough data to correlate a_e4 with gf3 (n=0)\n",
      "Not enough data to correlate a_e4 with gf4 (n=0)\n",
      "Not enough data to correlate a_e4 with gf5 (n=0)\n",
      "Not enough data to correlate a_e4 with gf6 (n=0)\n",
      "Not enough data to correlate a_e4 with gf7 (n=0)\n",
      "Not enough data to correlate a_e4 with a_hn1 (n=0)\n",
      "Not enough data to correlate a_e4 with a_hn2 (n=0)\n",
      "Not enough data to correlate a_e4 with a_hn3 (n=0)\n",
      "Not enough data to correlate a_e4 with a_hn4 (n=0)\n",
      "Not enough data to correlate a_e4 with a_hn5 (n=0)\n",
      "Not enough data to correlate a_e4 with a_hn7 (n=0)\n",
      "Not enough data to correlate a_e4 with a_hn10 (n=0)\n",
      "Not enough data to correlate a_e4 with a_e1 (n=0)\n",
      "Not enough data to correlate a_e4 with a_e2 (n=0)\n",
      "Not enough data to correlate a_e4 with a_e3 (n=0)\n",
      "Not enough data to correlate a_e4 with a_e5 (n=0)\n",
      "Not enough data to correlate a_e4 with a_e6 (n=0)\n",
      "Not enough data to correlate a_e4 with a_e7 (n=0)\n",
      "Not enough data to correlate a_e4 with a_c6 (n=0)\n",
      "Not enough data to correlate a_e4 with a_c2 (n=0)\n",
      "Not enough data to correlate a_e4 with a_act11 (n=0)\n",
      "Not enough data to correlate a_e5 with gp1 (n=0)\n",
      "Not enough data to correlate a_e5 with gp2 (n=0)\n",
      "Not enough data to correlate a_e5 with gp3 (n=0)\n",
      "Not enough data to correlate a_e5 with gp4 (n=0)\n",
      "Not enough data to correlate a_e5 with gp5 (n=0)\n",
      "Not enough data to correlate a_e5 with gp6 (n=0)\n",
      "Not enough data to correlate a_e5 with gp7 (n=0)\n",
      "Not enough data to correlate a_e5 with gs1 (n=0)\n",
      "Not enough data to correlate a_e5 with gs2 (n=0)\n",
      "Not enough data to correlate a_e5 with gs3 (n=0)\n",
      "Not enough data to correlate a_e5 with gs4 (n=0)\n",
      "Not enough data to correlate a_e5 with gs5 (n=0)\n",
      "Not enough data to correlate a_e5 with gs6 (n=0)\n",
      "Not enough data to correlate a_e5 with gs7 (n=0)\n",
      "Not enough data to correlate a_e5 with ge1 (n=0)\n",
      "Not enough data to correlate a_e5 with ge2 (n=0)\n",
      "Not enough data to correlate a_e5 with ge3 (n=0)\n",
      "Not enough data to correlate a_e5 with ge4 (n=0)\n",
      "Not enough data to correlate a_e5 with ge5 (n=0)\n",
      "Not enough data to correlate a_e5 with ge6 (n=0)\n",
      "Not enough data to correlate a_e5 with gf1 (n=0)\n",
      "Not enough data to correlate a_e5 with gf2 (n=0)\n",
      "Not enough data to correlate a_e5 with gf3 (n=0)\n",
      "Not enough data to correlate a_e5 with gf4 (n=0)\n",
      "Not enough data to correlate a_e5 with gf5 (n=0)\n",
      "Not enough data to correlate a_e5 with gf6 (n=0)\n",
      "Not enough data to correlate a_e5 with gf7 (n=0)\n",
      "Not enough data to correlate a_e5 with a_hn1 (n=0)\n",
      "Not enough data to correlate a_e5 with a_hn2 (n=0)\n",
      "Not enough data to correlate a_e5 with a_hn3 (n=0)\n",
      "Not enough data to correlate a_e5 with a_hn4 (n=0)\n",
      "Not enough data to correlate a_e5 with a_hn5 (n=0)\n",
      "Not enough data to correlate a_e5 with a_hn7 (n=0)\n",
      "Not enough data to correlate a_e5 with a_hn10 (n=0)\n",
      "Not enough data to correlate a_e5 with a_e1 (n=0)\n",
      "Not enough data to correlate a_e5 with a_e2 (n=0)\n",
      "Not enough data to correlate a_e5 with a_e3 (n=0)\n",
      "Not enough data to correlate a_e5 with a_e4 (n=0)\n",
      "Not enough data to correlate a_e5 with a_e6 (n=0)\n",
      "Not enough data to correlate a_e5 with a_e7 (n=0)\n",
      "Not enough data to correlate a_e5 with a_c6 (n=0)\n",
      "Not enough data to correlate a_e5 with a_c2 (n=0)\n",
      "Not enough data to correlate a_e5 with a_act11 (n=0)\n",
      "Not enough data to correlate a_e6 with gp1 (n=0)\n",
      "Not enough data to correlate a_e6 with gp2 (n=0)\n",
      "Not enough data to correlate a_e6 with gp3 (n=0)\n",
      "Not enough data to correlate a_e6 with gp4 (n=0)\n",
      "Not enough data to correlate a_e6 with gp5 (n=0)\n",
      "Not enough data to correlate a_e6 with gp6 (n=0)\n",
      "Not enough data to correlate a_e6 with gp7 (n=0)\n",
      "Not enough data to correlate a_e6 with gs1 (n=0)\n",
      "Not enough data to correlate a_e6 with gs2 (n=0)\n",
      "Not enough data to correlate a_e6 with gs3 (n=0)\n",
      "Not enough data to correlate a_e6 with gs4 (n=0)\n",
      "Not enough data to correlate a_e6 with gs5 (n=0)\n",
      "Not enough data to correlate a_e6 with gs6 (n=0)\n",
      "Not enough data to correlate a_e6 with gs7 (n=0)\n",
      "Not enough data to correlate a_e6 with ge1 (n=0)\n",
      "Not enough data to correlate a_e6 with ge2 (n=0)\n",
      "Not enough data to correlate a_e6 with ge3 (n=0)\n",
      "Not enough data to correlate a_e6 with ge4 (n=0)\n",
      "Not enough data to correlate a_e6 with ge5 (n=0)\n",
      "Not enough data to correlate a_e6 with ge6 (n=0)\n",
      "Not enough data to correlate a_e6 with gf1 (n=0)\n",
      "Not enough data to correlate a_e6 with gf2 (n=0)\n",
      "Not enough data to correlate a_e6 with gf3 (n=0)\n",
      "Not enough data to correlate a_e6 with gf4 (n=0)\n",
      "Not enough data to correlate a_e6 with gf5 (n=0)\n",
      "Not enough data to correlate a_e6 with gf6 (n=0)\n",
      "Not enough data to correlate a_e6 with gf7 (n=0)\n",
      "Not enough data to correlate a_e6 with a_hn1 (n=0)\n",
      "Not enough data to correlate a_e6 with a_hn2 (n=0)\n",
      "Not enough data to correlate a_e6 with a_hn3 (n=0)\n",
      "Not enough data to correlate a_e6 with a_hn4 (n=0)\n",
      "Not enough data to correlate a_e6 with a_hn5 (n=0)\n",
      "Not enough data to correlate a_e6 with a_hn7 (n=0)\n",
      "Not enough data to correlate a_e6 with a_hn10 (n=0)\n",
      "Not enough data to correlate a_e6 with a_e1 (n=0)\n",
      "Not enough data to correlate a_e6 with a_e2 (n=0)\n",
      "Not enough data to correlate a_e6 with a_e3 (n=0)\n",
      "Not enough data to correlate a_e6 with a_e4 (n=0)\n",
      "Not enough data to correlate a_e6 with a_e5 (n=0)\n",
      "Not enough data to correlate a_e6 with a_e7 (n=0)\n",
      "Not enough data to correlate a_e6 with a_c6 (n=0)\n",
      "Not enough data to correlate a_e6 with a_c2 (n=0)\n",
      "Not enough data to correlate a_e6 with a_act11 (n=0)\n",
      "Not enough data to correlate a_e7 with gp1 (n=0)\n",
      "Not enough data to correlate a_e7 with gp2 (n=0)\n",
      "Not enough data to correlate a_e7 with gp3 (n=0)\n",
      "Not enough data to correlate a_e7 with gp4 (n=0)\n",
      "Not enough data to correlate a_e7 with gp5 (n=0)\n",
      "Not enough data to correlate a_e7 with gp6 (n=0)\n",
      "Not enough data to correlate a_e7 with gp7 (n=0)\n",
      "Not enough data to correlate a_e7 with gs1 (n=0)\n",
      "Not enough data to correlate a_e7 with gs2 (n=0)\n",
      "Not enough data to correlate a_e7 with gs3 (n=0)\n",
      "Not enough data to correlate a_e7 with gs4 (n=0)\n",
      "Not enough data to correlate a_e7 with gs5 (n=0)\n",
      "Not enough data to correlate a_e7 with gs6 (n=0)\n",
      "Not enough data to correlate a_e7 with gs7 (n=0)\n",
      "Not enough data to correlate a_e7 with ge1 (n=0)\n",
      "Not enough data to correlate a_e7 with ge2 (n=0)\n",
      "Not enough data to correlate a_e7 with ge3 (n=0)\n",
      "Not enough data to correlate a_e7 with ge4 (n=0)\n",
      "Not enough data to correlate a_e7 with ge5 (n=0)\n",
      "Not enough data to correlate a_e7 with ge6 (n=0)\n",
      "Not enough data to correlate a_e7 with gf1 (n=0)\n",
      "Not enough data to correlate a_e7 with gf2 (n=0)\n",
      "Not enough data to correlate a_e7 with gf3 (n=0)\n",
      "Not enough data to correlate a_e7 with gf4 (n=0)\n",
      "Not enough data to correlate a_e7 with gf5 (n=0)\n",
      "Not enough data to correlate a_e7 with gf6 (n=0)\n",
      "Not enough data to correlate a_e7 with gf7 (n=0)\n",
      "Not enough data to correlate a_e7 with a_hn1 (n=0)\n",
      "Not enough data to correlate a_e7 with a_hn2 (n=0)\n",
      "Not enough data to correlate a_e7 with a_hn3 (n=0)\n",
      "Not enough data to correlate a_e7 with a_hn4 (n=0)\n",
      "Not enough data to correlate a_e7 with a_hn5 (n=0)\n",
      "Not enough data to correlate a_e7 with a_hn7 (n=0)\n",
      "Not enough data to correlate a_e7 with a_hn10 (n=0)\n",
      "Not enough data to correlate a_e7 with a_e1 (n=0)\n",
      "Not enough data to correlate a_e7 with a_e2 (n=0)\n",
      "Not enough data to correlate a_e7 with a_e3 (n=0)\n",
      "Not enough data to correlate a_e7 with a_e4 (n=0)\n",
      "Not enough data to correlate a_e7 with a_e5 (n=0)\n",
      "Not enough data to correlate a_e7 with a_e6 (n=0)\n",
      "Not enough data to correlate a_e7 with a_c6 (n=0)\n",
      "Not enough data to correlate a_e7 with a_c2 (n=0)\n",
      "Not enough data to correlate a_e7 with a_act11 (n=0)\n",
      "Not enough data to correlate a_c6 with gp1 (n=0)\n",
      "Not enough data to correlate a_c6 with gp2 (n=0)\n",
      "Not enough data to correlate a_c6 with gp3 (n=0)\n",
      "Not enough data to correlate a_c6 with gp4 (n=0)\n",
      "Not enough data to correlate a_c6 with gp5 (n=0)\n",
      "Not enough data to correlate a_c6 with gp6 (n=0)\n",
      "Not enough data to correlate a_c6 with gp7 (n=0)\n",
      "Not enough data to correlate a_c6 with gs1 (n=0)\n",
      "Not enough data to correlate a_c6 with gs2 (n=0)\n",
      "Not enough data to correlate a_c6 with gs3 (n=0)\n",
      "Not enough data to correlate a_c6 with gs4 (n=0)\n",
      "Not enough data to correlate a_c6 with gs5 (n=0)\n",
      "Not enough data to correlate a_c6 with gs6 (n=0)\n",
      "Not enough data to correlate a_c6 with gs7 (n=0)\n",
      "Not enough data to correlate a_c6 with ge1 (n=0)\n",
      "Not enough data to correlate a_c6 with ge2 (n=0)\n",
      "Not enough data to correlate a_c6 with ge3 (n=0)\n",
      "Not enough data to correlate a_c6 with ge4 (n=0)\n",
      "Not enough data to correlate a_c6 with ge5 (n=0)\n",
      "Not enough data to correlate a_c6 with ge6 (n=0)\n",
      "Not enough data to correlate a_c6 with gf1 (n=0)\n",
      "Not enough data to correlate a_c6 with gf2 (n=0)\n",
      "Not enough data to correlate a_c6 with gf3 (n=0)\n",
      "Not enough data to correlate a_c6 with gf4 (n=0)\n",
      "Not enough data to correlate a_c6 with gf5 (n=0)\n",
      "Not enough data to correlate a_c6 with gf6 (n=0)\n",
      "Not enough data to correlate a_c6 with gf7 (n=0)\n",
      "Not enough data to correlate a_c6 with a_hn1 (n=0)\n",
      "Not enough data to correlate a_c6 with a_hn2 (n=0)\n",
      "Not enough data to correlate a_c6 with a_hn3 (n=0)\n",
      "Not enough data to correlate a_c6 with a_hn4 (n=0)\n",
      "Not enough data to correlate a_c6 with a_hn5 (n=0)\n",
      "Not enough data to correlate a_c6 with a_hn7 (n=0)\n",
      "Not enough data to correlate a_c6 with a_hn10 (n=0)\n",
      "Not enough data to correlate a_c6 with a_e1 (n=0)\n",
      "Not enough data to correlate a_c6 with a_e2 (n=0)\n",
      "Not enough data to correlate a_c6 with a_e3 (n=0)\n",
      "Not enough data to correlate a_c6 with a_e4 (n=0)\n",
      "Not enough data to correlate a_c6 with a_e5 (n=0)\n",
      "Not enough data to correlate a_c6 with a_e6 (n=0)\n",
      "Not enough data to correlate a_c6 with a_e7 (n=0)\n",
      "Not enough data to correlate a_c6 with a_c2 (n=0)\n",
      "Not enough data to correlate a_c6 with a_act11 (n=0)\n",
      "Not enough data to correlate a_c2 with gp1 (n=0)\n",
      "Not enough data to correlate a_c2 with gp2 (n=0)\n",
      "Not enough data to correlate a_c2 with gp3 (n=0)\n",
      "Not enough data to correlate a_c2 with gp4 (n=0)\n",
      "Not enough data to correlate a_c2 with gp5 (n=0)\n",
      "Not enough data to correlate a_c2 with gp6 (n=0)\n",
      "Not enough data to correlate a_c2 with gp7 (n=0)\n",
      "Not enough data to correlate a_c2 with gs1 (n=0)\n",
      "Not enough data to correlate a_c2 with gs2 (n=0)\n",
      "Not enough data to correlate a_c2 with gs3 (n=0)\n",
      "Not enough data to correlate a_c2 with gs4 (n=0)\n",
      "Not enough data to correlate a_c2 with gs5 (n=0)\n",
      "Not enough data to correlate a_c2 with gs6 (n=0)\n",
      "Not enough data to correlate a_c2 with gs7 (n=0)\n",
      "Not enough data to correlate a_c2 with ge1 (n=0)\n",
      "Not enough data to correlate a_c2 with ge2 (n=0)\n",
      "Not enough data to correlate a_c2 with ge3 (n=0)\n",
      "Not enough data to correlate a_c2 with ge4 (n=0)\n",
      "Not enough data to correlate a_c2 with ge5 (n=0)\n",
      "Not enough data to correlate a_c2 with ge6 (n=0)\n",
      "Not enough data to correlate a_c2 with gf1 (n=0)\n",
      "Not enough data to correlate a_c2 with gf2 (n=0)\n",
      "Not enough data to correlate a_c2 with gf3 (n=0)\n",
      "Not enough data to correlate a_c2 with gf4 (n=0)\n",
      "Not enough data to correlate a_c2 with gf5 (n=0)\n",
      "Not enough data to correlate a_c2 with gf6 (n=0)\n",
      "Not enough data to correlate a_c2 with gf7 (n=0)\n",
      "Not enough data to correlate a_c2 with a_hn1 (n=0)\n",
      "Not enough data to correlate a_c2 with a_hn2 (n=0)\n",
      "Not enough data to correlate a_c2 with a_hn3 (n=0)\n",
      "Not enough data to correlate a_c2 with a_hn4 (n=0)\n",
      "Not enough data to correlate a_c2 with a_hn5 (n=0)\n",
      "Not enough data to correlate a_c2 with a_hn7 (n=0)\n",
      "Not enough data to correlate a_c2 with a_hn10 (n=0)\n",
      "Not enough data to correlate a_c2 with a_e1 (n=0)\n",
      "Not enough data to correlate a_c2 with a_e2 (n=0)\n",
      "Not enough data to correlate a_c2 with a_e3 (n=0)\n",
      "Not enough data to correlate a_c2 with a_e4 (n=0)\n",
      "Not enough data to correlate a_c2 with a_e5 (n=0)\n",
      "Not enough data to correlate a_c2 with a_e6 (n=0)\n",
      "Not enough data to correlate a_c2 with a_e7 (n=0)\n",
      "Not enough data to correlate a_c2 with a_c6 (n=0)\n",
      "Not enough data to correlate a_c2 with a_act11 (n=0)\n",
      "Not enough data to correlate a_act11 with gp1 (n=0)\n",
      "Not enough data to correlate a_act11 with gp2 (n=0)\n",
      "Not enough data to correlate a_act11 with gp3 (n=0)\n",
      "Not enough data to correlate a_act11 with gp4 (n=0)\n",
      "Not enough data to correlate a_act11 with gp5 (n=0)\n",
      "Not enough data to correlate a_act11 with gp6 (n=0)\n",
      "Not enough data to correlate a_act11 with gp7 (n=0)\n",
      "Not enough data to correlate a_act11 with gs1 (n=0)\n",
      "Not enough data to correlate a_act11 with gs2 (n=0)\n",
      "Not enough data to correlate a_act11 with gs3 (n=0)\n",
      "Not enough data to correlate a_act11 with gs4 (n=0)\n",
      "Not enough data to correlate a_act11 with gs5 (n=0)\n",
      "Not enough data to correlate a_act11 with gs6 (n=0)\n",
      "Not enough data to correlate a_act11 with gs7 (n=0)\n",
      "Not enough data to correlate a_act11 with ge1 (n=0)\n",
      "Not enough data to correlate a_act11 with ge2 (n=0)\n",
      "Not enough data to correlate a_act11 with ge3 (n=0)\n",
      "Not enough data to correlate a_act11 with ge4 (n=0)\n",
      "Not enough data to correlate a_act11 with ge5 (n=0)\n",
      "Not enough data to correlate a_act11 with ge6 (n=0)\n",
      "Not enough data to correlate a_act11 with gf1 (n=0)\n",
      "Not enough data to correlate a_act11 with gf2 (n=0)\n",
      "Not enough data to correlate a_act11 with gf3 (n=0)\n",
      "Not enough data to correlate a_act11 with gf4 (n=0)\n",
      "Not enough data to correlate a_act11 with gf5 (n=0)\n",
      "Not enough data to correlate a_act11 with gf6 (n=0)\n",
      "Not enough data to correlate a_act11 with gf7 (n=0)\n",
      "Not enough data to correlate a_act11 with a_hn1 (n=0)\n",
      "Not enough data to correlate a_act11 with a_hn2 (n=0)\n",
      "Not enough data to correlate a_act11 with a_hn3 (n=0)\n",
      "Not enough data to correlate a_act11 with a_hn4 (n=0)\n",
      "Not enough data to correlate a_act11 with a_hn5 (n=0)\n",
      "Not enough data to correlate a_act11 with a_hn7 (n=0)\n",
      "Not enough data to correlate a_act11 with a_hn10 (n=0)\n",
      "Not enough data to correlate a_act11 with a_e1 (n=0)\n",
      "Not enough data to correlate a_act11 with a_e2 (n=0)\n",
      "Not enough data to correlate a_act11 with a_e3 (n=0)\n",
      "Not enough data to correlate a_act11 with a_e4 (n=0)\n",
      "Not enough data to correlate a_act11 with a_e5 (n=0)\n",
      "Not enough data to correlate a_act11 with a_e6 (n=0)\n",
      "Not enough data to correlate a_act11 with a_e7 (n=0)\n",
      "Not enough data to correlate a_act11 with a_c6 (n=0)\n",
      "Not enough data to correlate a_act11 with a_c2 (n=0)\n",
      "\n",
      "--- Timepoint: 5_years_postop_arm_1 ---\n",
      "\n",
      "--- Timepoint: 1_month_postop_arm_1 ---\n",
      "\n",
      "--- Timepoint: preoperative_arm_1 ---\n",
      "\n",
      "--- Timepoint: 1_year_postop_arm_1 ---\n",
      "\n",
      "--- Timepoint: 3_months_postop_arm_1 ---\n",
      "\n",
      "--- Timepoint: 6_months_postop_arm_1 ---\n",
      "\n",
      "--- Timepoint: 2_years_postop_arm_1 ---\n",
      "\n",
      "--- Timepoint: 3_years_postop_arm_1 ---\n",
      "\n",
      "--- Timepoint: 4_years_postop_arm_1 ---\n",
      "\n",
      "--- Timepoint Correlations Computed ---\n",
      "{'baseline_arm_1':               gp1       gp2       gp3       gp4       gp5       gp6       gp7  \\\n",
      "gp1      1.000000  0.376251  0.533387  0.414626  0.261542  0.570929  0.552182   \n",
      "gp2      0.376251  1.000000  0.329306  0.365543  0.304171  0.470109  0.395585   \n",
      "gp3      0.533387  0.329306  1.000000  0.346561  0.311348  0.479973  0.508998   \n",
      "gp4      0.414626  0.365543  0.346561  1.000000  0.233289  0.533530  0.369897   \n",
      "gp5      0.261542  0.304171  0.311348  0.233289  1.000000  0.357934  0.311355   \n",
      "gp6      0.570929  0.470109  0.479973  0.533530  0.357934  1.000000  0.576420   \n",
      "gp7      0.552182  0.395585  0.508998  0.369897  0.311355  0.576420  1.000000   \n",
      "gs1     -0.186151 -0.122292 -0.170145 -0.095107 -0.094938 -0.189947 -0.168211   \n",
      "gs2     -0.007684 -0.055653 -0.046849 -0.016284 -0.075136 -0.068454 -0.035644   \n",
      "gs3     -0.129714 -0.111908 -0.075716 -0.077406 -0.079956 -0.140401 -0.127584   \n",
      "gs4     -0.058791 -0.128031 -0.061285 -0.089025 -0.099511 -0.129461 -0.070072   \n",
      "gs5     -0.092744 -0.123576 -0.111542 -0.070133 -0.165514 -0.146693 -0.098109   \n",
      "gs6     -0.111185 -0.157253 -0.075708 -0.073174 -0.103558 -0.119458 -0.154710   \n",
      "gs7     -0.273360 -0.179654 -0.242127 -0.159217 -0.099692 -0.227579 -0.243222   \n",
      "ge1      0.385030  0.281136  0.335895  0.304726  0.221943  0.455347  0.312673   \n",
      "ge2     -0.121564 -0.090136 -0.088890 -0.103115 -0.041988 -0.169076 -0.113678   \n",
      "ge3      0.339197  0.231008  0.291279  0.222766  0.154751  0.319256  0.275325   \n",
      "ge4      0.262423  0.215758  0.178536  0.266923  0.141437  0.337843  0.217393   \n",
      "ge5      0.166890  0.137890  0.117431  0.156086  0.132386  0.234738  0.138231   \n",
      "ge6      0.291646  0.180631  0.241722  0.276449  0.095141  0.345336  0.227126   \n",
      "gf1     -0.501965 -0.268834 -0.497723 -0.270394 -0.265799 -0.431448 -0.471299   \n",
      "gf2     -0.390468 -0.169980 -0.364425 -0.200766 -0.210210 -0.321144 -0.331911   \n",
      "gf3     -0.487007 -0.314374 -0.430890 -0.280266 -0.264484 -0.460513 -0.418700   \n",
      "gf4     -0.221742 -0.152390 -0.172274 -0.158215 -0.113490 -0.289851 -0.170468   \n",
      "gf5     -0.325379 -0.213792 -0.216585 -0.265623 -0.107035 -0.280723 -0.237682   \n",
      "gf6     -0.479488 -0.285798 -0.425848 -0.277192 -0.251750 -0.451792 -0.444795   \n",
      "gf7     -0.474568 -0.353990 -0.420687 -0.324976 -0.230808 -0.482288 -0.443180   \n",
      "a_hn1   -0.333810 -0.284494 -0.264739 -0.364456 -0.155423 -0.404274 -0.298115   \n",
      "a_hn2    0.313345  0.207834  0.208934  0.184359  0.209834  0.249137  0.264380   \n",
      "a_hn3    0.309605  0.225562  0.213496  0.193408  0.122089  0.222355  0.228387   \n",
      "a_hn4   -0.279051 -0.179982 -0.254185 -0.150673 -0.228750 -0.255834 -0.239849   \n",
      "a_hn5   -0.347358 -0.309072 -0.267337 -0.369553 -0.127107 -0.405425 -0.302243   \n",
      "a_hn7   -0.243038 -0.213298 -0.207873 -0.287117 -0.009810 -0.309401 -0.191520   \n",
      "a_hn10  -0.234414 -0.166782 -0.258328 -0.197037 -0.189491 -0.271346 -0.232677   \n",
      "a_e1     0.213592  0.160651  0.123367  0.284717 -0.045914  0.239244  0.141673   \n",
      "a_e2     0.254905  0.189790  0.196172  0.249349 -0.025510  0.285751  0.199062   \n",
      "a_e3     0.243863  0.234820  0.210712  0.290015  0.051883  0.291995  0.249769   \n",
      "a_e4     0.238852  0.255140  0.179052  0.511342  0.081961  0.366406  0.228838   \n",
      "a_e5     0.203129  0.214112  0.160184  0.257275  0.044199  0.260139  0.205226   \n",
      "a_e6    -0.301529 -0.298301 -0.235019 -0.293664 -0.149761 -0.358921 -0.247601   \n",
      "a_e7     0.171939  0.166502  0.093152  0.198429  0.023226  0.133695  0.142388   \n",
      "a_c6    -0.378016 -0.264743 -0.268707 -0.335267 -0.150970 -0.417807 -0.308677   \n",
      "a_c2     0.368592  0.310621  0.245203  0.336647  0.096597  0.406955  0.307890   \n",
      "a_act11  0.249436  0.300989  0.223188  0.493446  0.213873  0.379124  0.257788   \n",
      "\n",
      "              gs1       gs2       gs3  ...      a_e1      a_e2      a_e3  \\\n",
      "gp1     -0.186151 -0.007684 -0.129714  ...  0.213592  0.254905  0.243863   \n",
      "gp2     -0.122292 -0.055653 -0.111908  ...  0.160651  0.189790  0.234820   \n",
      "gp3     -0.170145 -0.046849 -0.075716  ...  0.123367  0.196172  0.210712   \n",
      "gp4     -0.095107 -0.016284 -0.077406  ...  0.284717  0.249349  0.290015   \n",
      "gp5     -0.094938 -0.075136 -0.079956  ... -0.045914 -0.025510  0.051883   \n",
      "gp6     -0.189947 -0.068454 -0.140401  ...  0.239244  0.285751  0.291995   \n",
      "gp7     -0.168211 -0.035644 -0.127584  ...  0.141673  0.199062  0.249769   \n",
      "gs1      1.000000  0.385798  0.679209  ... -0.025599 -0.067330 -0.092180   \n",
      "gs2      0.385798  1.000000  0.492343  ...  0.054890 -0.008854 -0.008410   \n",
      "gs3      0.679209  0.492343  1.000000  ... -0.005576 -0.059178 -0.061777   \n",
      "gs4      0.294493  0.484412  0.376884  ... -0.010817 -0.062356 -0.042119   \n",
      "gs5      0.336599  0.584782  0.419291  ...  0.024852 -0.069852 -0.080739   \n",
      "gs6      0.269486  0.522237  0.393004  ... -0.001284 -0.071123 -0.046777   \n",
      "gs7      0.260727  0.236181  0.197131  ... -0.024923 -0.059155 -0.042289   \n",
      "ge1     -0.125218 -0.040435 -0.107803  ...  0.196830  0.200261  0.204134   \n",
      "ge2      0.136754  0.122261  0.138037  ... -0.052069 -0.085606 -0.106006   \n",
      "ge3     -0.157205 -0.083657 -0.161386  ...  0.123666  0.202879  0.185431   \n",
      "ge4     -0.068003  0.012360 -0.022419  ...  0.180760  0.159997  0.158813   \n",
      "ge5     -0.003292  0.007754 -0.001918  ...  0.183032  0.167775  0.164272   \n",
      "ge6     -0.075711 -0.010330 -0.056046  ...  0.231820  0.241355  0.204332   \n",
      "gf1      0.226517  0.120876  0.195242  ... -0.131903 -0.161063 -0.165373   \n",
      "gf2      0.280763  0.204522  0.242462  ... -0.129584 -0.148791 -0.139016   \n",
      "gf3      0.298883  0.169035  0.262237  ... -0.167813 -0.204290 -0.197415   \n",
      "gf4      0.212432  0.141564  0.204438  ... -0.104533 -0.140601 -0.092746   \n",
      "gf5      0.145642  0.117559  0.118225  ... -0.114666 -0.107121 -0.155581   \n",
      "gf6      0.288376  0.124315  0.217029  ... -0.165228 -0.190205 -0.216686   \n",
      "gf7      0.246353  0.152192  0.196214  ... -0.208646 -0.255132 -0.286726   \n",
      "a_hn1    0.144764  0.068161  0.057140  ... -0.539261 -0.513201 -0.376033   \n",
      "a_hn2   -0.058262 -0.055040 -0.081471  ...  0.107268  0.179738  0.157617   \n",
      "a_hn3   -0.105300 -0.062090 -0.092292  ...  0.103461  0.107929  0.148753   \n",
      "a_hn4    0.200090  0.083867  0.140317  ... -0.086936 -0.165988 -0.133736   \n",
      "a_hn5    0.152550  0.056490  0.045963  ... -0.459683 -0.455407 -0.349773   \n",
      "a_hn7    0.115155  0.014015  0.058094  ... -0.530097 -0.520078 -0.418756   \n",
      "a_hn10   0.322438  0.214785  0.298678  ... -0.026370 -0.098832 -0.077412   \n",
      "a_e1    -0.025599  0.054890 -0.005576  ...  1.000000  0.646023  0.446730   \n",
      "a_e2    -0.067330 -0.008854 -0.059178  ...  0.646023  1.000000  0.687751   \n",
      "a_e3    -0.092180 -0.008410 -0.061777  ...  0.446730  0.687751  1.000000   \n",
      "a_e4    -0.048487  0.028237 -0.018429  ...  0.412555  0.434557  0.451572   \n",
      "a_e5    -0.081572  0.039291 -0.036090  ...  0.355783  0.411599  0.397188   \n",
      "a_e6     0.206028  0.162025  0.156717  ... -0.449673 -0.456614 -0.357461   \n",
      "a_e7    -0.056976 -0.058383 -0.074821  ...  0.144411  0.148685  0.153156   \n",
      "a_c6     0.142831  0.054910  0.123279  ... -0.353424 -0.358714 -0.267400   \n",
      "a_c2    -0.050060  0.023234 -0.005662  ...  0.419684  0.426363  0.354047   \n",
      "a_act11 -0.068087 -0.042084 -0.099011  ...  0.109418  0.130195  0.170938   \n",
      "\n",
      "             a_e4      a_e5      a_e6      a_e7      a_c6      a_c2   a_act11  \n",
      "gp1      0.238852  0.203129 -0.301529  0.171939 -0.378016  0.368592  0.249436  \n",
      "gp2      0.255140  0.214112 -0.298301  0.166502 -0.264743  0.310621  0.300989  \n",
      "gp3      0.179052  0.160184 -0.235019  0.093152 -0.268707  0.245203  0.223188  \n",
      "gp4      0.511342  0.257275 -0.293664  0.198429 -0.335267  0.336647  0.493446  \n",
      "gp5      0.081961  0.044199 -0.149761  0.023226 -0.150970  0.096597  0.213873  \n",
      "gp6      0.366406  0.260139 -0.358921  0.133695 -0.417807  0.406955  0.379124  \n",
      "gp7      0.228838  0.205226 -0.247601  0.142388 -0.308677  0.307890  0.257788  \n",
      "gs1     -0.048487 -0.081572  0.206028 -0.056976  0.142831 -0.050060 -0.068087  \n",
      "gs2      0.028237  0.039291  0.162025 -0.058383  0.054910  0.023234 -0.042084  \n",
      "gs3     -0.018429 -0.036090  0.156717 -0.074821  0.123279 -0.005662 -0.099011  \n",
      "gs4     -0.067206  0.005238  0.177071 -0.004628  0.131193 -0.084775 -0.070859  \n",
      "gs5     -0.041755  0.024519  0.177020 -0.004016  0.127259 -0.072990 -0.103511  \n",
      "gs6     -0.005367 -0.041768  0.156989 -0.089005  0.098442 -0.047671 -0.091000  \n",
      "gs7     -0.082970 -0.062732  0.210091 -0.129682  0.218029 -0.135201 -0.075803  \n",
      "ge1      0.231068  0.214673 -0.249083  0.116701 -0.263202  0.232351  0.242447  \n",
      "ge2     -0.079298 -0.060903  0.164313 -0.027450  0.141169 -0.116536 -0.097825  \n",
      "ge3      0.199227  0.168598 -0.195819  0.146162 -0.229405  0.190786  0.191450  \n",
      "ge4      0.245857  0.190475 -0.174650  0.172724 -0.210437  0.225263  0.237810  \n",
      "ge5      0.220008  0.126738 -0.180803  0.097279 -0.165359  0.138568  0.154889  \n",
      "ge6      0.252516  0.217780 -0.234422  0.145809 -0.248844  0.227809  0.205649  \n",
      "gf1     -0.119294 -0.114398  0.333578 -0.132351  0.361465 -0.244112 -0.175271  \n",
      "gf2     -0.116793 -0.079112  0.315374 -0.086045  0.330210 -0.189906 -0.162963  \n",
      "gf3     -0.188291 -0.127310  0.429154 -0.142511  0.379303 -0.263184 -0.199436  \n",
      "gf4     -0.152683 -0.079111  0.263027 -0.001983  0.258767 -0.154183 -0.072773  \n",
      "gf5     -0.215488 -0.166553  0.221189 -0.177123  0.242480 -0.201836 -0.218333  \n",
      "gf6     -0.190339 -0.162658  0.430265 -0.145452  0.393831 -0.285318 -0.219991  \n",
      "gf7     -0.254872 -0.197059  0.453326 -0.154525  0.383901 -0.338487 -0.282956  \n",
      "a_hn1   -0.351013 -0.291238  0.654768 -0.090858  0.569383 -0.505877 -0.134332  \n",
      "a_hn2    0.118470  0.215185 -0.157115  0.194546 -0.223702  0.184749  0.180529  \n",
      "a_hn3    0.159813  0.210783 -0.111333  0.319201 -0.114566  0.089780  0.200827  \n",
      "a_hn4   -0.076789 -0.126476  0.268180 -0.102726  0.290994 -0.191142 -0.080602  \n",
      "a_hn5   -0.338714 -0.276702  0.621252 -0.077358  0.608097 -0.527228 -0.163661  \n",
      "a_hn7   -0.421240 -0.391309  0.529906 -0.087342  0.446899 -0.404320 -0.095141  \n",
      "a_hn10  -0.083455 -0.128376  0.261182 -0.080097  0.326364 -0.103898 -0.092142  \n",
      "a_e1     0.412555  0.355783 -0.449673  0.144411 -0.353424  0.419684  0.109418  \n",
      "a_e2     0.434557  0.411599 -0.456614  0.148685 -0.358714  0.426363  0.130195  \n",
      "a_e3     0.451572  0.397188 -0.357461  0.153156 -0.267400  0.354047  0.170938  \n",
      "a_e4     1.000000  0.367299 -0.304032  0.131662 -0.295250  0.369620  0.325724  \n",
      "a_e5     0.367299  1.000000 -0.316899  0.264759 -0.255445  0.241982  0.166819  \n",
      "a_e6    -0.304032 -0.316899  1.000000 -0.125344  0.573708 -0.434698 -0.158828  \n",
      "a_e7     0.131662  0.264759 -0.125344  1.000000 -0.048923  0.112909  0.207658  \n",
      "a_c6    -0.295250 -0.255445  0.573708 -0.048923  1.000000 -0.490826 -0.182089  \n",
      "a_c2     0.369620  0.241982 -0.434698  0.112909 -0.490826  1.000000  0.278730  \n",
      "a_act11  0.325724  0.166819 -0.158828  0.207658 -0.182089  0.278730  1.000000  \n",
      "\n",
      "[44 rows x 44 columns], 'surgery_arm_1':          gp1  gp2  gp3  gp4  gp5  gp6  gp7  gs1  gs2  gs3  ...  a_e1  a_e2  \\\n",
      "gp1      1.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "gp2      NaN  1.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "gp3      NaN  NaN  1.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "gp4      NaN  NaN  NaN  1.0  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "gp5      NaN  NaN  NaN  NaN  1.0  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "gp6      NaN  NaN  NaN  NaN  NaN  1.0  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "gp7      NaN  NaN  NaN  NaN  NaN  NaN  1.0  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "gs1      NaN  NaN  NaN  NaN  NaN  NaN  NaN  1.0  NaN  NaN  ...   NaN   NaN   \n",
      "gs2      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  1.0  NaN  ...   NaN   NaN   \n",
      "gs3      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  1.0  ...   NaN   NaN   \n",
      "gs4      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "gs5      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "gs6      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "gs7      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "ge1      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "ge2      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "ge3      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "ge4      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "ge5      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "ge6      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "gf1      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "gf2      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "gf3      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "gf4      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "gf5      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "gf6      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "gf7      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "a_hn1    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "a_hn2    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "a_hn3    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "a_hn4    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "a_hn5    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "a_hn7    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "a_hn10   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "a_e1     NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   1.0   NaN   \n",
      "a_e2     NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   1.0   \n",
      "a_e3     NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "a_e4     NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "a_e5     NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "a_e6     NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "a_e7     NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "a_c6     NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "a_c2     NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "a_act11  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   \n",
      "\n",
      "         a_e3  a_e4  a_e5  a_e6  a_e7  a_c6  a_c2  a_act11  \n",
      "gp1       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "gp2       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "gp3       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "gp4       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "gp5       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "gp6       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "gp7       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "gs1       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "gs2       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "gs3       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "gs4       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "gs5       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "gs6       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "gs7       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "ge1       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "ge2       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "ge3       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "ge4       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "ge5       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "ge6       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "gf1       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "gf2       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "gf3       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "gf4       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "gf5       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "gf6       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "gf7       NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "a_hn1     NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "a_hn2     NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "a_hn3     NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "a_hn4     NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "a_hn5     NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "a_hn7     NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "a_hn10    NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "a_e1      NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "a_e2      NaN   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "a_e3      1.0   NaN   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "a_e4      NaN   1.0   NaN   NaN   NaN   NaN   NaN      NaN  \n",
      "a_e5      NaN   NaN   1.0   NaN   NaN   NaN   NaN      NaN  \n",
      "a_e6      NaN   NaN   NaN   1.0   NaN   NaN   NaN      NaN  \n",
      "a_e7      NaN   NaN   NaN   NaN   1.0   NaN   NaN      NaN  \n",
      "a_c6      NaN   NaN   NaN   NaN   NaN   1.0   NaN      NaN  \n",
      "a_c2      NaN   NaN   NaN   NaN   NaN   NaN   1.0      NaN  \n",
      "a_act11   NaN   NaN   NaN   NaN   NaN   NaN   NaN      1.0  \n",
      "\n",
      "[44 rows x 44 columns], '5_years_postop_arm_1':               gp1       gp2       gp3       gp4       gp5       gp6       gp7  \\\n",
      "gp1      1.000000  0.157411  0.341450  0.286258  0.196302  0.324117  0.517648   \n",
      "gp2      0.157411  1.000000  0.363734  0.306640  0.344167  0.506557  0.295313   \n",
      "gp3      0.341450  0.363734  1.000000  0.349969  0.293076  0.500833  0.286962   \n",
      "gp4      0.286258  0.306640  0.349969  1.000000  0.162114  0.415611  0.193466   \n",
      "gp5      0.196302  0.344167  0.293076  0.162114  1.000000  0.427919  0.209447   \n",
      "gp6      0.324117  0.506557  0.500833  0.415611  0.427919  1.000000  0.502648   \n",
      "gp7      0.517648  0.295313  0.286962  0.193466  0.209447  0.502648  1.000000   \n",
      "gs1     -0.348228 -0.194246 -0.232814 -0.116250 -0.042675 -0.199360 -0.339691   \n",
      "gs2     -0.068787 -0.304495 -0.016801 -0.031955 -0.134702 -0.178923 -0.202356   \n",
      "gs3     -0.234831 -0.175456 -0.136642 -0.055493 -0.004628 -0.111233 -0.192939   \n",
      "gs4     -0.112044 -0.140957 -0.289125 -0.157943 -0.099183 -0.093267 -0.113602   \n",
      "gs5     -0.102578 -0.275531 -0.308966 -0.099022 -0.153019 -0.040173 -0.044831   \n",
      "gs6     -0.052767 -0.316925 -0.155391  0.062636 -0.421421 -0.186942 -0.113947   \n",
      "gs7     -0.159181 -0.091738 -0.101962  0.118195 -0.356611 -0.074502 -0.203780   \n",
      "ge1      0.328786  0.201428  0.170689  0.130291  0.019758  0.269712  0.371470   \n",
      "ge2     -0.111387 -0.293125 -0.208331 -0.104831 -0.194277 -0.274910 -0.243605   \n",
      "ge3      0.354868  0.203546  0.079414  0.081419  0.187403  0.253055  0.356325   \n",
      "ge4      0.253198  0.191357  0.094605  0.134364  0.109523  0.291705  0.251875   \n",
      "ge5      0.200719  0.047267  0.319865  0.147237  0.076289  0.364664  0.311218   \n",
      "ge6      0.222764  0.066602  0.251891  0.314258  0.077917  0.245964  0.268198   \n",
      "gf1     -0.520502 -0.107411 -0.415823 -0.110813 -0.076998 -0.373141 -0.431227   \n",
      "gf2     -0.389313 -0.106862 -0.414768 -0.091968 -0.106082 -0.362962 -0.243966   \n",
      "gf3     -0.485306 -0.059193 -0.372386 -0.115528 -0.140795 -0.270551 -0.382942   \n",
      "gf4     -0.171960 -0.199108 -0.242628 -0.173031 -0.133183 -0.310051 -0.202321   \n",
      "gf5     -0.092556 -0.199389 -0.149006 -0.255121 -0.251799 -0.358347 -0.176027   \n",
      "gf6     -0.533502 -0.128969 -0.253388 -0.160570 -0.280281 -0.274061 -0.479481   \n",
      "gf7     -0.483187 -0.271467 -0.390152 -0.203064 -0.265446 -0.457107 -0.483386   \n",
      "a_hn1   -0.358968 -0.200758 -0.284172 -0.232801 -0.282022 -0.289403 -0.370631   \n",
      "a_hn2    0.160383  0.261063  0.312207  0.184816  0.213327  0.449570  0.292131   \n",
      "a_hn3    0.525325  0.241327  0.316790  0.354735  0.321737  0.400603  0.314212   \n",
      "a_hn4   -0.285346 -0.328294 -0.251598 -0.227814 -0.271298 -0.390400 -0.210378   \n",
      "a_hn5   -0.498526 -0.067976 -0.360944 -0.174463 -0.238655 -0.230035 -0.302190   \n",
      "a_hn7   -0.361128 -0.179039 -0.350299 -0.367249 -0.214505 -0.274028 -0.170436   \n",
      "a_hn10  -0.187865 -0.139404 -0.285966 -0.147590 -0.169481 -0.222394 -0.177864   \n",
      "a_e1     0.280584  0.278191  0.264558  0.309192  0.150379  0.267594  0.218184   \n",
      "a_e2    -0.080443  0.175299  0.068049  0.147416  0.011118  0.196409  0.067533   \n",
      "a_e3     0.061865  0.138985  0.106352  0.071764  0.047920  0.083348 -0.056917   \n",
      "a_e4     0.345988  0.070565  0.300940  0.325687 -0.055845  0.037908  0.286080   \n",
      "a_e5     0.204060  0.252193  0.146878  0.280297  0.231707  0.278020  0.179474   \n",
      "a_e6    -0.404712 -0.236791 -0.447104 -0.253296 -0.284442 -0.315647 -0.263182   \n",
      "a_e7     0.218408  0.144971  0.013111  0.059502  0.085359  0.279207  0.435755   \n",
      "a_c6    -0.238326 -0.150130 -0.418953 -0.267740 -0.224601 -0.395989 -0.250416   \n",
      "a_c2     0.400098  0.144872  0.252004  0.281458  0.064210  0.186731  0.246980   \n",
      "a_act11  0.340356  0.274208  0.172929  0.451620  0.261059  0.317879  0.365210   \n",
      "\n",
      "              gs1       gs2       gs3  ...      a_e1      a_e2      a_e3  \\\n",
      "gp1     -0.348228 -0.068787 -0.234831  ...  0.280584 -0.080443  0.061865   \n",
      "gp2     -0.194246 -0.304495 -0.175456  ...  0.278191  0.175299  0.138985   \n",
      "gp3     -0.232814 -0.016801 -0.136642  ...  0.264558  0.068049  0.106352   \n",
      "gp4     -0.116250 -0.031955 -0.055493  ...  0.309192  0.147416  0.071764   \n",
      "gp5     -0.042675 -0.134702 -0.004628  ...  0.150379  0.011118  0.047920   \n",
      "gp6     -0.199360 -0.178923 -0.111233  ...  0.267594  0.196409  0.083348   \n",
      "gp7     -0.339691 -0.202356 -0.192939  ...  0.218184  0.067533 -0.056917   \n",
      "gs1      1.000000  0.544076  0.820808  ... -0.224086  0.032753  0.005650   \n",
      "gs2      0.544076  1.000000  0.630916  ... -0.085244 -0.113502  0.011409   \n",
      "gs3      0.820808  0.630916  1.000000  ... -0.223078  0.032851 -0.042195   \n",
      "gs4      0.406563  0.407103  0.447264  ... -0.293867 -0.005841 -0.000012   \n",
      "gs5      0.377864  0.347939  0.385016  ... -0.303905 -0.088185 -0.050319   \n",
      "gs6      0.289802  0.536327  0.273241  ... -0.118679 -0.035960 -0.007916   \n",
      "gs7      0.356121  0.284698  0.298468  ... -0.065610  0.326742  0.279476   \n",
      "ge1     -0.374806 -0.249801 -0.447972  ...  0.197769  0.061810  0.162704   \n",
      "ge2      0.326348  0.143526  0.282546  ... -0.281602 -0.183565 -0.064029   \n",
      "ge3     -0.320443 -0.338521 -0.325417  ...  0.044374 -0.084095 -0.028271   \n",
      "ge4     -0.332217 -0.223303 -0.284041  ...  0.052008 -0.071656 -0.045736   \n",
      "ge5     -0.306773 -0.075124 -0.274333  ...  0.165329  0.002505 -0.019360   \n",
      "ge6     -0.314160 -0.141774 -0.335426  ...  0.226679 -0.049593 -0.060415   \n",
      "gf1      0.525501  0.186195  0.435941  ... -0.170216  0.061611  0.006874   \n",
      "gf2      0.440996  0.096155  0.326780  ... -0.201636  0.110698  0.112296   \n",
      "gf3      0.546398  0.168911  0.443298  ... -0.269304  0.090188  0.045044   \n",
      "gf4      0.327781  0.163995  0.330034  ... -0.203884  0.090256 -0.000414   \n",
      "gf5     -0.030700  0.101362 -0.041797  ... -0.158588 -0.091076 -0.032008   \n",
      "gf6      0.473902  0.239628  0.418717  ... -0.175015  0.108115  0.003516   \n",
      "gf7      0.507285  0.203331  0.382291  ... -0.239561 -0.046510 -0.013597   \n",
      "a_hn1    0.300302  0.146303  0.273916  ... -0.381957 -0.004987 -0.085354   \n",
      "a_hn2   -0.199991 -0.196516 -0.200012  ...  0.225738  0.026384  0.213502   \n",
      "a_hn3   -0.162592  0.011343 -0.096534  ...  0.401565  0.152069  0.023191   \n",
      "a_hn4    0.263390  0.104407  0.229148  ... -0.240098 -0.003640  0.002200   \n",
      "a_hn5    0.305861  0.020861  0.296616  ... -0.328533  0.140420 -0.057654   \n",
      "a_hn7    0.290381  0.003746  0.220896  ... -0.553969 -0.131617 -0.308661   \n",
      "a_hn10   0.416802  0.223390  0.397192  ... -0.321108  0.143443  0.053419   \n",
      "a_e1    -0.224086 -0.085244 -0.223078  ...  1.000000  0.342770  0.372029   \n",
      "a_e2     0.032753 -0.113502  0.032851  ...  0.342770  1.000000  0.422417   \n",
      "a_e3     0.005650  0.011409 -0.042195  ...  0.372029  0.422417  1.000000   \n",
      "a_e4    -0.305228 -0.045254 -0.241792  ...  0.393594  0.042249  0.157218   \n",
      "a_e5    -0.167657 -0.206647 -0.218028  ...  0.193284  0.106011  0.164953   \n",
      "a_e6     0.433325  0.206584  0.387795  ... -0.438098  0.058094 -0.064937   \n",
      "a_e7    -0.225016 -0.046996 -0.106409  ... -0.078077 -0.188841 -0.061245   \n",
      "a_c6     0.315893  0.081856  0.324320  ... -0.441852  0.033150 -0.123941   \n",
      "a_c2    -0.166011  0.164218 -0.042139  ...  0.349155 -0.031043  0.024542   \n",
      "a_act11 -0.246033 -0.081776 -0.104381  ...  0.273540  0.124712  0.000642   \n",
      "\n",
      "             a_e4      a_e5      a_e6      a_e7      a_c6      a_c2   a_act11  \n",
      "gp1      0.345988  0.204060 -0.404712  0.218408 -0.238326  0.400098  0.340356  \n",
      "gp2      0.070565  0.252193 -0.236791  0.144971 -0.150130  0.144872  0.274208  \n",
      "gp3      0.300940  0.146878 -0.447104  0.013111 -0.418953  0.252004  0.172929  \n",
      "gp4      0.325687  0.280297 -0.253296  0.059502 -0.267740  0.281458  0.451620  \n",
      "gp5     -0.055845  0.231707 -0.284442  0.085359 -0.224601  0.064210  0.261059  \n",
      "gp6      0.037908  0.278020 -0.315647  0.279207 -0.395989  0.186731  0.317879  \n",
      "gp7      0.286080  0.179474 -0.263182  0.435755 -0.250416  0.246980  0.365210  \n",
      "gs1     -0.305228 -0.167657  0.433325 -0.225016  0.315893 -0.166011 -0.246033  \n",
      "gs2     -0.045254 -0.206647  0.206584 -0.046996  0.081856  0.164218 -0.081776  \n",
      "gs3     -0.241792 -0.218028  0.387795 -0.106409  0.324320 -0.042139 -0.104381  \n",
      "gs4     -0.190136 -0.167824  0.403983  0.132493  0.269002 -0.186032 -0.041740  \n",
      "gs5     -0.224935 -0.113939  0.376263  0.069708  0.240132 -0.141266 -0.032741  \n",
      "gs6     -0.043595 -0.043305  0.233770 -0.089256  0.021258  0.045279 -0.014943  \n",
      "gs7     -0.113215 -0.250182  0.079631 -0.059236  0.024112 -0.130278 -0.087846  \n",
      "ge1      0.261676  0.180746 -0.234213  0.142584 -0.143213  0.403072  0.251063  \n",
      "ge2     -0.111363 -0.133477  0.238537 -0.064159  0.253506 -0.161522 -0.259588  \n",
      "ge3      0.216864  0.140123 -0.269928  0.217356 -0.078088  0.134210  0.286997  \n",
      "ge4      0.244154  0.189939 -0.174783  0.261690 -0.090689  0.025588  0.235470  \n",
      "ge5      0.158560  0.152221 -0.339492  0.055716 -0.395533  0.208084  0.128962  \n",
      "ge6      0.229624  0.079145 -0.307892  0.118194 -0.325475  0.303440  0.201062  \n",
      "gf1     -0.210660 -0.080092  0.457618 -0.168681  0.349890 -0.270353 -0.236971  \n",
      "gf2     -0.103997  0.067932  0.552097 -0.078051  0.398937 -0.330022 -0.109676  \n",
      "gf3     -0.249585 -0.064308  0.524266 -0.171755  0.401362 -0.332410 -0.201973  \n",
      "gf4     -0.131806 -0.068158  0.358552 -0.096236  0.302706 -0.253059 -0.141371  \n",
      "gf5      0.266314 -0.092393  0.220443 -0.073178  0.188993 -0.072995 -0.226487  \n",
      "gf6     -0.194886 -0.167534  0.460035 -0.279725  0.279340 -0.297298 -0.289795  \n",
      "gf7     -0.127728 -0.146449  0.499627 -0.312892  0.424007 -0.341594 -0.320424  \n",
      "a_hn1   -0.229343 -0.262406  0.486518 -0.235458  0.467248 -0.237745 -0.155335  \n",
      "a_hn2    0.027072  0.167955 -0.229189  0.075638 -0.210937  0.127625  0.141545  \n",
      "a_hn3    0.160457  0.101954 -0.320438  0.047222 -0.407285  0.405228  0.316665  \n",
      "a_hn4   -0.102643 -0.026874  0.398375  0.034612  0.306312 -0.310263 -0.317123  \n",
      "a_hn5   -0.204034 -0.215843  0.465387 -0.120885  0.535557 -0.329316 -0.262770  \n",
      "a_hn7   -0.227313 -0.277136  0.439837  0.024287  0.495706 -0.368289 -0.120276  \n",
      "a_hn10  -0.186832 -0.146969  0.471305 -0.072963  0.327843 -0.312115 -0.089247  \n",
      "a_e1     0.393594  0.193284 -0.438098 -0.078077 -0.441852  0.349155  0.273540  \n",
      "a_e2     0.042249  0.106011  0.058094 -0.188841  0.033150 -0.031043  0.124712  \n",
      "a_e3     0.157218  0.164953 -0.064937 -0.061245 -0.123941  0.024542  0.000642  \n",
      "a_e4     1.000000  0.276143 -0.156909 -0.021259 -0.178237  0.205019  0.282074  \n",
      "a_e5     0.276143  1.000000 -0.099485  0.238138 -0.166599  0.019739  0.196621  \n",
      "a_e6    -0.156909 -0.099485  1.000000 -0.116082  0.582362 -0.371648 -0.149570  \n",
      "a_e7    -0.021259  0.238138 -0.116082  1.000000  0.009978  0.003032  0.057967  \n",
      "a_c6    -0.178237 -0.166599  0.582362  0.009978  1.000000 -0.326357 -0.160872  \n",
      "a_c2     0.205019  0.019739 -0.371648  0.003032 -0.326357  1.000000  0.334666  \n",
      "a_act11  0.282074  0.196621 -0.149570  0.057967 -0.160872  0.334666  1.000000  \n",
      "\n",
      "[44 rows x 44 columns], '1_month_postop_arm_1':               gp1       gp2       gp3       gp4       gp5       gp6       gp7  \\\n",
      "gp1      1.000000  0.317547  0.532554  0.350397  0.409140  0.534552  0.519885   \n",
      "gp2      0.317547  1.000000  0.267905  0.298474  0.354782  0.429025  0.354489   \n",
      "gp3      0.532554  0.267905  1.000000  0.367972  0.473138  0.557550  0.527988   \n",
      "gp4      0.350397  0.298474  0.367972  1.000000  0.408564  0.471548  0.412610   \n",
      "gp5      0.409140  0.354782  0.473138  0.408564  1.000000  0.610890  0.476142   \n",
      "gp6      0.534552  0.429025  0.557550  0.471548  0.610890  1.000000  0.643058   \n",
      "gp7      0.519885  0.354489  0.527988  0.412610  0.476142  0.643058  1.000000   \n",
      "gs1     -0.109478 -0.104683 -0.202396 -0.146314 -0.204356 -0.306282 -0.209404   \n",
      "gs2      0.077232 -0.019604  0.021356 -0.012233 -0.007726 -0.032092 -0.019640   \n",
      "gs3     -0.063586 -0.040980 -0.147442 -0.106482 -0.143370 -0.219869 -0.157985   \n",
      "gs4      0.088313  0.066716 -0.052469 -0.030355  0.007594 -0.057982 -0.037923   \n",
      "gs5      0.068988 -0.058121 -0.039564  0.001935 -0.068752 -0.137832 -0.133559   \n",
      "gs6      0.074178 -0.041394 -0.002304 -0.068590 -0.015307 -0.023908 -0.099985   \n",
      "gs7     -0.251435 -0.072012 -0.332691 -0.237288 -0.237077 -0.356438 -0.270057   \n",
      "ge1      0.409975  0.339273  0.427114  0.317780  0.422162  0.542686  0.427335   \n",
      "ge2     -0.213845 -0.205799 -0.177831 -0.147975 -0.275036 -0.329413 -0.169286   \n",
      "ge3      0.282991  0.326338  0.358492  0.178642  0.378418  0.422065  0.307436   \n",
      "ge4      0.325738  0.266385  0.341429  0.278281  0.272216  0.492492  0.340763   \n",
      "ge5      0.130198  0.170127  0.228846  0.125184  0.192235  0.263557  0.162270   \n",
      "ge6      0.188405  0.101064  0.284079  0.151009  0.234972  0.359031  0.251418   \n",
      "gf1     -0.465542 -0.263612 -0.492845 -0.353016 -0.381471 -0.515365 -0.505663   \n",
      "gf2     -0.410224 -0.240749 -0.396319 -0.314352 -0.393996 -0.494143 -0.485335   \n",
      "gf3     -0.409995 -0.297939 -0.501468 -0.309276 -0.469863 -0.557078 -0.518500   \n",
      "gf4     -0.196568 -0.157646 -0.229569 -0.110708 -0.312279 -0.312058 -0.229791   \n",
      "gf5     -0.303279 -0.124539 -0.268302 -0.303422 -0.170740 -0.313836 -0.251672   \n",
      "gf6     -0.433512 -0.250870 -0.425819 -0.323028 -0.432047 -0.478108 -0.470778   \n",
      "gf7     -0.464146 -0.301152 -0.452982 -0.323412 -0.452569 -0.506729 -0.474056   \n",
      "a_hn1   -0.251761 -0.230408 -0.327038 -0.263306 -0.268068 -0.314899 -0.316246   \n",
      "a_hn2    0.225751  0.126490  0.171827  0.168470  0.203428  0.285735  0.230566   \n",
      "a_hn3    0.276909  0.176666  0.248684  0.214074  0.193071  0.281000  0.259678   \n",
      "a_hn4   -0.323840 -0.203698 -0.197081 -0.085627 -0.227491 -0.261594 -0.214021   \n",
      "a_hn5   -0.347322 -0.252091 -0.333854 -0.234139 -0.300975 -0.356202 -0.331160   \n",
      "a_hn7   -0.185686 -0.146139 -0.172974 -0.106216 -0.215334 -0.232892 -0.249935   \n",
      "a_hn10  -0.219084 -0.149406 -0.252935 -0.122823 -0.195904 -0.322329 -0.260148   \n",
      "a_e1     0.154420  0.158430  0.184155  0.151919  0.142327  0.175425  0.254328   \n",
      "a_e2     0.155785  0.152994  0.082507  0.096974  0.148932  0.142528  0.145826   \n",
      "a_e3     0.157974  0.140005  0.073058  0.128855  0.207182  0.148896  0.189524   \n",
      "a_e4     0.147312  0.238459  0.125174  0.236103  0.188938  0.191193  0.221924   \n",
      "a_e5     0.160342  0.177228  0.133413  0.120179  0.181582  0.212768  0.241664   \n",
      "a_e6    -0.301764 -0.302440 -0.336199 -0.289296 -0.302807 -0.420346 -0.337343   \n",
      "a_e7     0.094649  0.120744  0.113004  0.115591  0.073716  0.107105  0.154279   \n",
      "a_c6    -0.349706 -0.338110 -0.334645 -0.242490 -0.354521 -0.424408 -0.364479   \n",
      "a_c2     0.388795  0.310761  0.331730  0.300427  0.400588  0.375235  0.339066   \n",
      "a_act11  0.248614  0.263964  0.276166  0.478241  0.274821  0.312306  0.269867   \n",
      "\n",
      "              gs1       gs2       gs3  ...      a_e1      a_e2      a_e3  \\\n",
      "gp1     -0.109478  0.077232 -0.063586  ...  0.154420  0.155785  0.157974   \n",
      "gp2     -0.104683 -0.019604 -0.040980  ...  0.158430  0.152994  0.140005   \n",
      "gp3     -0.202396  0.021356 -0.147442  ...  0.184155  0.082507  0.073058   \n",
      "gp4     -0.146314 -0.012233 -0.106482  ...  0.151919  0.096974  0.128855   \n",
      "gp5     -0.204356 -0.007726 -0.143370  ...  0.142327  0.148932  0.207182   \n",
      "gp6     -0.306282 -0.032092 -0.219869  ...  0.175425  0.142528  0.148896   \n",
      "gp7     -0.209404 -0.019640 -0.157985  ...  0.254328  0.145826  0.189524   \n",
      "gs1      1.000000  0.451500  0.705216  ... -0.110409 -0.061104 -0.038378   \n",
      "gs2      0.451500  1.000000  0.600773  ...  0.002867  0.000125  0.025754   \n",
      "gs3      0.705216  0.600773  1.000000  ... -0.078211 -0.036875 -0.055378   \n",
      "gs4      0.399867  0.615193  0.526813  ... -0.020309  0.003846 -0.022363   \n",
      "gs5      0.443819  0.628085  0.554257  ... -0.036437 -0.068961 -0.094345   \n",
      "gs6      0.387226  0.609441  0.514424  ...  0.018550  0.028883  0.041285   \n",
      "gs7      0.305515  0.267419  0.328370  ... -0.043977 -0.073054 -0.060782   \n",
      "ge1     -0.271081  0.005960 -0.154896  ...  0.213033  0.226244  0.162325   \n",
      "ge2      0.257031  0.141703  0.227369  ... -0.039037 -0.095112 -0.063291   \n",
      "ge3     -0.246563 -0.044109 -0.166834  ...  0.147076  0.204347  0.190968   \n",
      "ge4     -0.189631 -0.021634 -0.118889  ...  0.159123  0.231736  0.157730   \n",
      "ge5     -0.128272 -0.013660 -0.100963  ...  0.125132  0.076008  0.072482   \n",
      "ge6     -0.222553 -0.052167 -0.181312  ...  0.141304  0.136223  0.122641   \n",
      "gf1      0.228981  0.058487  0.190694  ... -0.182423 -0.110242 -0.115943   \n",
      "gf2      0.353179  0.119160  0.291928  ... -0.181014 -0.123968 -0.090630   \n",
      "gf3      0.375584  0.154150  0.287794  ... -0.139372 -0.127731 -0.087677   \n",
      "gf4      0.327725  0.165348  0.289477  ... -0.129814 -0.193296 -0.125299   \n",
      "gf5      0.231748  0.100002  0.195381  ... -0.126955 -0.061880 -0.032374   \n",
      "gf6      0.383525  0.158499  0.265756  ... -0.224110 -0.154962 -0.179225   \n",
      "gf7      0.357086  0.139080  0.230373  ... -0.239169 -0.172670 -0.152289   \n",
      "a_hn1    0.185067  0.068286  0.096868  ... -0.343058 -0.306179 -0.184429   \n",
      "a_hn2   -0.107191 -0.021551 -0.070785  ...  0.149685  0.202740  0.147000   \n",
      "a_hn3   -0.135602 -0.088667 -0.143404  ...  0.147432  0.245189  0.246794   \n",
      "a_hn4    0.102781  0.012513  0.064980  ... -0.062745 -0.084048 -0.060223   \n",
      "a_hn5    0.183141  0.040435  0.080279  ... -0.296209 -0.198471 -0.131739   \n",
      "a_hn7    0.176664  0.025653  0.056904  ... -0.482055 -0.393784 -0.280094   \n",
      "a_hn10   0.359554  0.267452  0.321157  ... -0.131052 -0.105648 -0.067018   \n",
      "a_e1    -0.110409  0.002867 -0.078211  ...  1.000000  0.506953  0.369958   \n",
      "a_e2    -0.061104  0.000125 -0.036875  ...  0.506953  1.000000  0.696402   \n",
      "a_e3    -0.038378  0.025754 -0.055378  ...  0.369958  0.696402  1.000000   \n",
      "a_e4    -0.110347 -0.032994 -0.073569  ...  0.255162  0.306774  0.304817   \n",
      "a_e5    -0.035153  0.123987 -0.002838  ...  0.327999  0.407144  0.380027   \n",
      "a_e6     0.356540  0.193528  0.271874  ... -0.185710 -0.201256 -0.135284   \n",
      "a_e7    -0.097562 -0.035911 -0.092771  ...  0.089820  0.072433  0.059819   \n",
      "a_c6     0.211363  0.047975  0.095102  ... -0.216418 -0.267282 -0.205825   \n",
      "a_c2    -0.116225  0.002893 -0.070080  ...  0.201636  0.224569  0.166269   \n",
      "a_act11 -0.089721 -0.030026 -0.047173  ...  0.113947  0.093685  0.182377   \n",
      "\n",
      "             a_e4      a_e5      a_e6      a_e7      a_c6      a_c2   a_act11  \n",
      "gp1      0.147312  0.160342 -0.301764  0.094649 -0.349706  0.388795  0.248614  \n",
      "gp2      0.238459  0.177228 -0.302440  0.120744 -0.338110  0.310761  0.263964  \n",
      "gp3      0.125174  0.133413 -0.336199  0.113004 -0.334645  0.331730  0.276166  \n",
      "gp4      0.236103  0.120179 -0.289296  0.115591 -0.242490  0.300427  0.478241  \n",
      "gp5      0.188938  0.181582 -0.302807  0.073716 -0.354521  0.400588  0.274821  \n",
      "gp6      0.191193  0.212768 -0.420346  0.107105 -0.424408  0.375235  0.312306  \n",
      "gp7      0.221924  0.241664 -0.337343  0.154279 -0.364479  0.339066  0.269867  \n",
      "gs1     -0.110347 -0.035153  0.356540 -0.097562  0.211363 -0.116225 -0.089721  \n",
      "gs2     -0.032994  0.123987  0.193528 -0.035911  0.047975  0.002893 -0.030026  \n",
      "gs3     -0.073569 -0.002838  0.271874 -0.092771  0.095102 -0.070080 -0.047173  \n",
      "gs4     -0.042928  0.016694  0.149988 -0.059967  0.069648  0.034112 -0.102163  \n",
      "gs5     -0.130144  0.021437  0.173326 -0.073671  0.101237  0.000477 -0.062267  \n",
      "gs6      0.018862  0.078611  0.210692 -0.049951  0.052375 -0.019456 -0.108487  \n",
      "gs7     -0.055752  0.022645  0.319937 -0.062218  0.270838 -0.165106 -0.239858  \n",
      "ge1      0.135708  0.210936 -0.400178  0.011071 -0.426097  0.302192  0.194058  \n",
      "ge2     -0.100913 -0.115327  0.302850 -0.048030  0.307701 -0.146381 -0.062977  \n",
      "ge3      0.145751  0.199466 -0.282100  0.040146 -0.267450  0.296697  0.152322  \n",
      "ge4      0.134833  0.191903 -0.284188  0.014710 -0.230927  0.214531  0.168782  \n",
      "ge5      0.087269  0.089682 -0.223651  0.053471 -0.157377  0.081439  0.098871  \n",
      "ge6      0.149350  0.130634 -0.262026  0.055537 -0.214215  0.155878  0.176758  \n",
      "gf1     -0.086059 -0.100929  0.400638 -0.066725  0.391246 -0.324988 -0.257131  \n",
      "gf2     -0.084273 -0.126395  0.439170 -0.031314  0.392081 -0.264360 -0.188378  \n",
      "gf3     -0.143237 -0.127500  0.514225 -0.047488  0.480794 -0.318295 -0.236537  \n",
      "gf4     -0.040440 -0.137757  0.299367 -0.078757  0.290802 -0.086109 -0.118909  \n",
      "gf5     -0.138859 -0.064571  0.323359 -0.214680  0.244752 -0.161572 -0.169726  \n",
      "gf6     -0.095464 -0.126887  0.518787 -0.118802  0.457604 -0.289620 -0.272144  \n",
      "gf7     -0.082515 -0.137204  0.506098 -0.100428  0.473953 -0.280527 -0.279980  \n",
      "a_hn1   -0.166250 -0.222578  0.622103 -0.123285  0.559521 -0.380084 -0.164378  \n",
      "a_hn2    0.159566  0.143253 -0.298683  0.074658 -0.215644  0.187078  0.123131  \n",
      "a_hn3    0.225786  0.192958 -0.258156  0.286634 -0.253608  0.226928  0.178472  \n",
      "a_hn4   -0.001343 -0.086729  0.270246 -0.111342  0.322796 -0.247477 -0.040289  \n",
      "a_hn5   -0.148862 -0.148570  0.519276 -0.147582  0.552520 -0.383066 -0.259717  \n",
      "a_hn7   -0.274731 -0.313703  0.362656 -0.141056  0.357255 -0.186056 -0.158716  \n",
      "a_hn10  -0.104079 -0.094948  0.315746 -0.098641  0.319390 -0.157146 -0.035890  \n",
      "a_e1     0.255162  0.327999 -0.185710  0.089820 -0.216418  0.201636  0.113947  \n",
      "a_e2     0.306774  0.407144 -0.201256  0.072433 -0.267282  0.224569  0.093685  \n",
      "a_e3     0.304817  0.380027 -0.135284  0.059819 -0.205825  0.166269  0.182377  \n",
      "a_e4     1.000000  0.408908 -0.082288  0.178326 -0.083995  0.173432  0.291299  \n",
      "a_e5     0.408908  1.000000 -0.134729  0.180185 -0.156057  0.216276  0.116132  \n",
      "a_e6    -0.082288 -0.134729  1.000000 -0.115116  0.632125 -0.321241 -0.221603  \n",
      "a_e7     0.178326  0.180185 -0.115116  1.000000 -0.086149  0.157314  0.169579  \n",
      "a_c6    -0.083995 -0.156057  0.632125 -0.086149  1.000000 -0.427359 -0.198838  \n",
      "a_c2     0.173432  0.216276 -0.321241  0.157314 -0.427359  1.000000  0.244053  \n",
      "a_act11  0.291299  0.116132 -0.221603  0.169579 -0.198838  0.244053  1.000000  \n",
      "\n",
      "[44 rows x 44 columns], 'preoperative_arm_1':               gp1       gp2       gp3       gp4       gp5       gp6       gp7  \\\n",
      "gp1      1.000000  0.390245  0.477369  0.392320  0.417154  0.527328  0.558252   \n",
      "gp2      0.390245  1.000000  0.256881  0.318554  0.297106  0.445314  0.358886   \n",
      "gp3      0.477369  0.256881  1.000000  0.407399  0.343796  0.528564  0.520682   \n",
      "gp4      0.392320  0.318554  0.407399  1.000000  0.288440  0.554992  0.399447   \n",
      "gp5      0.417154  0.297106  0.343796  0.288440  1.000000  0.430990  0.393825   \n",
      "gp6      0.527328  0.445314  0.528564  0.554992  0.430990  1.000000  0.580885   \n",
      "gp7      0.558252  0.358886  0.520682  0.399447  0.393825  0.580885  1.000000   \n",
      "gs1     -0.168052 -0.075937 -0.237141 -0.166983 -0.159058 -0.248402 -0.257955   \n",
      "gs2     -0.137903 -0.056222 -0.087763 -0.155180  0.006896 -0.108140 -0.122353   \n",
      "gs3     -0.145893 -0.024517 -0.144795 -0.116844 -0.077450 -0.160008 -0.187920   \n",
      "gs4     -0.113626 -0.030321 -0.165790 -0.105926 -0.053676 -0.186299 -0.155067   \n",
      "gs5     -0.127744 -0.065327 -0.165997 -0.153847 -0.051849 -0.180556 -0.164406   \n",
      "gs6     -0.088451 -0.128324 -0.107019 -0.144769  0.070175 -0.108237 -0.060681   \n",
      "gs7     -0.351794 -0.185141 -0.239300 -0.268796 -0.194008 -0.224958 -0.288993   \n",
      "ge1      0.402310  0.223243  0.374430  0.307090  0.185955  0.409636  0.391429   \n",
      "ge2     -0.106314 -0.120013 -0.148632 -0.108596 -0.070512 -0.160735 -0.135280   \n",
      "ge3      0.166301  0.074236  0.268204  0.226755  0.171537  0.221731  0.250037   \n",
      "ge4      0.199398  0.102750  0.241446  0.248066  0.110953  0.239886  0.220815   \n",
      "ge5      0.170713  0.068756  0.186829  0.209608  0.108280  0.232471  0.181583   \n",
      "ge6      0.250120  0.085131  0.315019  0.336512  0.129167  0.306095  0.226665   \n",
      "gf1     -0.410741 -0.286001 -0.476964 -0.288367 -0.284176 -0.398662 -0.445090   \n",
      "gf2     -0.386670 -0.236651 -0.440118 -0.214573 -0.277280 -0.297250 -0.386507   \n",
      "gf3     -0.426473 -0.258014 -0.461042 -0.286573 -0.239017 -0.417104 -0.454874   \n",
      "gf4     -0.212844 -0.121320 -0.191717 -0.110459 -0.078533 -0.281420 -0.229587   \n",
      "gf5     -0.318372 -0.250459 -0.253997 -0.337697 -0.157385 -0.292907 -0.253359   \n",
      "gf6     -0.440032 -0.253684 -0.493069 -0.247674 -0.240985 -0.408124 -0.463686   \n",
      "gf7     -0.436437 -0.257277 -0.452393 -0.339034 -0.262511 -0.444440 -0.469928   \n",
      "a_hn1   -0.336287 -0.306062 -0.340272 -0.342881 -0.203796 -0.438599 -0.288152   \n",
      "a_hn2    0.268088  0.125428  0.166159  0.212608  0.178261  0.238421  0.229574   \n",
      "a_hn3    0.194037  0.151450  0.150557  0.225202  0.047584  0.174118  0.191201   \n",
      "a_hn4   -0.198861 -0.117462 -0.165670 -0.163839 -0.132824 -0.201579 -0.158278   \n",
      "a_hn5   -0.354684 -0.311739 -0.358770 -0.383619 -0.184142 -0.418265 -0.308888   \n",
      "a_hn7   -0.238791 -0.236166 -0.244700 -0.308171 -0.112942 -0.366488 -0.221824   \n",
      "a_hn10  -0.189384 -0.110299 -0.132486 -0.137702 -0.159259 -0.210941 -0.172667   \n",
      "a_e1     0.207826  0.134925  0.238576  0.352030  0.069490  0.345594  0.134811   \n",
      "a_e2     0.225551  0.255570  0.312342  0.364245  0.185423  0.412145  0.169717   \n",
      "a_e3     0.195333  0.250947  0.239915  0.282933  0.115463  0.346359  0.219361   \n",
      "a_e4     0.237808  0.154503  0.265928  0.450815  0.060743  0.368266  0.215166   \n",
      "a_e5     0.154865  0.147549  0.117315  0.261012  0.032968  0.282702  0.189748   \n",
      "a_e6    -0.313180 -0.216613 -0.306757 -0.361551 -0.180529 -0.379991 -0.316803   \n",
      "a_e7     0.214540  0.147673  0.213420  0.174034  0.152594  0.226032  0.219934   \n",
      "a_c6    -0.428675 -0.351079 -0.355571 -0.372235 -0.228548 -0.430877 -0.352644   \n",
      "a_c2     0.310816  0.250538  0.253716  0.266904  0.196221  0.356768  0.292386   \n",
      "a_act11  0.240036  0.250849  0.243731  0.448508  0.101885  0.360572  0.266216   \n",
      "\n",
      "              gs1       gs2       gs3  ...      a_e1      a_e2      a_e3  \\\n",
      "gp1     -0.168052 -0.137903 -0.145893  ...  0.207826  0.225551  0.195333   \n",
      "gp2     -0.075937 -0.056222 -0.024517  ...  0.134925  0.255570  0.250947   \n",
      "gp3     -0.237141 -0.087763 -0.144795  ...  0.238576  0.312342  0.239915   \n",
      "gp4     -0.166983 -0.155180 -0.116844  ...  0.352030  0.364245  0.282933   \n",
      "gp5     -0.159058  0.006896 -0.077450  ...  0.069490  0.185423  0.115463   \n",
      "gp6     -0.248402 -0.108140 -0.160008  ...  0.345594  0.412145  0.346359   \n",
      "gp7     -0.257955 -0.122353 -0.187920  ...  0.134811  0.169717  0.219361   \n",
      "gs1      1.000000  0.480219  0.733795  ... -0.156389 -0.185385 -0.177126   \n",
      "gs2      0.480219  1.000000  0.622586  ... -0.037458 -0.060986 -0.082292   \n",
      "gs3      0.733795  0.622586  1.000000  ... -0.119906 -0.137063 -0.121019   \n",
      "gs4      0.484582  0.577145  0.506191  ... -0.070430 -0.069388 -0.077182   \n",
      "gs5      0.470018  0.655276  0.555202  ... -0.092132 -0.094476 -0.099465   \n",
      "gs6      0.341146  0.540361  0.408453  ... -0.111434 -0.135274 -0.067001   \n",
      "gs7      0.299184  0.281758  0.209719  ... -0.110762 -0.111087 -0.117941   \n",
      "ge1     -0.221299 -0.112840 -0.164570  ...  0.134723  0.149076  0.155999   \n",
      "ge2      0.213860  0.244670  0.258025  ... -0.055139 -0.099301 -0.116863   \n",
      "ge3     -0.254779 -0.195434 -0.225259  ...  0.150698  0.136677  0.126834   \n",
      "ge4     -0.147713 -0.124065 -0.087011  ...  0.071070  0.095436  0.107538   \n",
      "ge5     -0.149381 -0.088436 -0.113553  ...  0.141807  0.183078  0.191845   \n",
      "ge6     -0.184298 -0.122809 -0.139311  ...  0.196728  0.218821  0.166571   \n",
      "gf1      0.235536  0.194230  0.196177  ... -0.152878 -0.203479 -0.159847   \n",
      "gf2      0.255460  0.255814  0.226550  ... -0.092570 -0.146591 -0.068172   \n",
      "gf3      0.413777  0.357575  0.362836  ... -0.141978 -0.234202 -0.204196   \n",
      "gf4      0.312194  0.236311  0.263269  ... -0.072278 -0.123413 -0.120452   \n",
      "gf5      0.230997  0.205760  0.124926  ... -0.165180 -0.105440 -0.177776   \n",
      "gf6      0.301350  0.203105  0.240597  ... -0.183929 -0.217529 -0.180664   \n",
      "gf7      0.361876  0.214193  0.286645  ... -0.232112 -0.254460 -0.240778   \n",
      "a_hn1    0.234744  0.145525  0.187217  ... -0.569442 -0.545346 -0.438505   \n",
      "a_hn2   -0.148576 -0.040371 -0.103992  ...  0.066061  0.176885  0.153870   \n",
      "a_hn3   -0.127346  0.061857 -0.027333  ...  0.199075  0.193060  0.198469   \n",
      "a_hn4    0.205669  0.066609  0.120727  ... -0.189007 -0.150285 -0.110065   \n",
      "a_hn5    0.200587  0.171109  0.169067  ... -0.525605 -0.507021 -0.370028   \n",
      "a_hn7    0.316365  0.174012  0.266608  ... -0.591027 -0.494682 -0.410335   \n",
      "a_hn10   0.307235  0.277151  0.287638  ... -0.072298 -0.165473 -0.144302   \n",
      "a_e1    -0.156389 -0.037458 -0.119906  ...  1.000000  0.606080  0.445846   \n",
      "a_e2    -0.185385 -0.060986 -0.137063  ...  0.606080  1.000000  0.687727   \n",
      "a_e3    -0.177126 -0.082292 -0.121019  ...  0.445846  0.687727  1.000000   \n",
      "a_e4    -0.209369 -0.053544 -0.118023  ...  0.507568  0.456013  0.404559   \n",
      "a_e5    -0.167493 -0.020196 -0.148340  ...  0.407672  0.417834  0.413501   \n",
      "a_e6     0.293754  0.256553  0.261276  ... -0.498982 -0.484047 -0.383428   \n",
      "a_e7    -0.123320 -0.056974 -0.054999  ...  0.099622  0.156278  0.147463   \n",
      "a_c6     0.206436  0.141657  0.132657  ... -0.443201 -0.356086 -0.277368   \n",
      "a_c2    -0.101941 -0.062279 -0.043043  ...  0.358266  0.303176  0.166887   \n",
      "a_act11 -0.116727 -0.009736 -0.061663  ...  0.249505  0.250601  0.214356   \n",
      "\n",
      "             a_e4      a_e5      a_e6      a_e7      a_c6      a_c2   a_act11  \n",
      "gp1      0.237808  0.154865 -0.313180  0.214540 -0.428675  0.310816  0.240036  \n",
      "gp2      0.154503  0.147549 -0.216613  0.147673 -0.351079  0.250538  0.250849  \n",
      "gp3      0.265928  0.117315 -0.306757  0.213420 -0.355571  0.253716  0.243731  \n",
      "gp4      0.450815  0.261012 -0.361551  0.174034 -0.372235  0.266904  0.448508  \n",
      "gp5      0.060743  0.032968 -0.180529  0.152594 -0.228548  0.196221  0.101885  \n",
      "gp6      0.368266  0.282702 -0.379991  0.226032 -0.430877  0.356768  0.360572  \n",
      "gp7      0.215166  0.189748 -0.316803  0.219934 -0.352644  0.292386  0.266216  \n",
      "gs1     -0.209369 -0.167493  0.293754 -0.123320  0.206436 -0.101941 -0.116727  \n",
      "gs2     -0.053544 -0.020196  0.256553 -0.056974  0.141657 -0.062279 -0.009736  \n",
      "gs3     -0.118023 -0.148340  0.261276 -0.054999  0.132657 -0.043043 -0.061663  \n",
      "gs4     -0.066434 -0.066432  0.279826 -0.072566  0.221803 -0.069193  0.007562  \n",
      "gs5     -0.101534 -0.020401  0.323500 -0.039814  0.215296 -0.060671 -0.022529  \n",
      "gs6     -0.107081 -0.093028  0.272028 -0.095870  0.245602 -0.086408 -0.018102  \n",
      "gs7     -0.147036 -0.054891  0.253191 -0.208151  0.359798 -0.201282 -0.060794  \n",
      "ge1      0.207452  0.046519 -0.213677  0.143364 -0.287146  0.148437  0.238861  \n",
      "ge2     -0.036292  0.007930  0.224964 -0.108881  0.130227 -0.098071 -0.060220  \n",
      "ge3      0.122274  0.098772 -0.177830  0.095807 -0.217659  0.173991  0.164185  \n",
      "ge4      0.100045  0.054258 -0.211513  0.044362 -0.125672  0.082705  0.230902  \n",
      "ge5      0.103617  0.092239 -0.165761  0.073801 -0.174324  0.070010  0.195079  \n",
      "ge6      0.202420  0.127682 -0.223406  0.126192 -0.224351  0.154285  0.185805  \n",
      "gf1     -0.139434 -0.102370  0.346408 -0.133696  0.378487 -0.238229 -0.128347  \n",
      "gf2     -0.096789 -0.013721  0.334832 -0.143884  0.363513 -0.178489 -0.139180  \n",
      "gf3     -0.171469 -0.080863  0.505020 -0.177388  0.351970 -0.197450 -0.168492  \n",
      "gf4     -0.075659 -0.056290  0.286273 -0.005321  0.234487 -0.156048 -0.053113  \n",
      "gf5     -0.197251 -0.056623  0.240047 -0.203751  0.343944 -0.158130 -0.152817  \n",
      "gf6     -0.166904 -0.066218  0.482826 -0.155059  0.436049 -0.248242 -0.129528  \n",
      "gf7     -0.236152 -0.108517  0.479975 -0.150287  0.414726 -0.242589 -0.258172  \n",
      "a_hn1   -0.373097 -0.257965  0.689826 -0.123159  0.687558 -0.423544 -0.219291  \n",
      "a_hn2    0.089582  0.203672 -0.163415  0.154694 -0.214000  0.089806  0.200577  \n",
      "a_hn3    0.215869  0.272435 -0.067965  0.236638 -0.100722  0.048393  0.242761  \n",
      "a_hn4   -0.128232 -0.158914  0.325654 -0.258070  0.344952 -0.224286 -0.091151  \n",
      "a_hn5   -0.339121 -0.269029  0.645419 -0.123935  0.692605 -0.472081 -0.252483  \n",
      "a_hn7   -0.452121 -0.377389  0.550806 -0.110135  0.489417 -0.219560 -0.150342  \n",
      "a_hn10  -0.080605 -0.167135  0.334231 -0.090354  0.286286 -0.110884 -0.047686  \n",
      "a_e1     0.507568  0.407672 -0.498982  0.099622 -0.443201  0.358266  0.249505  \n",
      "a_e2     0.456013  0.417834 -0.484047  0.156278 -0.356086  0.303176  0.250601  \n",
      "a_e3     0.404559  0.413501 -0.383428  0.147463 -0.277368  0.166887  0.214356  \n",
      "a_e4     1.000000  0.400779 -0.286273  0.101699 -0.264697  0.214912  0.361097  \n",
      "a_e5     0.400779  1.000000 -0.202980  0.233812 -0.163300  0.132820  0.211242  \n",
      "a_e6    -0.286273 -0.202980  1.000000 -0.089432  0.627916 -0.387819 -0.161054  \n",
      "a_e7     0.101699  0.233812 -0.089432  1.000000 -0.151270  0.149192  0.121283  \n",
      "a_c6    -0.264697 -0.163300  0.627916 -0.151270  1.000000 -0.474132 -0.211360  \n",
      "a_c2     0.214912  0.132820 -0.387819  0.149192 -0.474132  1.000000  0.228190  \n",
      "a_act11  0.361097  0.211242 -0.161054  0.121283 -0.211360  0.228190  1.000000  \n",
      "\n",
      "[44 rows x 44 columns], '1_year_postop_arm_1':               gp1       gp2       gp3       gp4       gp5       gp6       gp7  \\\n",
      "gp1      1.000000  0.451484  0.523082  0.361110  0.328933  0.562696  0.402067   \n",
      "gp2      0.451484  1.000000  0.397406  0.386639  0.190062  0.510797  0.405272   \n",
      "gp3      0.523082  0.397406  1.000000  0.331835  0.312961  0.485761  0.388904   \n",
      "gp4      0.361110  0.386639  0.331835  1.000000  0.368065  0.530769  0.434959   \n",
      "gp5      0.328933  0.190062  0.312961  0.368065  1.000000  0.421873  0.297520   \n",
      "gp6      0.562696  0.510797  0.485761  0.530769  0.421873  1.000000  0.493852   \n",
      "gp7      0.402067  0.405272  0.388904  0.434959  0.297520  0.493852  1.000000   \n",
      "gs1     -0.121842 -0.222606 -0.185026 -0.169785 -0.060826 -0.264991 -0.213858   \n",
      "gs2      0.017572  0.028597 -0.073496 -0.081717 -0.041132 -0.038214 -0.055029   \n",
      "gs3     -0.069334 -0.108896 -0.141677 -0.134844 -0.050707 -0.194645 -0.120765   \n",
      "gs4     -0.062651 -0.066745 -0.068269 -0.134780 -0.141445 -0.102106 -0.114565   \n",
      "gs5     -0.089075 -0.087059 -0.132015 -0.152834 -0.149565 -0.096521 -0.120368   \n",
      "gs6     -0.050697 -0.027369 -0.161009 -0.042550 -0.040100 -0.002088 -0.081188   \n",
      "gs7     -0.353778 -0.176895 -0.308070 -0.333741 -0.235785 -0.357211 -0.262911   \n",
      "ge1      0.440091  0.398588  0.388205  0.353597  0.206325  0.514739  0.242657   \n",
      "ge2     -0.188417 -0.156693 -0.294918 -0.257975 -0.160223 -0.319397 -0.264078   \n",
      "ge3      0.319212  0.310355  0.445206  0.370792  0.206225  0.493679  0.272437   \n",
      "ge4      0.340238  0.381110  0.325670  0.415145  0.192646  0.465362  0.271760   \n",
      "ge5      0.223583  0.109204  0.263626  0.293424  0.233668  0.370042  0.170017   \n",
      "ge6      0.358747  0.337391  0.413316  0.450401  0.233727  0.454000  0.278640   \n",
      "gf1     -0.534316 -0.385397 -0.580970 -0.341963 -0.305616 -0.472390 -0.487383   \n",
      "gf2     -0.472027 -0.365094 -0.538259 -0.236895 -0.245299 -0.436232 -0.386114   \n",
      "gf3     -0.474479 -0.387043 -0.531412 -0.350096 -0.227422 -0.529060 -0.426012   \n",
      "gf4     -0.269347 -0.175898 -0.316912 -0.217462 -0.143916 -0.304237 -0.187325   \n",
      "gf5     -0.172834 -0.272963 -0.171851 -0.336849 -0.074807 -0.224683 -0.208303   \n",
      "gf6     -0.462354 -0.418668 -0.508910 -0.358281 -0.226135 -0.510385 -0.401068   \n",
      "gf7     -0.412164 -0.379986 -0.516743 -0.504269 -0.337066 -0.581771 -0.382592   \n",
      "a_hn1   -0.326243 -0.298264 -0.313976 -0.378001 -0.287128 -0.433344 -0.348668   \n",
      "a_hn2    0.250735  0.149050  0.212539  0.127322  0.027653  0.179300  0.088498   \n",
      "a_hn3    0.356327  0.180724  0.273540  0.185948  0.133409  0.262969  0.199727   \n",
      "a_hn4   -0.202090 -0.175450 -0.229095 -0.155424 -0.025986 -0.190131 -0.150836   \n",
      "a_hn5   -0.334653 -0.285343 -0.272008 -0.324711 -0.308876 -0.326662 -0.277455   \n",
      "a_hn7   -0.210516 -0.134874 -0.091267 -0.235112 -0.134366 -0.189953 -0.325686   \n",
      "a_hn10  -0.232440 -0.230377 -0.251013 -0.263899 -0.199317 -0.240107 -0.276278   \n",
      "a_e1     0.182295  0.077009  0.003768  0.172818  0.036267  0.161297  0.165443   \n",
      "a_e2     0.153939  0.173249  0.044297  0.148064  0.022198  0.090891  0.250205   \n",
      "a_e3     0.142774  0.125676  0.058416  0.120850  0.041424  0.117089  0.180895   \n",
      "a_e4     0.203458  0.270449  0.097582  0.277249  0.000905  0.274086  0.228491   \n",
      "a_e5     0.135624  0.132861  0.075246  0.188685  0.089369  0.196124  0.173848   \n",
      "a_e6    -0.333363 -0.310922 -0.349827 -0.360923 -0.232468 -0.431118 -0.326451   \n",
      "a_e7     0.185712  0.051395  0.084686  0.103337  0.064589  0.079035  0.125797   \n",
      "a_c6    -0.414626 -0.243055 -0.380070 -0.181619 -0.199476 -0.387352 -0.240879   \n",
      "a_c2     0.196214  0.165331  0.224250  0.214756  0.149588  0.334010  0.311472   \n",
      "a_act11  0.165443  0.248370  0.258967  0.415201  0.179658  0.290026  0.256732   \n",
      "\n",
      "              gs1       gs2       gs3  ...      a_e1      a_e2      a_e3  \\\n",
      "gp1     -0.121842  0.017572 -0.069334  ...  0.182295  0.153939  0.142774   \n",
      "gp2     -0.222606  0.028597 -0.108896  ...  0.077009  0.173249  0.125676   \n",
      "gp3     -0.185026 -0.073496 -0.141677  ...  0.003768  0.044297  0.058416   \n",
      "gp4     -0.169785 -0.081717 -0.134844  ...  0.172818  0.148064  0.120850   \n",
      "gp5     -0.060826 -0.041132 -0.050707  ...  0.036267  0.022198  0.041424   \n",
      "gp6     -0.264991 -0.038214 -0.194645  ...  0.161297  0.090891  0.117089   \n",
      "gp7     -0.213858 -0.055029 -0.120765  ...  0.165443  0.250205  0.180895   \n",
      "gs1      1.000000  0.489016  0.738090  ... -0.017053  0.030242 -0.043849   \n",
      "gs2      0.489016  1.000000  0.587612  ... -0.033901  0.026313 -0.066677   \n",
      "gs3      0.738090  0.587612  1.000000  ... -0.078209 -0.057999 -0.106376   \n",
      "gs4      0.424698  0.628680  0.487834  ... -0.139129 -0.056979 -0.136093   \n",
      "gs5      0.481251  0.755979  0.512235  ... -0.007841 -0.010070 -0.027818   \n",
      "gs6      0.404431  0.648990  0.462185  ...  0.040371  0.026423 -0.012751   \n",
      "gs7      0.362442  0.216781  0.247593  ... -0.122582 -0.049828 -0.013944   \n",
      "ge1     -0.315688 -0.230247 -0.238464  ...  0.235189  0.196723  0.196508   \n",
      "ge2      0.254171  0.318184  0.261426  ... -0.092325 -0.063333 -0.068475   \n",
      "ge3     -0.219628 -0.159874 -0.201967  ...  0.187042  0.228223  0.120454   \n",
      "ge4     -0.289148 -0.170714 -0.229076  ...  0.142512  0.107837  0.108851   \n",
      "ge5     -0.158442 -0.185449 -0.205066  ...  0.077668  0.077748  0.129947   \n",
      "ge6     -0.283543 -0.155734 -0.277126  ...  0.083083  0.174722  0.109579   \n",
      "gf1      0.302609  0.077255  0.202176  ... -0.026025 -0.044012 -0.052565   \n",
      "gf2      0.331027  0.202613  0.221961  ...  0.015845 -0.062726 -0.045053   \n",
      "gf3      0.475052  0.340530  0.405732  ... -0.079984 -0.132566 -0.113769   \n",
      "gf4      0.378962  0.389458  0.370604  ... -0.112502 -0.145531 -0.123548   \n",
      "gf5      0.195252  0.228592  0.187224  ...  0.071010 -0.025152 -0.016556   \n",
      "gf6      0.400832  0.273091  0.314873  ... -0.097150 -0.159260 -0.138511   \n",
      "gf7      0.391467  0.301052  0.305236  ... -0.189436 -0.202223 -0.204535   \n",
      "a_hn1    0.226392  0.141545  0.140956  ... -0.354641 -0.341293 -0.293116   \n",
      "a_hn2   -0.084616 -0.080224 -0.050821  ...  0.293545  0.223208  0.137857   \n",
      "a_hn3   -0.119204 -0.070820 -0.057264  ...  0.110569  0.042908  0.022371   \n",
      "a_hn4    0.290670  0.254875  0.231462  ... -0.077900 -0.081083 -0.064694   \n",
      "a_hn5    0.142417  0.133949  0.070897  ... -0.221543 -0.216830 -0.221161   \n",
      "a_hn7    0.209104  0.241090  0.205521  ... -0.545480 -0.406565 -0.351699   \n",
      "a_hn10   0.446502  0.387402  0.443158  ... -0.052970 -0.066413 -0.059244   \n",
      "a_e1    -0.017053 -0.033901 -0.078209  ...  1.000000  0.604018  0.483891   \n",
      "a_e2     0.030242  0.026313 -0.057999  ...  0.604018  1.000000  0.690269   \n",
      "a_e3    -0.043849 -0.066677 -0.106376  ...  0.483891  0.690269  1.000000   \n",
      "a_e4    -0.041107 -0.049422 -0.080083  ...  0.355039  0.384655  0.355053   \n",
      "a_e5     0.034160 -0.084400  0.046659  ...  0.430348  0.360304  0.321062   \n",
      "a_e6     0.321673  0.218184  0.241073  ... -0.253449 -0.280387 -0.232427   \n",
      "a_e7    -0.055836 -0.087019 -0.015480  ...  0.177555  0.132564  0.064064   \n",
      "a_c6     0.256955  0.198379  0.121054  ... -0.075633 -0.089010 -0.038941   \n",
      "a_c2    -0.054648  0.066509 -0.066633  ...  0.231107  0.278208  0.226174   \n",
      "a_act11 -0.000114  0.053164 -0.027760  ...  0.081184  0.085726  0.123698   \n",
      "\n",
      "             a_e4      a_e5      a_e6      a_e7      a_c6      a_c2   a_act11  \n",
      "gp1      0.203458  0.135624 -0.333363  0.185712 -0.414626  0.196214  0.165443  \n",
      "gp2      0.270449  0.132861 -0.310922  0.051395 -0.243055  0.165331  0.248370  \n",
      "gp3      0.097582  0.075246 -0.349827  0.084686 -0.380070  0.224250  0.258967  \n",
      "gp4      0.277249  0.188685 -0.360923  0.103337 -0.181619  0.214756  0.415201  \n",
      "gp5      0.000905  0.089369 -0.232468  0.064589 -0.199476  0.149588  0.179658  \n",
      "gp6      0.274086  0.196124 -0.431118  0.079035 -0.387352  0.334010  0.290026  \n",
      "gp7      0.228491  0.173848 -0.326451  0.125797 -0.240879  0.311472  0.256732  \n",
      "gs1     -0.041107  0.034160  0.321673 -0.055836  0.256955 -0.054648 -0.000114  \n",
      "gs2     -0.049422 -0.084400  0.218184 -0.087019  0.198379  0.066509  0.053164  \n",
      "gs3     -0.080083  0.046659  0.241073 -0.015480  0.121054 -0.066633 -0.027760  \n",
      "gs4     -0.124519 -0.047386  0.330150 -0.066203  0.190293 -0.041597 -0.020402  \n",
      "gs5     -0.082722 -0.032264  0.259038 -0.097570  0.217624 -0.031438  0.035869  \n",
      "gs6     -0.007699 -0.028100  0.208216 -0.013281  0.246752  0.038823 -0.025322  \n",
      "gs7     -0.130965 -0.131965  0.328962 -0.033537  0.367477 -0.109229 -0.113395  \n",
      "ge1      0.298133  0.263700 -0.321654  0.094676 -0.192286  0.245376  0.137032  \n",
      "ge2     -0.127275 -0.111902  0.343100 -0.150571  0.309932 -0.246553 -0.211274  \n",
      "ge3      0.226136  0.286322 -0.368538  0.078671 -0.309187  0.311030  0.227208  \n",
      "ge4      0.227618  0.215858 -0.241376  0.075146 -0.197169  0.151612  0.171771  \n",
      "ge5      0.125625  0.172312 -0.142223  0.013892 -0.154581  0.131665  0.157102  \n",
      "ge6      0.237692  0.158637 -0.285524 -0.024676 -0.210838  0.162456  0.148712  \n",
      "gf1     -0.170854 -0.147325  0.448342 -0.103862  0.407057 -0.251534 -0.173649  \n",
      "gf2     -0.104266 -0.122435  0.478503 -0.115050  0.475202 -0.199191 -0.112299  \n",
      "gf3     -0.240264 -0.128167  0.546111 -0.108612  0.498445 -0.222642 -0.173997  \n",
      "gf4     -0.074350 -0.118117  0.387261 -0.062398  0.377413 -0.083521 -0.063910  \n",
      "gf5     -0.060621 -0.022851  0.254117 -0.115816  0.199279  0.024094 -0.185821  \n",
      "gf6     -0.209696 -0.216642  0.559636 -0.148458  0.457062 -0.180914 -0.149383  \n",
      "gf7     -0.237769 -0.242844  0.565200 -0.120399  0.485469 -0.238839 -0.224073  \n",
      "a_hn1   -0.231495 -0.248683  0.708208 -0.087171  0.517238 -0.340450 -0.219996  \n",
      "a_hn2    0.204722  0.245055 -0.147307  0.068501 -0.112325  0.121500  0.013121  \n",
      "a_hn3    0.265039  0.162233 -0.204706  0.182957 -0.178761  0.102316  0.150865  \n",
      "a_hn4   -0.069279 -0.064817  0.287874 -0.139240  0.317474 -0.155154  0.052518  \n",
      "a_hn5   -0.212302 -0.071662  0.564571  0.027462  0.523327 -0.329878 -0.256894  \n",
      "a_hn7   -0.300681 -0.335684  0.387924 -0.246825  0.287380 -0.247595 -0.114326  \n",
      "a_hn10  -0.052845 -0.064749  0.384742 -0.153405  0.294832 -0.158880 -0.055470  \n",
      "a_e1     0.355039  0.430348 -0.253449  0.177555 -0.075633  0.231107  0.081184  \n",
      "a_e2     0.384655  0.360304 -0.280387  0.132564 -0.089010  0.278208  0.085726  \n",
      "a_e3     0.355053  0.321062 -0.232427  0.064064 -0.038941  0.226174  0.123698  \n",
      "a_e4     1.000000  0.427329 -0.223056  0.125791 -0.125994  0.246008  0.185197  \n",
      "a_e5     0.427329  1.000000 -0.160863  0.311894 -0.082228  0.164999  0.000382  \n",
      "a_e6    -0.223056 -0.160863  1.000000 -0.135653  0.536754 -0.410094 -0.172465  \n",
      "a_e7     0.125791  0.311894 -0.135653  1.000000 -0.094682  0.081422  0.042855  \n",
      "a_c6    -0.125994 -0.082228  0.536754 -0.094682  1.000000 -0.338516 -0.138931  \n",
      "a_c2     0.246008  0.164999 -0.410094  0.081422 -0.338516  1.000000  0.203062  \n",
      "a_act11  0.185197  0.000382 -0.172465  0.042855 -0.138931  0.203062  1.000000  \n",
      "\n",
      "[44 rows x 44 columns], '3_months_postop_arm_1':               gp1       gp2       gp3       gp4       gp5       gp6       gp7  \\\n",
      "gp1      1.000000  0.398865  0.493274  0.357931  0.481835  0.540341  0.544453   \n",
      "gp2      0.398865  1.000000  0.220359  0.370086  0.460543  0.446980  0.218279   \n",
      "gp3      0.493274  0.220359  1.000000  0.378607  0.270487  0.451759  0.420451   \n",
      "gp4      0.357931  0.370086  0.378607  1.000000  0.363733  0.430688  0.289610   \n",
      "gp5      0.481835  0.460543  0.270487  0.363733  1.000000  0.691238  0.388229   \n",
      "gp6      0.540341  0.446980  0.451759  0.430688  0.691238  1.000000  0.578578   \n",
      "gp7      0.544453  0.218279  0.420451  0.289610  0.388229  0.578578  1.000000   \n",
      "gs1     -0.130319 -0.057572 -0.291757 -0.041880 -0.153819 -0.154843 -0.151347   \n",
      "gs2      0.062553  0.000581  0.066142  0.007568  0.003123  0.026646 -0.046630   \n",
      "gs3     -0.013102  0.038071 -0.091094 -0.019589 -0.072072 -0.110958 -0.098921   \n",
      "gs4     -0.142464 -0.025266 -0.152808 -0.194622 -0.125264 -0.203304 -0.212430   \n",
      "gs5     -0.073644 -0.030266 -0.022147 -0.146429 -0.118008 -0.144795 -0.179915   \n",
      "gs6      0.076830  0.008851  0.084249 -0.039750  0.021551  0.003597  0.002477   \n",
      "gs7     -0.302513  0.017800 -0.295108 -0.118152 -0.179347 -0.374784 -0.358371   \n",
      "ge1      0.266846  0.187635  0.362333  0.239804  0.214643  0.432261  0.282463   \n",
      "ge2     -0.168520 -0.107837 -0.178635 -0.162670 -0.208208 -0.262513 -0.210392   \n",
      "ge3      0.255013  0.227566  0.324430  0.295008  0.341006  0.455529  0.406945   \n",
      "ge4      0.148794  0.210562  0.317003  0.305736  0.179871  0.355062  0.225776   \n",
      "ge5      0.146722  0.163333  0.178226  0.139299  0.197361  0.371018  0.226144   \n",
      "ge6      0.134822  0.131100  0.255192  0.289608  0.158414  0.345240  0.279870   \n",
      "gf1     -0.527084 -0.230957 -0.519147 -0.363143 -0.337311 -0.453538 -0.572325   \n",
      "gf2     -0.376956 -0.211334 -0.498473 -0.382342 -0.351727 -0.436759 -0.452414   \n",
      "gf3     -0.514948 -0.250906 -0.500822 -0.387226 -0.366158 -0.522614 -0.481842   \n",
      "gf4     -0.152919 -0.031511 -0.174911 -0.160565 -0.103917 -0.273583 -0.265021   \n",
      "gf5     -0.342905 -0.111587 -0.264254 -0.344475 -0.144177 -0.209664 -0.163425   \n",
      "gf6     -0.531577 -0.183709 -0.550273 -0.313499 -0.315014 -0.503001 -0.432727   \n",
      "gf7     -0.485531 -0.238164 -0.498209 -0.411882 -0.433277 -0.582412 -0.480223   \n",
      "a_hn1   -0.330195 -0.381849 -0.257273 -0.313787 -0.284531 -0.357695 -0.229630   \n",
      "a_hn2    0.284260  0.158905  0.248151  0.080318  0.153802  0.172477  0.222754   \n",
      "a_hn3    0.396716  0.340874  0.250632  0.133560  0.267164  0.258690  0.308640   \n",
      "a_hn4   -0.390879 -0.190066 -0.338422 -0.213501 -0.255813 -0.406656 -0.247717   \n",
      "a_hn5   -0.337261 -0.351093 -0.233854 -0.308431 -0.334976 -0.423812 -0.144607   \n",
      "a_hn7   -0.334384 -0.175482 -0.185492 -0.164233 -0.292475 -0.308090 -0.223482   \n",
      "a_hn10  -0.298206 -0.247768 -0.202182 -0.171597 -0.272959 -0.319556 -0.255760   \n",
      "a_e1     0.227632  0.115375  0.179407  0.149831  0.145566  0.239191  0.224598   \n",
      "a_e2     0.198568  0.188305  0.089721  0.228055  0.238973  0.328054  0.198212   \n",
      "a_e3     0.132670  0.156806 -0.047733  0.229199  0.152691  0.214528  0.100759   \n",
      "a_e4     0.284196  0.279343  0.200200  0.326335  0.246163  0.311046  0.246310   \n",
      "a_e5     0.254407  0.293114  0.202478  0.229758  0.226169  0.245571  0.240268   \n",
      "a_e6    -0.424651 -0.322336 -0.283331 -0.245650 -0.300179 -0.387375 -0.293230   \n",
      "a_e7     0.156863  0.012465  0.142732 -0.105722 -0.042073  0.024727  0.118384   \n",
      "a_c6    -0.444637 -0.265572 -0.324416 -0.252032 -0.313637 -0.456115 -0.233548   \n",
      "a_c2     0.306561  0.296034  0.220623  0.297953  0.394126  0.382576  0.307134   \n",
      "a_act11  0.188834  0.362742  0.153289  0.476988  0.309232  0.260604  0.132476   \n",
      "\n",
      "              gs1       gs2       gs3  ...      a_e1      a_e2      a_e3  \\\n",
      "gp1     -0.130319  0.062553 -0.013102  ...  0.227632  0.198568  0.132670   \n",
      "gp2     -0.057572  0.000581  0.038071  ...  0.115375  0.188305  0.156806   \n",
      "gp3     -0.291757  0.066142 -0.091094  ...  0.179407  0.089721 -0.047733   \n",
      "gp4     -0.041880  0.007568 -0.019589  ...  0.149831  0.228055  0.229199   \n",
      "gp5     -0.153819  0.003123 -0.072072  ...  0.145566  0.238973  0.152691   \n",
      "gp6     -0.154843  0.026646 -0.110958  ...  0.239191  0.328054  0.214528   \n",
      "gp7     -0.151347 -0.046630 -0.098921  ...  0.224598  0.198212  0.100759   \n",
      "gs1      1.000000  0.448379  0.639841  ... -0.047799 -0.038274  0.007881   \n",
      "gs2      0.448379  1.000000  0.598924  ... -0.034257 -0.053300  0.005783   \n",
      "gs3      0.639841  0.598924  1.000000  ... -0.109891 -0.071083 -0.094237   \n",
      "gs4      0.304074  0.474837  0.474342  ... -0.109183  0.024078  0.009903   \n",
      "gs5      0.334845  0.535881  0.507884  ... -0.060865 -0.023157 -0.031198   \n",
      "gs6      0.214867  0.407854  0.417214  ...  0.088958 -0.136070 -0.008575   \n",
      "gs7      0.130080 -0.023058  0.103369  ... -0.231091 -0.129461 -0.077782   \n",
      "ge1     -0.179084 -0.087063 -0.216743  ...  0.365839  0.257412  0.113952   \n",
      "ge2      0.088150  0.137540  0.078907  ... -0.045803 -0.133252 -0.010860   \n",
      "ge3     -0.198050 -0.059456 -0.127564  ...  0.199971  0.236199  0.086498   \n",
      "ge4     -0.133754 -0.190757 -0.227364  ...  0.179840  0.283450  0.181238   \n",
      "ge5     -0.001022  0.011226 -0.116325  ... -0.018260  0.098346  0.010327   \n",
      "ge6     -0.154366 -0.088033 -0.195863  ...  0.134831  0.209139  0.130004   \n",
      "gf1      0.143303  0.037974  0.111221  ... -0.169684 -0.132658 -0.099702   \n",
      "gf2      0.251902  0.067572  0.174851  ... -0.179934 -0.188831 -0.135186   \n",
      "gf3      0.247691  0.124518  0.193762  ... -0.220761 -0.240937 -0.049407   \n",
      "gf4      0.229573  0.142185  0.268094  ... -0.017390 -0.045293 -0.027660   \n",
      "gf5      0.247777  0.117799  0.094377  ... -0.079886 -0.121828 -0.067281   \n",
      "gf6      0.279199  0.105619  0.262448  ... -0.185704 -0.228755 -0.175857   \n",
      "gf7      0.197470  0.061207  0.125892  ... -0.192207 -0.211076 -0.099890   \n",
      "a_hn1    0.187396  0.204677  0.167510  ... -0.375166 -0.414158 -0.296305   \n",
      "a_hn2   -0.119764 -0.007823 -0.058238  ...  0.183435  0.081469 -0.105007   \n",
      "a_hn3   -0.150725 -0.156883 -0.173097  ...  0.199153  0.160765  0.046802   \n",
      "a_hn4    0.154327  0.040287  0.067524  ... -0.199848 -0.106454 -0.088171   \n",
      "a_hn5    0.195179  0.173511  0.106976  ... -0.212919 -0.215523 -0.113918   \n",
      "a_hn7    0.167876  0.137909  0.067008  ... -0.405775 -0.415439 -0.299848   \n",
      "a_hn10   0.330630  0.279574  0.309628  ... -0.083749 -0.116383 -0.172756   \n",
      "a_e1    -0.047799 -0.034257 -0.109891  ...  1.000000  0.426214  0.255081   \n",
      "a_e2    -0.038274 -0.053300 -0.071083  ...  0.426214  1.000000  0.671374   \n",
      "a_e3     0.007881  0.005783 -0.094237  ...  0.255081  0.671374  1.000000   \n",
      "a_e4    -0.031519 -0.054557 -0.019784  ...  0.105144  0.291097  0.208832   \n",
      "a_e5    -0.018270 -0.063398 -0.079130  ...  0.418756  0.317025  0.301799   \n",
      "a_e6     0.290847  0.185422  0.185435  ... -0.260057 -0.363457 -0.233921   \n",
      "a_e7     0.035035  0.057668  0.117240  ...  0.115540  0.075322  0.035485   \n",
      "a_c6     0.280406  0.143191  0.163801  ... -0.265317 -0.328560 -0.310887   \n",
      "a_c2     0.104420  0.036944 -0.005734  ...  0.162128  0.214489  0.195660   \n",
      "a_act11  0.041033 -0.026688 -0.029976  ...  0.056057  0.121817  0.137075   \n",
      "\n",
      "             a_e4      a_e5      a_e6      a_e7      a_c6      a_c2   a_act11  \n",
      "gp1      0.284196  0.254407 -0.424651  0.156863 -0.444637  0.306561  0.188834  \n",
      "gp2      0.279343  0.293114 -0.322336  0.012465 -0.265572  0.296034  0.362742  \n",
      "gp3      0.200200  0.202478 -0.283331  0.142732 -0.324416  0.220623  0.153289  \n",
      "gp4      0.326335  0.229758 -0.245650 -0.105722 -0.252032  0.297953  0.476988  \n",
      "gp5      0.246163  0.226169 -0.300179 -0.042073 -0.313637  0.394126  0.309232  \n",
      "gp6      0.311046  0.245571 -0.387375  0.024727 -0.456115  0.382576  0.260604  \n",
      "gp7      0.246310  0.240268 -0.293230  0.118384 -0.233548  0.307134  0.132476  \n",
      "gs1     -0.031519 -0.018270  0.290847  0.035035  0.280406  0.104420  0.041033  \n",
      "gs2     -0.054557 -0.063398  0.185422  0.057668  0.143191  0.036944 -0.026688  \n",
      "gs3     -0.019784 -0.079130  0.185435  0.117240  0.163801 -0.005734 -0.029976  \n",
      "gs4     -0.085449 -0.117781  0.195706  0.061743  0.208343 -0.072745 -0.029101  \n",
      "gs5     -0.171058 -0.182707  0.148170  0.053853  0.124232 -0.032722 -0.096107  \n",
      "gs6     -0.040071 -0.082481  0.117538  0.117017  0.018252 -0.063012 -0.039116  \n",
      "gs7     -0.318316 -0.128198  0.376872 -0.038988  0.340029 -0.310510 -0.144899  \n",
      "ge1      0.054097  0.247025 -0.271501  0.052611 -0.239967  0.089901  0.155067  \n",
      "ge2     -0.225167 -0.122742  0.298732  0.041543  0.420108 -0.107410 -0.166005  \n",
      "ge3      0.312893  0.064438 -0.208813  0.006265 -0.172976  0.224211  0.246588  \n",
      "ge4      0.196781  0.140744 -0.290054  0.031283 -0.218484  0.241312  0.265350  \n",
      "ge5      0.091784  0.048134 -0.179531 -0.029123 -0.105671  0.123683  0.197322  \n",
      "ge6      0.207239  0.081960 -0.255797  0.001651 -0.154521  0.225852  0.195822  \n",
      "gf1     -0.209681 -0.083618  0.380733 -0.089719  0.420530 -0.271437 -0.155308  \n",
      "gf2     -0.183716 -0.137731  0.374216 -0.104240  0.443862 -0.210765 -0.204442  \n",
      "gf3     -0.144188 -0.167910  0.542929 -0.086191  0.477892 -0.236528 -0.200986  \n",
      "gf4     -0.109076  0.007746  0.192620  0.117799  0.231472 -0.028668 -0.087307  \n",
      "gf5     -0.156264 -0.051079  0.148487  0.008462  0.288398 -0.076327 -0.035505  \n",
      "gf6     -0.121014 -0.193331  0.478814 -0.175414  0.521313 -0.204686 -0.151424  \n",
      "gf7     -0.166225 -0.234169  0.482235 -0.024402  0.455585 -0.303573 -0.213195  \n",
      "a_hn1   -0.214662 -0.363915  0.571281 -0.092331  0.672931 -0.408369 -0.184565  \n",
      "a_hn2    0.133269  0.152249 -0.234752  0.179141 -0.201012  0.199155  0.099453  \n",
      "a_hn3    0.249445  0.252250 -0.273835  0.118976 -0.219763  0.108628  0.303188  \n",
      "a_hn4   -0.231275 -0.237974  0.320621 -0.144324  0.369536 -0.261232 -0.197158  \n",
      "a_hn5   -0.284617 -0.195397  0.491301 -0.078467  0.646739 -0.381304 -0.228695  \n",
      "a_hn7   -0.206781 -0.431722  0.503064 -0.076108  0.494882 -0.234179 -0.043997  \n",
      "a_hn10  -0.234621 -0.247025  0.301108  0.040642  0.258611 -0.178057 -0.159148  \n",
      "a_e1     0.105144  0.418756 -0.260057  0.115540 -0.265317  0.162128  0.056057  \n",
      "a_e2     0.291097  0.317025 -0.363457  0.075322 -0.328560  0.214489  0.121817  \n",
      "a_e3     0.208832  0.301799 -0.233921  0.035485 -0.310887  0.195660  0.137075  \n",
      "a_e4     1.000000  0.381829 -0.255688  0.151089 -0.259348  0.249087  0.317064  \n",
      "a_e5     0.381829  1.000000 -0.363625  0.104500 -0.243506  0.269847  0.156446  \n",
      "a_e6    -0.255688 -0.363625  1.000000 -0.169823  0.543591 -0.320868 -0.110619  \n",
      "a_e7     0.151089  0.104500 -0.169823  1.000000 -0.063330  0.181259  0.058744  \n",
      "a_c6    -0.259348 -0.243506  0.543591 -0.063330  1.000000 -0.348303 -0.089927  \n",
      "a_c2     0.249087  0.269847 -0.320868  0.181259 -0.348303  1.000000  0.209373  \n",
      "a_act11  0.317064  0.156446 -0.110619  0.058744 -0.089927  0.209373  1.000000  \n",
      "\n",
      "[44 rows x 44 columns], '6_months_postop_arm_1':               gp1       gp2       gp3       gp4       gp5       gp6       gp7  \\\n",
      "gp1      1.000000  0.410770  0.562232  0.367324  0.387786  0.596183  0.497618   \n",
      "gp2      0.410770  1.000000  0.405563  0.298101  0.310826  0.476229  0.373241   \n",
      "gp3      0.562232  0.405563  1.000000  0.389842  0.350520  0.457684  0.536837   \n",
      "gp4      0.367324  0.298101  0.389842  1.000000  0.362655  0.506206  0.346588   \n",
      "gp5      0.387786  0.310826  0.350520  0.362655  1.000000  0.462129  0.386978   \n",
      "gp6      0.596183  0.476229  0.457684  0.506206  0.462129  1.000000  0.612528   \n",
      "gp7      0.497618  0.373241  0.536837  0.346588  0.386978  0.612528  1.000000   \n",
      "gs1     -0.191793 -0.239541 -0.218941 -0.064457 -0.141849 -0.238114 -0.314271   \n",
      "gs2      0.028118 -0.088856  0.037259  0.061576  0.118740 -0.051339 -0.052805   \n",
      "gs3     -0.113740 -0.187027 -0.206358  0.092246 -0.075845 -0.124440 -0.163342   \n",
      "gs4     -0.047432 -0.090815 -0.047200 -0.038167  0.052256 -0.098921 -0.134265   \n",
      "gs5     -0.052165 -0.110332 -0.032848 -0.029828  0.036631 -0.145457 -0.145366   \n",
      "gs6     -0.034057 -0.126399 -0.066329 -0.017902  0.115070 -0.092697 -0.041223   \n",
      "gs7     -0.164687 -0.184511 -0.040448 -0.037471 -0.149002 -0.117368 -0.231243   \n",
      "ge1      0.505824  0.254163  0.415255  0.340105  0.408808  0.529788  0.434696   \n",
      "ge2     -0.238897  0.002328 -0.147424 -0.121185 -0.135948 -0.185802 -0.149824   \n",
      "ge3      0.321120  0.090830  0.255692  0.266167  0.248762  0.412386  0.324532   \n",
      "ge4      0.326149  0.176486  0.260414  0.337108  0.278683  0.416440  0.306668   \n",
      "ge5      0.206052  0.063469  0.114871  0.232947  0.085071  0.300615  0.139248   \n",
      "ge6      0.276595  0.116855  0.178229  0.338135  0.219830  0.373228  0.263481   \n",
      "gf1     -0.528369 -0.357521 -0.523783 -0.258809 -0.246821 -0.458433 -0.482898   \n",
      "gf2     -0.479966 -0.350448 -0.558346 -0.242869 -0.258655 -0.398827 -0.455399   \n",
      "gf3     -0.460153 -0.346447 -0.486599 -0.275573 -0.237565 -0.495043 -0.497842   \n",
      "gf4     -0.236853 -0.058321 -0.201337 -0.118729 -0.104372 -0.331226 -0.236177   \n",
      "gf5     -0.292599 -0.175025 -0.264214 -0.242754 -0.052343 -0.246590 -0.206116   \n",
      "gf6     -0.409031 -0.299058 -0.457722 -0.248260 -0.241668 -0.341805 -0.374829   \n",
      "gf7     -0.419310 -0.330676 -0.422641 -0.257720 -0.284899 -0.445064 -0.414708   \n",
      "a_hn1   -0.460153 -0.223054 -0.315794 -0.260740 -0.163609 -0.370930 -0.338281   \n",
      "a_hn2    0.210424  0.282642  0.248906  0.253416  0.149335  0.244659  0.158521   \n",
      "a_hn3    0.398924  0.271117  0.259044  0.347974  0.268653  0.432850  0.255999   \n",
      "a_hn4   -0.163686 -0.121781 -0.295652 -0.088308  0.038747 -0.129414 -0.198378   \n",
      "a_hn5   -0.331077 -0.275057 -0.251327 -0.199429 -0.200834 -0.289036 -0.169956   \n",
      "a_hn7   -0.253921 -0.077048 -0.086464 -0.269308 -0.074344 -0.333544 -0.213978   \n",
      "a_hn10  -0.214082 -0.165981 -0.307210 -0.111752 -0.005051 -0.236914 -0.377812   \n",
      "a_e1     0.265435  0.214292  0.132007  0.144862  0.094966  0.274490  0.188530   \n",
      "a_e2     0.239158  0.054363  0.117907  0.269086  0.070513  0.226811  0.138198   \n",
      "a_e3     0.155448  0.002013  0.036180  0.141866 -0.067910  0.204083  0.039645   \n",
      "a_e4     0.133605  0.013224  0.088373  0.144062  0.138048  0.128013  0.023916   \n",
      "a_e5     0.278070  0.084017  0.086346  0.197206  0.045864  0.186316  0.132064   \n",
      "a_e6    -0.357199 -0.266971 -0.295252 -0.259205 -0.131748 -0.375157 -0.224566   \n",
      "a_e7     0.291569  0.019065  0.151427  0.165393  0.025817  0.178537  0.047144   \n",
      "a_c6    -0.412607 -0.334176 -0.367507 -0.189899 -0.168264 -0.319089 -0.264235   \n",
      "a_c2     0.302778  0.196817  0.308563  0.154617  0.203930  0.230917  0.297446   \n",
      "a_act11  0.211552  0.164391  0.270495  0.439698  0.265619  0.287123  0.277593   \n",
      "\n",
      "              gs1       gs2       gs3  ...      a_e1      a_e2      a_e3  \\\n",
      "gp1     -0.191793  0.028118 -0.113740  ...  0.265435  0.239158  0.155448   \n",
      "gp2     -0.239541 -0.088856 -0.187027  ...  0.214292  0.054363  0.002013   \n",
      "gp3     -0.218941  0.037259 -0.206358  ...  0.132007  0.117907  0.036180   \n",
      "gp4     -0.064457  0.061576  0.092246  ...  0.144862  0.269086  0.141866   \n",
      "gp5     -0.141849  0.118740 -0.075845  ...  0.094966  0.070513 -0.067910   \n",
      "gp6     -0.238114 -0.051339 -0.124440  ...  0.274490  0.226811  0.204083   \n",
      "gp7     -0.314271 -0.052805 -0.163342  ...  0.188530  0.138198  0.039645   \n",
      "gs1      1.000000  0.406132  0.700784  ... -0.070688  0.058981 -0.023519   \n",
      "gs2      0.406132  1.000000  0.598622  ... -0.151111  0.034570 -0.028067   \n",
      "gs3      0.700784  0.598622  1.000000  ... -0.137493 -0.038350  0.000135   \n",
      "gs4      0.412021  0.744989  0.576831  ... -0.117773 -0.040112  0.007737   \n",
      "gs5      0.423583  0.739195  0.590803  ... -0.151568 -0.060398 -0.060772   \n",
      "gs6      0.325645  0.543109  0.506589  ... -0.148182 -0.002199  0.041905   \n",
      "gs7      0.258875  0.280621  0.284172  ... -0.175025 -0.116447 -0.112752   \n",
      "ge1     -0.188999 -0.027568 -0.096981  ...  0.199141  0.160191  0.138088   \n",
      "ge2      0.193024  0.189712  0.208354  ... -0.144411 -0.104915 -0.101196   \n",
      "ge3     -0.188405 -0.089935 -0.105922  ...  0.193281  0.244257  0.207170   \n",
      "ge4     -0.167165  0.012831 -0.032882  ...  0.179019  0.160811  0.183281   \n",
      "ge5     -0.098920 -0.083712 -0.048257  ...  0.166651  0.175764  0.259661   \n",
      "ge6     -0.075751 -0.057635 -0.031451  ...  0.188729  0.147190  0.153399   \n",
      "gf1      0.344857  0.043676  0.215469  ... -0.134356 -0.080733 -0.025155   \n",
      "gf2      0.369956  0.089456  0.292189  ... -0.204995 -0.113254 -0.058892   \n",
      "gf3      0.418290  0.191470  0.339906  ... -0.268285 -0.195166 -0.111283   \n",
      "gf4      0.264877  0.293666  0.253352  ... -0.173986 -0.067887 -0.109531   \n",
      "gf5      0.194005  0.199569  0.121519  ... -0.148870 -0.139738 -0.136966   \n",
      "gf6      0.284509  0.175463  0.216739  ... -0.185987 -0.176917 -0.041447   \n",
      "gf7      0.336875  0.225952  0.259992  ... -0.215444 -0.115468  0.016224   \n",
      "a_hn1    0.189399  0.136744  0.162656  ... -0.383183 -0.426910 -0.287697   \n",
      "a_hn2   -0.120435 -0.002559 -0.129602  ... -0.009795  0.138010  0.104820   \n",
      "a_hn3   -0.143283 -0.108007 -0.154764  ...  0.152052  0.158670  0.084650   \n",
      "a_hn4    0.217975  0.269110  0.221180  ... -0.079685 -0.001642 -0.005283   \n",
      "a_hn5    0.188294  0.137785  0.077030  ... -0.192747 -0.281489 -0.047037   \n",
      "a_hn7    0.181917  0.189974  0.207924  ... -0.507349 -0.531003 -0.329068   \n",
      "a_hn10   0.442183  0.335449  0.495529  ... -0.030833 -0.082784  0.023413   \n",
      "a_e1    -0.070688 -0.151111 -0.137493  ...  1.000000  0.442250  0.288514   \n",
      "a_e2     0.058981  0.034570 -0.038350  ...  0.442250  1.000000  0.550992   \n",
      "a_e3    -0.023519 -0.028067  0.000135  ...  0.288514  0.550992  1.000000   \n",
      "a_e4     0.025238  0.027587 -0.061399  ...  0.187782  0.217591  0.178047   \n",
      "a_e5    -0.034340  0.003688 -0.044400  ...  0.402425  0.550000  0.364664   \n",
      "a_e6     0.152808  0.142865  0.189708  ... -0.387966 -0.393254 -0.198666   \n",
      "a_e7    -0.101136 -0.056844 -0.105579  ...  0.087266  0.174380  0.016113   \n",
      "a_c6     0.172196  0.182086  0.191165  ... -0.336769 -0.325160 -0.110274   \n",
      "a_c2    -0.072569  0.056566 -0.041279  ...  0.171629  0.240008  0.028463   \n",
      "a_act11 -0.151399 -0.004062  0.027955  ...  0.068581  0.157453  0.124628   \n",
      "\n",
      "             a_e4      a_e5      a_e6      a_e7      a_c6      a_c2   a_act11  \n",
      "gp1      0.133605  0.278070 -0.357199  0.291569 -0.412607  0.302778  0.211552  \n",
      "gp2      0.013224  0.084017 -0.266971  0.019065 -0.334176  0.196817  0.164391  \n",
      "gp3      0.088373  0.086346 -0.295252  0.151427 -0.367507  0.308563  0.270495  \n",
      "gp4      0.144062  0.197206 -0.259205  0.165393 -0.189899  0.154617  0.439698  \n",
      "gp5      0.138048  0.045864 -0.131748  0.025817 -0.168264  0.203930  0.265619  \n",
      "gp6      0.128013  0.186316 -0.375157  0.178537 -0.319089  0.230917  0.287123  \n",
      "gp7      0.023916  0.132064 -0.224566  0.047144 -0.264235  0.297446  0.277593  \n",
      "gs1      0.025238 -0.034340  0.152808 -0.101136  0.172196 -0.072569 -0.151399  \n",
      "gs2      0.027587  0.003688  0.142865 -0.056844  0.182086  0.056566 -0.004062  \n",
      "gs3     -0.061399 -0.044400  0.189708 -0.105579  0.191165 -0.041279  0.027955  \n",
      "gs4     -0.102168 -0.054263  0.205814 -0.043374  0.206581 -0.038894 -0.039502  \n",
      "gs5     -0.055879 -0.058066  0.249091 -0.098910  0.263362 -0.017313 -0.043620  \n",
      "gs6     -0.153807 -0.005965  0.237439 -0.089796  0.180203  0.117984  0.018886  \n",
      "gs7     -0.086697 -0.176815  0.181293 -0.073624  0.210605 -0.130831 -0.134041  \n",
      "ge1      0.077226  0.166782 -0.229601  0.117644 -0.262288  0.285435  0.247400  \n",
      "ge2     -0.119024 -0.100796  0.244019 -0.268144  0.246681 -0.171834 -0.099394  \n",
      "ge3      0.050437  0.174171 -0.222913  0.114526 -0.188594  0.236485  0.150275  \n",
      "ge4      0.124245  0.106893 -0.200332  0.090767 -0.144426  0.099862  0.196876  \n",
      "ge5      0.070080  0.104195 -0.222338  0.120447 -0.177741  0.049634  0.163804  \n",
      "ge6      0.009726  0.126559 -0.258412  0.166174 -0.129208  0.159893  0.185819  \n",
      "gf1     -0.180056 -0.150824  0.355043 -0.122580  0.396434 -0.330807 -0.183481  \n",
      "gf2     -0.105282 -0.204811  0.404308 -0.152479  0.422442 -0.310569 -0.210949  \n",
      "gf3     -0.092967 -0.169048  0.449789 -0.131273  0.508273 -0.340944 -0.274243  \n",
      "gf4     -0.076300 -0.089453  0.353182 -0.191615  0.333867 -0.222500 -0.088903  \n",
      "gf5     -0.123737 -0.188759  0.315574 -0.284962  0.380710 -0.106702 -0.262018  \n",
      "gf6     -0.142010 -0.129259  0.524380 -0.207328  0.513631 -0.367126 -0.169616  \n",
      "gf7     -0.116018 -0.111056  0.479884 -0.184870  0.478303 -0.272313 -0.238064  \n",
      "a_hn1   -0.146597 -0.317088  0.543027 -0.231479  0.527382 -0.280101 -0.054621  \n",
      "a_hn2    0.055705  0.218055 -0.083259  0.079125 -0.102739  0.179339  0.196235  \n",
      "a_hn3    0.161455  0.219117 -0.222874  0.276992 -0.160626  0.078414  0.215608  \n",
      "a_hn4    0.019142 -0.081999  0.290237 -0.109741  0.285458 -0.106418  0.024749  \n",
      "a_hn5   -0.082640 -0.201465  0.491676 -0.199824  0.524244 -0.327621 -0.278324  \n",
      "a_hn7   -0.251989 -0.486449  0.441456 -0.141398  0.382519 -0.228473 -0.125631  \n",
      "a_hn10  -0.063627 -0.053670  0.281230 -0.193220  0.314968 -0.186508 -0.104040  \n",
      "a_e1     0.187782  0.402425 -0.387966  0.087266 -0.336769  0.171629  0.068581  \n",
      "a_e2     0.217591  0.550000 -0.393254  0.174380 -0.325160  0.240008  0.157453  \n",
      "a_e3     0.178047  0.364664 -0.198666  0.016113 -0.110274  0.028463  0.124628  \n",
      "a_e4     1.000000  0.167814 -0.171380  0.031225 -0.119113  0.068248  0.166507  \n",
      "a_e5     0.167814  1.000000 -0.301993  0.147525 -0.180702  0.182619  0.273593  \n",
      "a_e6    -0.171380 -0.301993  1.000000 -0.230799  0.621512 -0.282456 -0.076782  \n",
      "a_e7     0.031225  0.147525 -0.230799  1.000000 -0.205263  0.038148  0.048295  \n",
      "a_c6    -0.119113 -0.180702  0.621512 -0.205263  1.000000 -0.404092 -0.093710  \n",
      "a_c2     0.068248  0.182619 -0.282456  0.038148 -0.404092  1.000000  0.209621  \n",
      "a_act11  0.166507  0.273593 -0.076782  0.048295 -0.093710  0.209621  1.000000  \n",
      "\n",
      "[44 rows x 44 columns], '2_years_postop_arm_1':               gp1       gp2       gp3       gp4       gp5       gp6       gp7  \\\n",
      "gp1      1.000000  0.436460  0.485226  0.411933  0.221272  0.541484  0.507800   \n",
      "gp2      0.436460  1.000000  0.352422  0.372341  0.250969  0.331749  0.390906   \n",
      "gp3      0.485226  0.352422  1.000000  0.440918  0.278274  0.530720  0.525468   \n",
      "gp4      0.411933  0.372341  0.440918  1.000000  0.417625  0.485501  0.531000   \n",
      "gp5      0.221272  0.250969  0.278274  0.417625  1.000000  0.463565  0.347314   \n",
      "gp6      0.541484  0.331749  0.530720  0.485501  0.463565  1.000000  0.686372   \n",
      "gp7      0.507800  0.390906  0.525468  0.531000  0.347314  0.686372  1.000000   \n",
      "gs1     -0.269253 -0.073499 -0.335904 -0.081652 -0.317260 -0.301239 -0.220569   \n",
      "gs2     -0.091475 -0.004616 -0.102949 -0.205387 -0.313826 -0.212290 -0.127721   \n",
      "gs3     -0.136140  0.036259 -0.305915 -0.140266 -0.353669 -0.269177 -0.277862   \n",
      "gs4     -0.108642 -0.086646 -0.169111 -0.240335 -0.314538 -0.263423 -0.220742   \n",
      "gs5     -0.041960 -0.048056 -0.166103 -0.134075 -0.223094 -0.210072 -0.115519   \n",
      "gs6     -0.058686 -0.063860 -0.096513 -0.124334 -0.293671 -0.199700 -0.146117   \n",
      "gs7     -0.386575  0.001050 -0.352918 -0.023237 -0.044355 -0.341636 -0.195907   \n",
      "ge1      0.464608  0.318866  0.625130  0.392595  0.294742  0.533993  0.597568   \n",
      "ge2     -0.136340  0.043980 -0.169356 -0.173809 -0.420454 -0.329330 -0.275507   \n",
      "ge3      0.214026  0.148389  0.393836  0.340860  0.324062  0.472240  0.439115   \n",
      "ge4      0.373833  0.237660  0.251343  0.237531  0.228223  0.406813  0.415152   \n",
      "ge5      0.285570  0.091200  0.402634  0.224002  0.225259  0.364783  0.259244   \n",
      "ge6      0.298495  0.067644  0.428926  0.248119  0.231428  0.373656  0.312657   \n",
      "gf1     -0.485886 -0.190622 -0.399589 -0.191292 -0.318462 -0.520846 -0.509222   \n",
      "gf2     -0.404600 -0.135058 -0.407477 -0.255681 -0.252188 -0.372457 -0.337071   \n",
      "gf3     -0.486072 -0.321986 -0.559563 -0.231029 -0.330135 -0.568849 -0.468238   \n",
      "gf4     -0.329946 -0.232713 -0.367283 -0.382869 -0.382541 -0.482306 -0.430634   \n",
      "gf5     -0.170748 -0.053710 -0.206102 -0.227972 -0.212669 -0.286900 -0.240705   \n",
      "gf6     -0.455311 -0.134140 -0.507429 -0.227375 -0.278610 -0.547942 -0.433960   \n",
      "gf7     -0.490654 -0.119350 -0.486748 -0.364431 -0.296346 -0.566064 -0.492104   \n",
      "a_hn1   -0.449606 -0.187170 -0.420244 -0.389889 -0.317287 -0.400569 -0.347868   \n",
      "a_hn2    0.285053  0.138262  0.208055  0.056110  0.191345  0.357549  0.246326   \n",
      "a_hn3    0.483621  0.262404  0.372818  0.298622  0.015431  0.229900  0.336881   \n",
      "a_hn4   -0.092466 -0.074263 -0.262693 -0.269194 -0.163213 -0.256506 -0.241767   \n",
      "a_hn5   -0.364150 -0.241800 -0.310562 -0.365882 -0.186610 -0.291773 -0.211781   \n",
      "a_hn7   -0.470294 -0.083574 -0.340857 -0.270718 -0.342260 -0.383702 -0.381465   \n",
      "a_hn10  -0.150971 -0.185393 -0.362063 -0.256237 -0.240753 -0.242514 -0.270601   \n",
      "a_e1     0.215454  0.085113  0.270568  0.165139  0.237708  0.319519  0.424785   \n",
      "a_e2     0.157027  0.108867  0.275841  0.263634  0.331108  0.287795  0.280064   \n",
      "a_e3     0.103636  0.074346  0.167162  0.331336  0.209028  0.152811  0.214095   \n",
      "a_e4     0.329054  0.216316  0.263183  0.302791  0.328333  0.318741  0.282193   \n",
      "a_e5     0.198349  0.119708  0.328584  0.399325  0.189274  0.234125  0.376211   \n",
      "a_e6    -0.392696 -0.141454 -0.210612 -0.219588 -0.269014 -0.272145 -0.347367   \n",
      "a_e7     0.082109  0.144461  0.247953  0.194955  0.116371  0.226868  0.291483   \n",
      "a_c6    -0.363950 -0.156456 -0.229918 -0.184452 -0.192658 -0.277379 -0.290782   \n",
      "a_c2     0.290640  0.206653  0.325137  0.249081  0.087138  0.394168  0.413857   \n",
      "a_act11  0.254896  0.392026  0.195033  0.470990  0.254864  0.270177  0.301266   \n",
      "\n",
      "              gs1       gs2       gs3  ...      a_e1      a_e2      a_e3  \\\n",
      "gp1     -0.269253 -0.091475 -0.136140  ...  0.215454  0.157027  0.103636   \n",
      "gp2     -0.073499 -0.004616  0.036259  ...  0.085113  0.108867  0.074346   \n",
      "gp3     -0.335904 -0.102949 -0.305915  ...  0.270568  0.275841  0.167162   \n",
      "gp4     -0.081652 -0.205387 -0.140266  ...  0.165139  0.263634  0.331336   \n",
      "gp5     -0.317260 -0.313826 -0.353669  ...  0.237708  0.331108  0.209028   \n",
      "gp6     -0.301239 -0.212290 -0.269177  ...  0.319519  0.287795  0.152811   \n",
      "gp7     -0.220569 -0.127721 -0.277862  ...  0.424785  0.280064  0.214095   \n",
      "gs1      1.000000  0.572229  0.745347  ... -0.231617 -0.229577 -0.047821   \n",
      "gs2      0.572229  1.000000  0.724558  ... -0.232081 -0.183816 -0.155097   \n",
      "gs3      0.745347  0.724558  1.000000  ... -0.357798 -0.319483 -0.121778   \n",
      "gs4      0.447527  0.672819  0.520511  ... -0.139246 -0.170420 -0.094180   \n",
      "gs5      0.470322  0.741599  0.597020  ... -0.154256 -0.183350 -0.101945   \n",
      "gs6      0.507081  0.701956  0.563662  ... -0.233570 -0.177447 -0.213223   \n",
      "gs7      0.343017  0.335102  0.384331  ... -0.036031 -0.075962  0.152702   \n",
      "ge1     -0.358616 -0.294683 -0.432557  ...  0.326178  0.231412  0.123641   \n",
      "ge2      0.311658  0.307769  0.366005  ... -0.277126 -0.230453 -0.193765   \n",
      "ge3     -0.274269 -0.227483 -0.251676  ...  0.257948  0.235648  0.188135   \n",
      "ge4     -0.166738 -0.112931 -0.197163  ...  0.217138  0.097663  0.159733   \n",
      "ge5     -0.241678 -0.204292 -0.268600  ...  0.192601  0.261496  0.169232   \n",
      "ge6     -0.310499 -0.200439 -0.243397  ...  0.162659  0.158129  0.064891   \n",
      "gf1      0.379858  0.237093  0.273098  ... -0.205324 -0.142947 -0.081043   \n",
      "gf2      0.369329  0.332251  0.304970  ... -0.228579 -0.176070 -0.205335   \n",
      "gf3      0.497618  0.254283  0.392384  ... -0.237824 -0.218294 -0.107436   \n",
      "gf4      0.287387  0.232150  0.277975  ... -0.184645 -0.164545 -0.210751   \n",
      "gf5      0.246904  0.372044  0.282505  ... -0.131726 -0.032454 -0.064323   \n",
      "gf6      0.462225  0.279651  0.431978  ... -0.281948 -0.228704 -0.071811   \n",
      "gf7      0.442162  0.382114  0.475738  ... -0.328087 -0.215336 -0.202327   \n",
      "a_hn1    0.460341  0.395260  0.390625  ... -0.269969 -0.171387 -0.222866   \n",
      "a_hn2   -0.115751 -0.120357 -0.126177  ...  0.295338  0.125827  0.091627   \n",
      "a_hn3   -0.104429 -0.065845 -0.037366  ...  0.239797  0.137551  0.116736   \n",
      "a_hn4    0.421548  0.254258  0.420872  ... -0.248205 -0.293744 -0.205690   \n",
      "a_hn5    0.298742  0.224100  0.262424  ... -0.251201 -0.140224 -0.241166   \n",
      "a_hn7    0.400312  0.291135  0.441656  ... -0.537537 -0.449112 -0.349766   \n",
      "a_hn10   0.419079  0.325253  0.440148  ... -0.140151 -0.387947 -0.080712   \n",
      "a_e1    -0.231617 -0.232081 -0.357798  ...  1.000000  0.545237  0.495049   \n",
      "a_e2    -0.229577 -0.183816 -0.319483  ...  0.545237  1.000000  0.600815   \n",
      "a_e3    -0.047821 -0.155097 -0.121778  ...  0.495049  0.600815  1.000000   \n",
      "a_e4    -0.160815 -0.157695 -0.105970  ...  0.358569  0.340407  0.335700   \n",
      "a_e5    -0.176347 -0.247578 -0.261318  ...  0.441307  0.327940  0.453399   \n",
      "a_e6     0.350953  0.356386  0.356860  ... -0.247106 -0.205293 -0.232703   \n",
      "a_e7     0.040186  0.077832  0.014929  ...  0.214197  0.065776  0.111576   \n",
      "a_c6     0.328104  0.246600  0.257160  ... -0.188823 -0.274426 -0.260837   \n",
      "a_c2    -0.176687 -0.116298 -0.138614  ...  0.192107  0.284518  0.120061   \n",
      "a_act11 -0.119081 -0.173163 -0.089320  ...  0.206285  0.146310  0.260725   \n",
      "\n",
      "             a_e4      a_e5      a_e6      a_e7      a_c6      a_c2   a_act11  \n",
      "gp1      0.329054  0.198349 -0.392696  0.082109 -0.363950  0.290640  0.254896  \n",
      "gp2      0.216316  0.119708 -0.141454  0.144461 -0.156456  0.206653  0.392026  \n",
      "gp3      0.263183  0.328584 -0.210612  0.247953 -0.229918  0.325137  0.195033  \n",
      "gp4      0.302791  0.399325 -0.219588  0.194955 -0.184452  0.249081  0.470990  \n",
      "gp5      0.328333  0.189274 -0.269014  0.116371 -0.192658  0.087138  0.254864  \n",
      "gp6      0.318741  0.234125 -0.272145  0.226868 -0.277379  0.394168  0.270177  \n",
      "gp7      0.282193  0.376211 -0.347367  0.291483 -0.290782  0.413857  0.301266  \n",
      "gs1     -0.160815 -0.176347  0.350953  0.040186  0.328104 -0.176687 -0.119081  \n",
      "gs2     -0.157695 -0.247578  0.356386  0.077832  0.246600 -0.116298 -0.173163  \n",
      "gs3     -0.105970 -0.261318  0.356860  0.014929  0.257160 -0.138614 -0.089320  \n",
      "gs4     -0.218214 -0.165368  0.280962 -0.064830  0.216470 -0.213990 -0.243924  \n",
      "gs5     -0.096424 -0.099105  0.245085 -0.030786  0.175304 -0.164960 -0.124932  \n",
      "gs6     -0.229243 -0.294287  0.329474  0.071471  0.280716 -0.105941 -0.278657  \n",
      "gs7     -0.016681 -0.050496  0.189995  0.192309  0.269341 -0.068964  0.076307  \n",
      "ge1      0.235836  0.321129 -0.323565  0.209624 -0.188829  0.320197  0.198507  \n",
      "ge2     -0.204691 -0.137684  0.226707 -0.121891  0.067845 -0.107398 -0.156298  \n",
      "ge3      0.075656  0.334988 -0.289494  0.073577 -0.157503  0.230755  0.267076  \n",
      "ge4      0.172344  0.181330 -0.289835  0.160967 -0.198177  0.093652  0.154219  \n",
      "ge5      0.332887  0.251406 -0.310295  0.089294 -0.212360  0.219592  0.223238  \n",
      "ge6      0.328924  0.212375 -0.284246  0.171777 -0.253894  0.306364  0.164279  \n",
      "gf1     -0.200906 -0.238247  0.441971 -0.048017  0.413592 -0.282322 -0.113493  \n",
      "gf2     -0.165022 -0.264894  0.389460 -0.091814  0.265395 -0.149328 -0.128739  \n",
      "gf3     -0.216340 -0.279965  0.412466 -0.129153  0.412183 -0.326857 -0.089204  \n",
      "gf4     -0.302506 -0.317987  0.390503 -0.194448  0.241328 -0.313290 -0.332284  \n",
      "gf5     -0.273718 -0.246488  0.200622 -0.165127  0.201847 -0.161010 -0.204883  \n",
      "gf6     -0.288618 -0.278562  0.452501 -0.080557  0.418008 -0.357706 -0.120994  \n",
      "gf7     -0.245007 -0.415883  0.502078 -0.110099  0.383382 -0.397124 -0.270744  \n",
      "a_hn1   -0.323422 -0.380192  0.546935 -0.168401  0.564024 -0.337729 -0.296239  \n",
      "a_hn2    0.234296  0.321923 -0.104061  0.170699 -0.189173  0.126599  0.224837  \n",
      "a_hn3    0.357057  0.353046 -0.323625  0.119643 -0.363401  0.241710  0.235039  \n",
      "a_hn4   -0.134835 -0.302613  0.227301 -0.115808  0.331010 -0.211363 -0.148099  \n",
      "a_hn5   -0.329500 -0.321573  0.531613 -0.123016  0.586098 -0.257449 -0.350241  \n",
      "a_hn7   -0.403188 -0.475936  0.497833 -0.180507  0.540964 -0.397182 -0.387513  \n",
      "a_hn10  -0.183006 -0.296084  0.271592 -0.257115  0.396969 -0.274389 -0.085694  \n",
      "a_e1     0.358569  0.441307 -0.247106  0.214197 -0.188823  0.192107  0.206285  \n",
      "a_e2     0.340407  0.327940 -0.205293  0.065776 -0.274426  0.284518  0.146310  \n",
      "a_e3     0.335700  0.453399 -0.232703  0.111576 -0.260837  0.120061  0.260725  \n",
      "a_e4     1.000000  0.340632 -0.318221  0.214045 -0.294040  0.265427  0.422719  \n",
      "a_e5     0.340632  1.000000 -0.411521  0.284387 -0.377086  0.288388  0.296563  \n",
      "a_e6    -0.318221 -0.411521  1.000000 -0.071441  0.637580 -0.339086 -0.165778  \n",
      "a_e7     0.214045  0.284387 -0.071441  1.000000 -0.015847  0.173219  0.147018  \n",
      "a_c6    -0.294040 -0.377086  0.637580 -0.015847  1.000000 -0.418502 -0.224310  \n",
      "a_c2     0.265427  0.288388 -0.339086  0.173219 -0.418502  1.000000  0.241248  \n",
      "a_act11  0.422719  0.296563 -0.165778  0.147018 -0.224310  0.241248  1.000000  \n",
      "\n",
      "[44 rows x 44 columns], '3_years_postop_arm_1':               gp1       gp2       gp3       gp4       gp5       gp6       gp7  \\\n",
      "gp1      1.000000  0.200227  0.468653  0.328280  0.339991  0.503563  0.433826   \n",
      "gp2      0.200227  1.000000  0.238122  0.435128  0.222740  0.199302  0.039428   \n",
      "gp3      0.468653  0.238122  1.000000  0.355273  0.275127  0.646572  0.533039   \n",
      "gp4      0.328280  0.435128  0.355273  1.000000  0.317402  0.373072  0.212243   \n",
      "gp5      0.339991  0.222740  0.275127  0.317402  1.000000  0.343622  0.065489   \n",
      "gp6      0.503563  0.199302  0.646572  0.373072  0.343622  1.000000  0.491324   \n",
      "gp7      0.433826  0.039428  0.533039  0.212243  0.065489  0.491324  1.000000   \n",
      "gs1     -0.423138 -0.217170 -0.302984 -0.214359 -0.123561 -0.388967 -0.290749   \n",
      "gs2     -0.238000  0.096116 -0.199350 -0.109750 -0.178305 -0.307447 -0.227378   \n",
      "gs3     -0.272667 -0.082636 -0.244747 -0.065148 -0.206157 -0.334471 -0.140223   \n",
      "gs4     -0.311570 -0.137487 -0.378289 -0.158693 -0.008063 -0.437949 -0.337147   \n",
      "gs5     -0.437943 -0.138625 -0.321773 -0.133470 -0.207564 -0.360489 -0.355517   \n",
      "gs6     -0.313979 -0.111883 -0.302092 -0.315535 -0.121360 -0.403941 -0.266912   \n",
      "gs7     -0.322153 -0.053144 -0.208614 -0.119004 -0.238703 -0.340544 -0.071505   \n",
      "ge1      0.323794  0.246590  0.515286  0.421012  0.288534  0.566360  0.274875   \n",
      "ge2     -0.287200 -0.140406 -0.312053 -0.303034 -0.157063 -0.283591 -0.039641   \n",
      "ge3      0.336623  0.160085  0.564192  0.352618  0.415337  0.579763  0.378438   \n",
      "ge4      0.476227  0.318531  0.334014  0.368065  0.113173  0.360053  0.414898   \n",
      "ge5      0.239979  0.190529  0.437518  0.339519  0.145168  0.356338  0.319812   \n",
      "ge6      0.238895  0.153519  0.246195  0.346063  0.152547  0.362765  0.225645   \n",
      "gf1     -0.511629 -0.103594 -0.642391 -0.363443 -0.376897 -0.599657 -0.458521   \n",
      "gf2     -0.429705 -0.102617 -0.586067 -0.364641 -0.389056 -0.496467 -0.257333   \n",
      "gf3     -0.401066 -0.014438 -0.497034 -0.241900 -0.206211 -0.551381 -0.279909   \n",
      "gf4     -0.345057 -0.268089 -0.468366 -0.425733 -0.088165 -0.516195 -0.445124   \n",
      "gf5     -0.291468 -0.186856 -0.433136 -0.311178 -0.059189 -0.468667 -0.398422   \n",
      "gf6     -0.570014 -0.124848 -0.513284 -0.312512 -0.361014 -0.436913 -0.319040   \n",
      "gf7     -0.450334 -0.367171 -0.516193 -0.502219 -0.385663 -0.532660 -0.187382   \n",
      "a_hn1   -0.452889 -0.324356 -0.389777 -0.476177 -0.307548 -0.453799 -0.192521   \n",
      "a_hn2    0.093653  0.202265  0.038568  0.142526  0.148265  0.031205 -0.148641   \n",
      "a_hn3    0.364791  0.178095  0.253444  0.197791  0.163385  0.334017  0.291795   \n",
      "a_hn4   -0.264856  0.056002 -0.130210 -0.174647  0.099108 -0.205291 -0.176082   \n",
      "a_hn5   -0.495955 -0.284642 -0.155651 -0.417550 -0.321754 -0.309095 -0.111468   \n",
      "a_hn7   -0.413881 -0.142947 -0.316173 -0.273543  0.040624 -0.310475 -0.122150   \n",
      "a_hn10  -0.374502 -0.129121 -0.259885 -0.218451 -0.100054 -0.389312 -0.221991   \n",
      "a_e1     0.411826  0.162472  0.170648  0.312657  0.035979  0.278467  0.024220   \n",
      "a_e2     0.164509  0.224595  0.194952  0.321675  0.056124  0.100883 -0.041185   \n",
      "a_e3     0.151951  0.197345  0.155918  0.219414 -0.062789  0.117989  0.022964   \n",
      "a_e4     0.214574  0.112645  0.052776  0.099562  0.319069 -0.007654  0.019479   \n",
      "a_e5     0.111685  0.125428  0.172298  0.243973 -0.212279  0.190489  0.090571   \n",
      "a_e6    -0.310002 -0.313431 -0.372363 -0.470047 -0.219800 -0.418495 -0.164681   \n",
      "a_e7     0.088256  0.171913  0.159796  0.212248 -0.101078  0.300453  0.195353   \n",
      "a_c6    -0.339532 -0.201555 -0.347418 -0.140984 -0.258761 -0.338036 -0.054139   \n",
      "a_c2     0.361362  0.060364  0.087829  0.051178  0.208111  0.170836  0.023045   \n",
      "a_act11  0.259699  0.215466  0.308863  0.326821  0.015932  0.289596  0.120644   \n",
      "\n",
      "              gs1       gs2       gs3  ...      a_e1      a_e2      a_e3  \\\n",
      "gp1     -0.423138 -0.238000 -0.272667  ...  0.411826  0.164509  0.151951   \n",
      "gp2     -0.217170  0.096116 -0.082636  ...  0.162472  0.224595  0.197345   \n",
      "gp3     -0.302984 -0.199350 -0.244747  ...  0.170648  0.194952  0.155918   \n",
      "gp4     -0.214359 -0.109750 -0.065148  ...  0.312657  0.321675  0.219414   \n",
      "gp5     -0.123561 -0.178305 -0.206157  ...  0.035979  0.056124 -0.062789   \n",
      "gp6     -0.388967 -0.307447 -0.334471  ...  0.278467  0.100883  0.117989   \n",
      "gp7     -0.290749 -0.227378 -0.140223  ...  0.024220 -0.041185  0.022964   \n",
      "gs1      1.000000  0.572659  0.810494  ... -0.170015 -0.200789 -0.135849   \n",
      "gs2      0.572659  1.000000  0.612913  ... -0.028042 -0.114595  0.046040   \n",
      "gs3      0.810494  0.612913  1.000000  ... -0.001846 -0.104210  0.019956   \n",
      "gs4      0.601984  0.669332  0.570814  ... -0.091586 -0.115181 -0.129604   \n",
      "gs5      0.769213  0.644704  0.634840  ... -0.100109 -0.093237 -0.097330   \n",
      "gs6      0.562339  0.599576  0.528072  ... -0.008199 -0.102976 -0.114374   \n",
      "gs7      0.548245  0.524246  0.619523  ... -0.057167  0.090622  0.017840   \n",
      "ge1     -0.421593 -0.292313 -0.361198  ...  0.281662  0.285470  0.223915   \n",
      "ge2      0.332289  0.249330  0.341926  ... -0.380657 -0.311643 -0.341713   \n",
      "ge3     -0.310133 -0.241272 -0.308809  ...  0.154951  0.228754  0.196903   \n",
      "ge4     -0.525590 -0.203071 -0.282687  ...  0.292910  0.197311  0.252818   \n",
      "ge5     -0.297283 -0.187310 -0.094586  ...  0.317028  0.265570  0.348093   \n",
      "ge6     -0.309309 -0.199918 -0.211675  ...  0.415009  0.201949  0.252353   \n",
      "gf1      0.340075  0.384511  0.387020  ... -0.067864 -0.122033 -0.063442   \n",
      "gf2      0.386484  0.351172  0.412766  ... -0.187570 -0.167069 -0.132850   \n",
      "gf3      0.576391  0.436845  0.614183  ... -0.161012 -0.217149 -0.200759   \n",
      "gf4      0.544062  0.356011  0.356363  ... -0.247495 -0.338688 -0.335922   \n",
      "gf5      0.437862  0.287786  0.279563  ... -0.299744 -0.313006 -0.395993   \n",
      "gf6      0.582523  0.419860  0.515912  ... -0.323949 -0.265113 -0.153390   \n",
      "gf7      0.564781  0.296704  0.499673  ... -0.432608 -0.449296 -0.370723   \n",
      "a_hn1    0.336416  0.170128  0.302903  ... -0.536302 -0.335353 -0.377948   \n",
      "a_hn2    0.039205 -0.029484  0.012318  ...  0.210100  0.070119 -0.039850   \n",
      "a_hn3   -0.299114 -0.275480 -0.287543  ...  0.177992  0.114040  0.025504   \n",
      "a_hn4    0.486360  0.297132  0.420137  ... -0.182449 -0.165498 -0.201842   \n",
      "a_hn5    0.324033  0.051628  0.175660  ... -0.498854 -0.267253 -0.339885   \n",
      "a_hn7    0.383578  0.106433  0.227809  ... -0.600452 -0.373312 -0.480903   \n",
      "a_hn10   0.642729  0.345721  0.531860  ... -0.202792 -0.107056 -0.183844   \n",
      "a_e1    -0.170015 -0.028042 -0.001846  ...  1.000000  0.561678  0.550715   \n",
      "a_e2    -0.200789 -0.114595 -0.104210  ...  0.561678  1.000000  0.791660   \n",
      "a_e3    -0.135849  0.046040  0.019956  ...  0.550715  0.791660  1.000000   \n",
      "a_e4    -0.059775 -0.000548 -0.092716  ...  0.434998  0.362356  0.287305   \n",
      "a_e5    -0.093695 -0.053940 -0.046101  ...  0.528426  0.502058  0.516016   \n",
      "a_e6     0.448738  0.352736  0.368800  ... -0.400769 -0.335720 -0.202968   \n",
      "a_e7    -0.123865 -0.086149 -0.078796  ...  0.331787  0.299650  0.246351   \n",
      "a_c6     0.407472  0.268468  0.411908  ... -0.279221 -0.162804 -0.112368   \n",
      "a_c2    -0.158223 -0.017194 -0.089750  ...  0.305450  0.146459  0.181131   \n",
      "a_act11 -0.085906 -0.017495  0.046301  ...  0.326021  0.339635  0.235858   \n",
      "\n",
      "             a_e4      a_e5      a_e6      a_e7      a_c6      a_c2   a_act11  \n",
      "gp1      0.214574  0.111685 -0.310002  0.088256 -0.339532  0.361362  0.259699  \n",
      "gp2      0.112645  0.125428 -0.313431  0.171913 -0.201555  0.060364  0.215466  \n",
      "gp3      0.052776  0.172298 -0.372363  0.159796 -0.347418  0.087829  0.308863  \n",
      "gp4      0.099562  0.243973 -0.470047  0.212248 -0.140984  0.051178  0.326821  \n",
      "gp5      0.319069 -0.212279 -0.219800 -0.101078 -0.258761  0.208111  0.015932  \n",
      "gp6     -0.007654  0.190489 -0.418495  0.300453 -0.338036  0.170836  0.289596  \n",
      "gp7      0.019479  0.090571 -0.164681  0.195353 -0.054139  0.023045  0.120644  \n",
      "gs1     -0.059775 -0.093695  0.448738 -0.123865  0.407472 -0.158223 -0.085906  \n",
      "gs2     -0.000548 -0.053940  0.352736 -0.086149  0.268468 -0.017194 -0.017495  \n",
      "gs3     -0.092716 -0.046101  0.368800 -0.078796  0.411908 -0.089750  0.046301  \n",
      "gs4     -0.003054 -0.154095  0.348596 -0.175677  0.279003  0.024834 -0.119398  \n",
      "gs5     -0.136573  0.016039  0.378537 -0.034216  0.351858 -0.145805 -0.022520  \n",
      "gs6     -0.040466 -0.061891  0.426682 -0.122253  0.238966 -0.019025 -0.041331  \n",
      "gs7      0.084863 -0.054883  0.312307 -0.057491  0.182543 -0.196296  0.018710  \n",
      "ge1      0.083087  0.194901 -0.515629  0.182750 -0.322286  0.170400  0.211349  \n",
      "ge2     -0.151223 -0.332289  0.422414 -0.279784  0.199332 -0.046452 -0.203674  \n",
      "ge3      0.205012  0.004125 -0.325835  0.131297 -0.231370  0.074087  0.130944  \n",
      "ge4      0.174644  0.141865 -0.400643  0.135957 -0.188146  0.149996  0.183978  \n",
      "ge5      0.153101  0.318382 -0.340185  0.176316 -0.195436 -0.059682  0.297110  \n",
      "ge6      0.136685  0.404182 -0.345565  0.238026 -0.214096  0.117506  0.247592  \n",
      "gf1     -0.161926 -0.219063  0.378835 -0.187762  0.387075 -0.139369 -0.173218  \n",
      "gf2     -0.065895 -0.149715  0.510248 -0.101879  0.571067 -0.287895 -0.107774  \n",
      "gf3     -0.065897 -0.263432  0.503762 -0.168682  0.453991 -0.183460 -0.094539  \n",
      "gf4     -0.089148 -0.405022  0.520338 -0.256116  0.291356  0.054214 -0.264618  \n",
      "gf5     -0.075674 -0.460785  0.452230 -0.423083  0.185725 -0.042559 -0.285022  \n",
      "gf6     -0.223106 -0.123807  0.454103 -0.048449  0.435555 -0.208646 -0.136002  \n",
      "gf7     -0.093125 -0.217072  0.701005 -0.267345  0.454021 -0.196883 -0.257537  \n",
      "a_hn1   -0.255888 -0.382139  0.715863 -0.321085  0.577403 -0.300886 -0.159433  \n",
      "a_hn2    0.163128  0.099369 -0.284792 -0.105684 -0.169599  0.054902  0.149003  \n",
      "a_hn3    0.117942  0.126328 -0.365189  0.045942 -0.292215  0.147271  0.230401  \n",
      "a_hn4   -0.078409 -0.261961  0.258745 -0.093229  0.183034 -0.001214 -0.095374  \n",
      "a_hn5   -0.170172 -0.260046  0.486977 -0.122559  0.372066 -0.451016 -0.154511  \n",
      "a_hn7   -0.215665 -0.491960  0.491549 -0.422752  0.369390 -0.175396 -0.147204  \n",
      "a_hn10  -0.033627 -0.165568  0.402064 -0.124856  0.359982 -0.094262 -0.056672  \n",
      "a_e1     0.434998  0.528426 -0.400769  0.331787 -0.279221  0.305450  0.326021  \n",
      "a_e2     0.362356  0.502058 -0.335720  0.299650 -0.162804  0.146459  0.339635  \n",
      "a_e3     0.287305  0.516016 -0.202968  0.246351 -0.112368  0.181131  0.235858  \n",
      "a_e4     1.000000  0.268780 -0.024354 -0.000496 -0.129459  0.123934  0.199026  \n",
      "a_e5     0.268780  1.000000 -0.281155  0.485208 -0.146748  0.073115  0.373150  \n",
      "a_e6    -0.024354 -0.281155  1.000000 -0.220706  0.641600 -0.172688 -0.085679  \n",
      "a_e7    -0.000496  0.485208 -0.220706  1.000000  0.003108 -0.059209  0.239313  \n",
      "a_c6    -0.129459 -0.146748  0.641600  0.003108  1.000000 -0.347886  0.009801  \n",
      "a_c2     0.123934  0.073115 -0.172688 -0.059209 -0.347886  1.000000  0.111193  \n",
      "a_act11  0.199026  0.373150 -0.085679  0.239313  0.009801  0.111193  1.000000  \n",
      "\n",
      "[44 rows x 44 columns], '4_years_postop_arm_1':               gp1       gp2       gp3       gp4       gp5       gp6       gp7  \\\n",
      "gp1      1.000000  0.414007  0.569661  0.453295  0.238025  0.567988  0.540938   \n",
      "gp2      0.414007  1.000000  0.426299  0.400242 -0.017034  0.720199  0.528404   \n",
      "gp3      0.569661  0.426299  1.000000  0.387633  0.452205  0.547194  0.545825   \n",
      "gp4      0.453295  0.400242  0.387633  1.000000 -0.023948  0.441778  0.331084   \n",
      "gp5      0.238025 -0.017034  0.452205 -0.023948  1.000000  0.090226  0.123939   \n",
      "gp6      0.567988  0.720199  0.547194  0.441778  0.090226  1.000000  0.609751   \n",
      "gp7      0.540938  0.528404  0.545825  0.331084  0.123939  0.609751  1.000000   \n",
      "gs1     -0.399915 -0.040255 -0.224050 -0.124888 -0.070291 -0.345194 -0.401593   \n",
      "gs2     -0.077414  0.015468 -0.101614  0.096506 -0.148472 -0.233033 -0.069494   \n",
      "gs3     -0.091679  0.030349 -0.003255 -0.053243 -0.060300 -0.182099 -0.120875   \n",
      "gs4     -0.337497 -0.069477 -0.170961  0.128768 -0.309516 -0.249340 -0.085529   \n",
      "gs5     -0.088263 -0.093903  0.016837  0.193412 -0.053318 -0.225265 -0.217989   \n",
      "gs6     -0.148137 -0.116457  0.000490 -0.190983  0.023310 -0.175889 -0.188034   \n",
      "gs7     -0.457494 -0.067478 -0.346218 -0.370834 -0.102013 -0.188353 -0.085086   \n",
      "ge1      0.553044  0.424319  0.494045  0.623510  0.061687  0.487220  0.546102   \n",
      "ge2     -0.099320 -0.070692 -0.175606 -0.110749 -0.234955 -0.167953 -0.202470   \n",
      "ge3      0.569276  0.514321  0.603218  0.398189  0.196773  0.608281  0.537854   \n",
      "ge4      0.589528  0.398780  0.380516  0.646625  0.041098  0.400121  0.540111   \n",
      "ge5      0.469682  0.152881  0.480437  0.301225  0.326015  0.363660  0.314329   \n",
      "ge6      0.485323  0.130025  0.390650  0.330515  0.180348  0.242369  0.399381   \n",
      "gf1     -0.574272  0.084536 -0.300293 -0.359625 -0.146945 -0.190938 -0.193457   \n",
      "gf2     -0.511271 -0.051306 -0.213751 -0.145176 -0.159995 -0.354722 -0.210525   \n",
      "gf3     -0.600992 -0.231993 -0.466507 -0.422135 -0.177792 -0.481573 -0.371072   \n",
      "gf4     -0.459582 -0.314636 -0.243703 -0.449846  0.055011 -0.502408 -0.393396   \n",
      "gf5     -0.500671 -0.421371 -0.352172 -0.493205 -0.021806 -0.479089 -0.435451   \n",
      "gf6     -0.521994 -0.065192 -0.522127 -0.380574 -0.319234 -0.357851 -0.416367   \n",
      "gf7     -0.652828 -0.230613 -0.562062 -0.427865 -0.271399 -0.398917 -0.416352   \n",
      "a_hn1   -0.468632 -0.267139 -0.391002 -0.275013 -0.486559 -0.470105 -0.494164   \n",
      "a_hn2    0.392325  0.043040  0.083939  0.331065  0.004235  0.096623  0.225026   \n",
      "a_hn3    0.606667  0.248786  0.472778  0.491517  0.183220  0.216036  0.276141   \n",
      "a_hn4   -0.502616 -0.367944 -0.086337 -0.351797  0.147025 -0.395740 -0.328183   \n",
      "a_hn5   -0.278455 -0.308555 -0.300300 -0.215345 -0.240733 -0.377047 -0.216590   \n",
      "a_hn7   -0.632620 -0.254410 -0.343687 -0.543364  0.022101 -0.456109 -0.512155   \n",
      "a_hn10  -0.321666 -0.324772 -0.182495 -0.214085 -0.047514 -0.518332 -0.312461   \n",
      "a_e1     0.578447  0.229833  0.242864  0.465841  0.014694  0.400736  0.507546   \n",
      "a_e2     0.523456  0.321785  0.387749  0.541731 -0.106397  0.533243  0.380113   \n",
      "a_e3     0.567553  0.269556  0.294398  0.468297 -0.130798  0.537479  0.407162   \n",
      "a_e4     0.646525  0.482035  0.358406  0.539340 -0.061857  0.632367  0.552016   \n",
      "a_e5     0.350860  0.386884  0.162169  0.550524 -0.120509  0.420263  0.427266   \n",
      "a_e6    -0.377296 -0.363541 -0.242990 -0.260867 -0.114718 -0.386837 -0.203482   \n",
      "a_e7     0.100829  0.500045  0.091054  0.201540 -0.129315  0.320257  0.446792   \n",
      "a_c6    -0.295321 -0.062065 -0.232683 -0.026021 -0.382658 -0.169802  0.057374   \n",
      "a_c2     0.291668  0.087326  0.198762  0.137166  0.053046  0.261293  0.281276   \n",
      "a_act11  0.399927  0.184481  0.214833  0.378448  0.122863  0.260945  0.242612   \n",
      "\n",
      "              gs1       gs2       gs3  ...      a_e1      a_e2      a_e3  \\\n",
      "gp1     -0.399915 -0.077414 -0.091679  ...  0.578447  0.523456  0.567553   \n",
      "gp2     -0.040255  0.015468  0.030349  ...  0.229833  0.321785  0.269556   \n",
      "gp3     -0.224050 -0.101614 -0.003255  ...  0.242864  0.387749  0.294398   \n",
      "gp4     -0.124888  0.096506 -0.053243  ...  0.465841  0.541731  0.468297   \n",
      "gp5     -0.070291 -0.148472 -0.060300  ...  0.014694 -0.106397 -0.130798   \n",
      "gp6     -0.345194 -0.233033 -0.182099  ...  0.400736  0.533243  0.537479   \n",
      "gp7     -0.401593 -0.069494 -0.120875  ...  0.507546  0.380113  0.407162   \n",
      "gs1      1.000000  0.457180  0.629730  ... -0.299768 -0.152658 -0.217342   \n",
      "gs2      0.457180  1.000000  0.787858  ... -0.088544  0.057119  0.201101   \n",
      "gs3      0.629730  0.787858  1.000000  ... -0.095438  0.126299  0.129130   \n",
      "gs4      0.327395  0.622041  0.565721  ... -0.198214 -0.060059 -0.036192   \n",
      "gs5      0.324474  0.694384  0.656627  ... -0.117616  0.044216  0.087767   \n",
      "gs6      0.188858  0.444471  0.380210  ... -0.196378 -0.119754 -0.065806   \n",
      "gs7      0.389231  0.545836  0.481066  ... -0.294937 -0.159238 -0.152018   \n",
      "ge1     -0.334552 -0.061609 -0.156047  ...  0.408468  0.516222  0.335427   \n",
      "ge2      0.033740  0.149566  0.190553  ... -0.253585 -0.097563 -0.037352   \n",
      "ge3     -0.310932 -0.180235 -0.102721  ...  0.473995  0.559259  0.398382   \n",
      "ge4     -0.344661 -0.006543 -0.106159  ...  0.448924  0.500479  0.329686   \n",
      "ge5     -0.413395 -0.051575 -0.164329  ...  0.285663  0.344394  0.315115   \n",
      "ge6     -0.421871  0.056575 -0.109573  ...  0.296317  0.238322  0.311906   \n",
      "gf1      0.422892  0.164866  0.294579  ... -0.463020 -0.290402 -0.381823   \n",
      "gf2      0.637331  0.455131  0.538491  ... -0.358479 -0.241032 -0.277743   \n",
      "gf3      0.648853  0.323366  0.481483  ... -0.434117 -0.331972 -0.369472   \n",
      "gf4      0.571399  0.309863  0.506365  ... -0.363097 -0.322025 -0.325605   \n",
      "gf5      0.245148  0.156972  0.153305  ... -0.457337 -0.403277 -0.277216   \n",
      "gf6      0.642691  0.301755  0.410949  ... -0.463430 -0.237214 -0.246405   \n",
      "gf7      0.469662  0.199582  0.276499  ... -0.556582 -0.341558 -0.443035   \n",
      "a_hn1    0.382666  0.143527  0.119172  ... -0.422614 -0.269284 -0.288377   \n",
      "a_hn2   -0.106874 -0.150824 -0.179419  ...  0.473168  0.190524  0.151397   \n",
      "a_hn3   -0.263063  0.105972 -0.060712  ...  0.509843  0.345256  0.394863   \n",
      "a_hn4    0.315721  0.149699  0.198811  ... -0.371232 -0.223315 -0.260988   \n",
      "a_hn5    0.143698 -0.151609 -0.084612  ... -0.152454 -0.198167 -0.144764   \n",
      "a_hn7    0.436664  0.158595  0.203552  ... -0.701151 -0.493924 -0.538479   \n",
      "a_hn10   0.442778  0.363675  0.357197  ... -0.140339 -0.194288 -0.186290   \n",
      "a_e1    -0.299768 -0.088544 -0.095438  ...  1.000000  0.527430  0.483698   \n",
      "a_e2    -0.152658  0.057119  0.126299  ...  0.527430  1.000000  0.672855   \n",
      "a_e3    -0.217342  0.201101  0.129130  ...  0.483698  0.672855  1.000000   \n",
      "a_e4    -0.309634  0.077741 -0.034244  ...  0.567203  0.643482  0.693812   \n",
      "a_e5    -0.207067  0.035174 -0.115003  ...  0.579904  0.357676  0.515782   \n",
      "a_e6     0.333772  0.085883  0.115838  ... -0.365022 -0.336891 -0.266894   \n",
      "a_e7    -0.077523 -0.059792 -0.077202  ...  0.229518  0.082588  0.193308   \n",
      "a_c6     0.010101  0.078809 -0.051870  ... -0.144281 -0.121410 -0.143484   \n",
      "a_c2    -0.175081 -0.228440  0.020189  ...  0.397251  0.222010  0.222939   \n",
      "a_act11  0.037319 -0.013971 -0.080070  ...  0.318756  0.175838  0.159638   \n",
      "\n",
      "             a_e4      a_e5      a_e6      a_e7      a_c6      a_c2   a_act11  \n",
      "gp1      0.646525  0.350860 -0.377296  0.100829 -0.295321  0.291668  0.399927  \n",
      "gp2      0.482035  0.386884 -0.363541  0.500045 -0.062065  0.087326  0.184481  \n",
      "gp3      0.358406  0.162169 -0.242990  0.091054 -0.232683  0.198762  0.214833  \n",
      "gp4      0.539340  0.550524 -0.260867  0.201540 -0.026021  0.137166  0.378448  \n",
      "gp5     -0.061857 -0.120509 -0.114718 -0.129315 -0.382658  0.053046  0.122863  \n",
      "gp6      0.632367  0.420263 -0.386837  0.320257 -0.169802  0.261293  0.260945  \n",
      "gp7      0.552016  0.427266 -0.203482  0.446792  0.057374  0.281276  0.242612  \n",
      "gs1     -0.309634 -0.207067  0.333772 -0.077523  0.010101 -0.175081  0.037319  \n",
      "gs2      0.077741  0.035174  0.085883 -0.059792  0.078809 -0.228440 -0.013971  \n",
      "gs3     -0.034244 -0.115003  0.115838 -0.077202 -0.051870  0.020189 -0.080070  \n",
      "gs4     -0.105337 -0.085305  0.376510 -0.106193  0.443891 -0.143579 -0.123185  \n",
      "gs5     -0.031793  0.019508  0.104663 -0.142485  0.070415 -0.137415  0.003592  \n",
      "gs6     -0.255409 -0.117235  0.430967 -0.011984  0.147350 -0.322090 -0.086841  \n",
      "gs7     -0.019420 -0.237358  0.293152 -0.230788  0.206174 -0.510405 -0.263161  \n",
      "ge1      0.566283  0.277298 -0.400218  0.074160  0.037840  0.323496  0.100676  \n",
      "ge2     -0.172273 -0.128481  0.173289 -0.025021  0.383168  0.007799 -0.242015  \n",
      "ge3      0.589396  0.455309 -0.243102  0.321509 -0.157528  0.259368  0.264450  \n",
      "ge4      0.496887  0.471228 -0.127381  0.145249  0.058248  0.197902  0.256060  \n",
      "ge5      0.480736  0.139464 -0.237226 -0.035413 -0.279131  0.322247  0.207958  \n",
      "ge6      0.444682  0.334022 -0.134433  0.017876 -0.188145  0.198030  0.202176  \n",
      "gf1     -0.489653 -0.144869  0.082734  0.181164  0.105376 -0.207676 -0.164655  \n",
      "gf2     -0.464690 -0.068110  0.337560  0.089880  0.161857 -0.230071 -0.125688  \n",
      "gf3     -0.490271 -0.246177  0.453747 -0.119268  0.295894 -0.247774 -0.134067  \n",
      "gf4     -0.483681 -0.282341  0.301424 -0.213363  0.058778 -0.202173 -0.291401  \n",
      "gf5     -0.427643 -0.354353  0.267930 -0.111985  0.118075 -0.246964 -0.282695  \n",
      "gf6     -0.391258 -0.190938  0.477688  0.024947  0.299284 -0.420963 -0.063714  \n",
      "gf7     -0.440366 -0.435077  0.504177 -0.183787  0.418451 -0.281814 -0.149054  \n",
      "a_hn1   -0.453369 -0.238825  0.540258 -0.217757  0.489274 -0.437162 -0.062509  \n",
      "a_hn2    0.302116  0.353157 -0.148109  0.150294 -0.149732  0.134373  0.331717  \n",
      "a_hn3    0.567370  0.369690 -0.374235  0.117390 -0.311238  0.049725  0.287642  \n",
      "a_hn4   -0.393899 -0.268171  0.301964 -0.258641  0.310528 -0.220301 -0.340869  \n",
      "a_hn5   -0.422164 -0.067911  0.555582  0.011285  0.499425 -0.169190 -0.120267  \n",
      "a_hn7   -0.545558 -0.610910  0.308428 -0.300528  0.234481 -0.166935 -0.366537  \n",
      "a_hn10  -0.292278 -0.137234  0.412428 -0.137986  0.177175 -0.207997 -0.035572  \n",
      "a_e1     0.567203  0.579904 -0.365022  0.229518 -0.144281  0.397251  0.318756  \n",
      "a_e2     0.643482  0.357676 -0.336891  0.082588 -0.121410  0.222010  0.175838  \n",
      "a_e3     0.693812  0.515782 -0.266894  0.193308 -0.143484  0.222939  0.159638  \n",
      "a_e4     1.000000  0.483179 -0.485937  0.172145 -0.153018  0.257086  0.291148  \n",
      "a_e5     0.483179  1.000000 -0.179452  0.543109 -0.007299 -0.004936  0.166703  \n",
      "a_e6    -0.485937 -0.179452  1.000000 -0.153294  0.397458 -0.239102 -0.008775  \n",
      "a_e7     0.172145  0.543109 -0.153294  1.000000  0.093974 -0.051917  0.221314  \n",
      "a_c6    -0.153018 -0.007299  0.397458  0.093974  1.000000 -0.285610 -0.193583  \n",
      "a_c2     0.257086 -0.004936 -0.239102 -0.051917 -0.285610  1.000000 -0.062231  \n",
      "a_act11  0.291148  0.166703 -0.008775  0.221314 -0.193583 -0.062231  1.000000  \n",
      "\n",
      "[44 rows x 44 columns]}\n"
     ]
    }
   ],
   "source": [
    "def compute_timepoint_correlations(file_path):\n",
    "    # Define the columns of interest (numeric survey-type variables)\n",
    "    target_columns = [\n",
    "        'gp1', 'gp2', 'gp3', 'gp4', 'gp5', 'gp6', 'gp7', 'gs1', 'gs2', 'gs3', 'gs4', 'gs5', 'gs6', 'gs7',\n",
    "        'ge1', 'ge2', 'ge3', 'ge4', 'ge5', 'ge6', 'gf1', 'gf2', 'gf3', 'gf4', 'gf5', 'gf6', 'gf7',\n",
    "        'a_hn1', 'a_hn2', 'a_hn3', 'a_hn4', 'a_hn5', 'a_hn7', 'a_hn10', 'a_e1', 'a_e2', 'a_e3',\n",
    "        'a_e4', 'a_e5', 'a_e6', 'a_e7', 'a_c6', 'a_c2', 'a_act11'\n",
    "    ]\n",
    "\n",
    "    # Load the Excel file\n",
    "    df = pd.read_excel(file_path)\n",
    " \n",
    "    # Store results in a dictionary by timepoint\n",
    "    all_timepoint_correlations = {}\n",
    "\n",
    "    # Get all unique timepoints\n",
    "    timepoints = df['redcap_event_name'].dropna().unique()\n",
    "\n",
    "    for timepoint in timepoints:\n",
    "        print(f\"\\n--- Timepoint: {timepoint} ---\")\n",
    "        df_tp = df[df['redcap_event_name'] == timepoint]\n",
    "\n",
    "        # Make sure only the relevant columns are selected and exist\n",
    "        available_cols = [col for col in target_columns if col in df_tp.columns]\n",
    "        df_subset = df_tp[available_cols]\n",
    "\n",
    "        correlation_matrix = pd.DataFrame(index=available_cols, columns=available_cols, dtype=float)\n",
    "\n",
    "        for col in available_cols:\n",
    "            df_col_clean = df_subset.dropna(subset=[col])\n",
    "            for other_col in available_cols:\n",
    "                if col == other_col:\n",
    "                    correlation_matrix.loc[col, other_col] = 1.0\n",
    "                    continue\n",
    "                df_pair = df_col_clean[[col, other_col]].dropna()\n",
    "                if len(df_pair) > 1:\n",
    "                    corr = df_pair[col].corr(df_pair[other_col], method='spearman')\n",
    "                    correlation_matrix.loc[col, other_col] = corr\n",
    "                    #print(f\"Correlation between {col} and {other_col}: {corr:.3f} (n={len(df_pair)})\")\n",
    "                else:\n",
    "                    correlation_matrix.loc[col, other_col] = None\n",
    "                    print(f\"Not enough data to correlate {col} with {other_col} (n={len(df_pair)})\")\n",
    "\n",
    "        all_timepoint_correlations[timepoint] = correlation_matrix\n",
    "\n",
    "    return all_timepoint_correlations\n",
    "\n",
    "file_path = \"../data/Merged_TSQIC_REDCap_ACCESS.xlsx\"\n",
    "timepoint_correlations = compute_timepoint_correlations(file_path)\n",
    "print(\"\\n--- Timepoint Correlations Computed ---\")\n",
    "print(timepoint_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import json\n",
    "import re\n",
    "# Column descriptions (shortened for this example, use full version in practice)\n",
    "column_descriptions = {\n",
    "    'gp1': \"I have a lack of energy\",\n",
    "    'gp2': \"I have nausea\",\n",
    "    'gp3': \"I have trouble meeting the needs of my family\",\n",
    "    'gp4': \"I have pain\",\n",
    "    'gp5': \"I am bothered by side effects of treatment\",\n",
    "    'gp6': \"I feel ill\",\n",
    "    'gp7': \"I am forced to spend time in bed\",\n",
    "    'gs1': \"I feel close to my friends\",\n",
    "    'gs2': \"I get emotional support from my family\",\n",
    "    'gs3': \"I get support from my friends\",\n",
    "    'gs4': \"My family has accepted my illness\",\n",
    "    'gs5': \"I am satisfied with family communication about my illness\",\n",
    "    'gs6': \"I feel close to my partner (or main support)\",\n",
    "    'gs7': \"I am satisfied with my sex life\",\n",
    "    'gf1': \"I am able to work (include work at home)\",\n",
    "    'gf2': \"My work is fulfilling\",\n",
    "    'gf3': \"I am able to enjoy life\",\n",
    "    'gf4': \"I have accepted my illness\",\n",
    "    'gf5': \"I am sleeping well\",\n",
    "    'gf6': \"I am enjoying the things I usually do for fun\",\n",
    "    'gf7': \"I am content with the quality of my life right now\",\n",
    "    'a_hn1': \"I am able to eat the foods that I like\",\n",
    "    'a_hn2': \"My mouth is dry\",\n",
    "    'a_hn3': \"I have trouble breathing\",\n",
    "    'a_hn4': \"My voice has its usual quality and strength\",\n",
    "    'a_hn5': \"I am able to eat as much food as I want\",\n",
    "    'a_hn7': \"I can swallow naturally and easily\",\n",
    "    'a_hn10': \"I am able to communicate with others\",\n",
    "    'a_e1': \"I have difficulty swallowing solid foods\",\n",
    "    'a_e2': \"I have difficulty swallowing soft or mashed foods\",\n",
    "    'a_e3': \"I have difficulty swallowing liquids\",\n",
    "    'a_e4': \"I have pain in my chest when I swallow\",\n",
    "    'a_e5': \"I choke when I swallow\",\n",
    "    'a_e6': \"I am able to enjoy meals with family or friends\",\n",
    "    'a_e7': \"I wake at night because of coughing\",\n",
    "    'a_c6': \"I have a good appetite\",\n",
    "    'a_c2': \"I am losing weight\",\n",
    "    'a_act11': \"I have pain in my stomach area\",\n",
    "    'ge1': \"I feel sad\",\n",
    "    'ge2': \"I am satisfied with how I am coping with my illness\",\n",
    "    'ge3': \"I am losing hope in the fight against my illness\",\n",
    "    'ge4': \"I feel nervous\",\n",
    "    'ge5': \"I worry about dying\",\n",
    "    'ge6': \"I worry that my condition will get worse\"\n",
    "}\n",
    "\n",
    "def build_llama3_chat_prompt(user_input: str) -> str:\n",
    "    # Remove the <instructions>...</instructions> block\n",
    "    input_cleaned = re.sub(r\"<instructions>.*?</instructions>\", \"\", user_input, flags=re.DOTALL).strip()\n",
    "\n",
    "    system_message = (\n",
    "        \"You are an AI assistant trained using the ReAct approach (Reason + Act). \"\n",
    "        \"Your goal is to impute missing patient survey responses by reasoning through the most relevant predictor variables. \"\n",
    "        \"All values range from 0 to 4: \"\n",
    "        \"- 0 means 'not at all' \"\n",
    "        \"- 1 means 'a little bit' \"\n",
    "        \"- 2 means 'somewhat' \"\n",
    "        \"- 3 means 'quite a bit' \"\n",
    "        \"- 4 means 'very much'. \"\n",
    "        \"First, think step-by-step and explain your reasoning inside <think>...</think> tags. \"\n",
    "        \"Then, give your final imputed answer in JSON format inside <answer>...</answer>.\"\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\"\n",
    "        f\"{system_message}<|eot_id|>\\n\"\n",
    "        \"<|start_header_id|>user<|end_header_id|>\\n\"\n",
    "        f\"{input_cleaned}<|eot_id|>\\n\"\n",
    "        \"<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "    )\n",
    "\n",
    "def normalize(val):\n",
    "    if isinstance(val, (int, float)):\n",
    "        return int(val)  # Remove decimal point (truncate)\n",
    "    return val\n",
    "    \n",
    "def generate_response(prompt: str, model, tokenizer, max_new_tokens=300):\n",
    "    chat_prompt = build_llama3_chat_prompt(prompt)\n",
    "    inputs = tokenizer(chat_prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract all <answer>...</answer> blocks\n",
    "    matches = re.findall(r\"<answer>(.*?)</answer>\", decoded, re.DOTALL)\n",
    "    answer_raw = matches[-1].strip() if matches else None\n",
    "\n",
    "    if answer_raw:\n",
    "        print(\"\\n🔍 Raw extracted string (repr):\\n\", repr(answer_raw))\n",
    "        try:\n",
    "            answer_cleaned = (\n",
    "                answer_raw.strip()\n",
    "                .replace(\"\\n\", \"\")\n",
    "                .replace(\"\\t\", \"\")\n",
    "                .replace(\"<|eot_id|>\", \"\")\n",
    "            )\n",
    "            answer_dict = json.loads(answer_cleaned)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"\\n⚠️ Found <answer> but failed to parse JSON:\\n\", answer_raw)\n",
    "            print(\"⚠️ JSONDecodeError:\", e)\n",
    "            answer_dict = None\n",
    "    else:\n",
    "        print(\"\\n⚠️ No <answer>...</answer> section found.\")\n",
    "        answer_dict = None\n",
    "\n",
    "    return decoded, answer_raw, answer_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_your_prompt_function(row, target_col, top_k, timepoint_correlations, column_descriptions):\n",
    "    \"\"\"\n",
    "    Build the ReAct-style prompt for imputing a single missing value.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    row : pd.Series\n",
    "        A single row of the DataFrame with a missing value\n",
    "    target_col : str\n",
    "        The column to impute\n",
    "    top_k : int\n",
    "        Number of top correlated predictors to include\n",
    "    timepoint_correlations : dict\n",
    "        Dictionary of correlation matrices by timepoint\n",
    "    column_descriptions : dict\n",
    "        Human-readable descriptions for each column\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    prompt : str\n",
    "        ReAct-style prompt as a string\n",
    "    \"\"\"\n",
    "    # Extract the timepoint\n",
    "    timepoint = \"baseline_arm_1\"\n",
    "    if timepoint not in timepoint_correlations:\n",
    "        raise ValueError(f\"Timepoint '{timepoint}' not found in correlation data.\")\n",
    "    \n",
    "    corr_matrix = timepoint_correlations[timepoint]\n",
    "    \n",
    "    # Get correlations for this target column\n",
    "    if target_col not in corr_matrix:\n",
    "        raise ValueError(f\"Column '{target_col}' not found in correlation matrix for timepoint '{timepoint}'.\")\n",
    "\n",
    "    target_corrs = corr_matrix[target_col].dropna().sort_values(key=abs, ascending=False)\n",
    "    \n",
    "    # Drop self-correlation\n",
    "    target_corrs = target_corrs.drop(labels=[target_col], errors='ignore')\n",
    "    \n",
    "    # Build top-k predictors — only continue if we find enough\n",
    "    predictors = []\n",
    "    for pred_col, corr_value in target_corrs.items():\n",
    "        if pd.notna(row.get(pred_col)):\n",
    "            predictors.append({\n",
    "                'name': pred_col,\n",
    "                'description': column_descriptions.get(pred_col, pred_col),\n",
    "                'value': row[pred_col],\n",
    "                'correlation': corr_value\n",
    "            })\n",
    "        if len(predictors) == top_k:\n",
    "            break\n",
    "    \n",
    "    # 🛑 Skip if we couldn't find enough valid predictors\n",
    "    if len(predictors) < top_k:\n",
    "        raise ValueError(f\"Not enough non-missing predictors for '{target_col}' at row {row.name}\")\n",
    "    \n",
    "    # Build prompt\n",
    "    instructions = (\n",
    "        \"<instructions>\\n\"\n",
    "        \"You are an AI assistant trained to impute missing patient survey responses.\\n\"\n",
    "        \"All values range from 0 to 4:\\n\"\n",
    "        \"- 0 means 'not at all'\\n\"\n",
    "        \"- 1 means 'a little bit'\\n\"\n",
    "        \"- 2 means 'somewhat'\\n\"\n",
    "        \"- 3 means 'quite a bit'\\n\"\n",
    "        \"- 4 means 'very much'\\n\"\n",
    "        \"Use the correlated features to reason about the missing value.\\n\"\n",
    "        \"Return your answer as JSON inside <answer>...</answer>.\\n\"\n",
    "        \"</instructions>\\n\"\n",
    "    )\n",
    "    \n",
    "    target_desc = column_descriptions.get(target_col, target_col)\n",
    "    reasoning = f\"<target>\\nWe are imputing '{target_col}': {target_desc}\\n</target>\\n<correlations>\"\n",
    "    \n",
    "    for pred in predictors:\n",
    "        reasoning += f\"\\n- {pred['description']} = {pred['value']} (correlation: {pred['correlation']:.2f})\"\n",
    "    \n",
    "    reasoning += \"\\n</correlations>\"\n",
    "    \n",
    "    return instructions + reasoning\n",
    "\n",
    "def apply_llm_finetuned_imputation(\n",
    "    df,\n",
    "    columns_to_impute,\n",
    "    adapter_path,  # renamed from model_path\n",
    "    base_model_path,  # NEW: required for LoRA setup\n",
    "    timepoint_correlations,\n",
    "    column_descriptions,\n",
    "    top_k=4\n",
    "):\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Load tokenizer from base model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model_path, use_fast=True)\n",
    "\n",
    "    # Load base model\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_path,\n",
    "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "        device_map=\"auto\" if torch.cuda.is_available() else None\n",
    "    )\n",
    "\n",
    "    # Load LoRA adapter\n",
    "    model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Begin imputation\n",
    "    df_imputed = df.copy()\n",
    "\n",
    "    for col in columns_to_impute:\n",
    "        missing_idx = df_imputed[df_imputed[col].isna()].index\n",
    "\n",
    "        for idx in missing_idx:\n",
    "            row = df_imputed.loc[idx]\n",
    "\n",
    "            try:\n",
    "                prompt = build_your_prompt_function(\n",
    "                    row=row,\n",
    "                    target_col=col,\n",
    "                    top_k=top_k,\n",
    "                    timepoint_correlations=timepoint_correlations,\n",
    "                    column_descriptions=column_descriptions\n",
    "                )\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "            decoded, answer_raw, answer_dict = generate_response(prompt, model, tokenizer)\n",
    "            if answer_dict and col in answer_dict:\n",
    "                value = normalize(answer_dict[col])\n",
    "                df_imputed.at[idx, col] = value\n",
    "            else:\n",
    "                print(f\"⚠️ Could not find valid value for '{col}' at index {idx}\")\n",
    "\n",
    "    return df_imputed, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Analyzing Dataset =====\n",
      "Dataset shape: (50, 62)\n",
      "\n",
      "Missing value counts:\n",
      "gp1: 40 missing values (80.00%)\n",
      "gp2: 40 missing values (80.00%)\n",
      "gp3: 40 missing values (80.00%)\n",
      "gp4: 40 missing values (80.00%)\n",
      "gp5: 40 missing values (80.00%)\n",
      "gp6: 40 missing values (80.00%)\n",
      "gp7: 40 missing values (80.00%)\n",
      "gs1: 40 missing values (80.00%)\n",
      "gs2: 40 missing values (80.00%)\n",
      "gs3: 40 missing values (80.00%)\n",
      "gs4: 41 missing values (82.00%)\n",
      "gs5: 40 missing values (80.00%)\n",
      "gs6: 40 missing values (80.00%)\n",
      "gs7: 43 missing values (86.00%)\n",
      "ge1: 40 missing values (80.00%)\n",
      "ge2: 40 missing values (80.00%)\n",
      "ge3: 41 missing values (82.00%)\n",
      "ge4: 41 missing values (82.00%)\n",
      "ge5: 40 missing values (80.00%)\n",
      "ge6: 40 missing values (80.00%)\n",
      "gf1: 40 missing values (80.00%)\n",
      "gf2: 41 missing values (82.00%)\n",
      "gf3: 40 missing values (80.00%)\n",
      "gf4: 40 missing values (80.00%)\n",
      "gf5: 40 missing values (80.00%)\n",
      "gf6: 41 missing values (82.00%)\n",
      "gf7: 40 missing values (80.00%)\n",
      "a_hn1: 40 missing values (80.00%)\n",
      "a_hn2: 40 missing values (80.00%)\n",
      "a_hn3: 40 missing values (80.00%)\n",
      "a_hn4: 40 missing values (80.00%)\n",
      "a_hn5: 40 missing values (80.00%)\n",
      "a_hn7: 40 missing values (80.00%)\n",
      "a_hn10: 40 missing values (80.00%)\n",
      "a_e1: 39 missing values (78.00%)\n",
      "a_e2: 39 missing values (78.00%)\n",
      "a_e3: 39 missing values (78.00%)\n",
      "a_e4: 40 missing values (80.00%)\n",
      "a_e5: 41 missing values (82.00%)\n",
      "a_e6: 40 missing values (80.00%)\n",
      "a_e7: 40 missing values (80.00%)\n",
      "a_c6: 40 missing values (80.00%)\n",
      "a_c2: 40 missing values (80.00%)\n",
      "a_act11: 40 missing values (80.00%)\n",
      "\n",
      "Observed values per column:\n",
      "gp1: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 3.0\n",
      "  Mean: 1.9000, Std: 0.9944\n",
      "  Unique values: 4 (40.0% unique)\n",
      "gp2: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 3.0\n",
      "  Mean: 0.8000, Std: 1.0328\n",
      "  Unique values: 4 (40.0% unique)\n",
      "gp3: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 3.0\n",
      "  Mean: 0.9000, Std: 0.9944\n",
      "  Unique values: 4 (40.0% unique)\n",
      "gp4: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 3.0\n",
      "  Mean: 1.5000, Std: 1.2693\n",
      "  Unique values: 4 (40.0% unique)\n",
      "gp5: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 3.0\n",
      "  Mean: 1.1000, Std: 1.3703\n",
      "  Unique values: 3 (30.0% unique)\n",
      "gp6: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 3.0\n",
      "  Mean: 1.3000, Std: 1.1595\n",
      "  Unique values: 4 (40.0% unique)\n",
      "gp7: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 3.0\n",
      "  Mean: 1.0000, Std: 1.2472\n",
      "  Unique values: 4 (40.0% unique)\n",
      "gs1: 10 observed values (20.00%)\n",
      "  Range: 2.0 to 4.0\n",
      "  Mean: 3.1000, Std: 0.7379\n",
      "  Unique values: 3 (30.0% unique)\n",
      "gs2: 10 observed values (20.00%)\n",
      "  Range: 3.0 to 4.0\n",
      "  Mean: 3.8000, Std: 0.4216\n",
      "  Unique values: 2 (20.0% unique)\n",
      "gs3: 10 observed values (20.00%)\n",
      "  Range: 2.0 to 4.0\n",
      "  Mean: 3.3000, Std: 0.8233\n",
      "  Unique values: 3 (30.0% unique)\n",
      "gs4: 9 observed values (18.00%)\n",
      "  Range: 2.0 to 4.0\n",
      "  Mean: 3.6667, Std: 0.7071\n",
      "  Unique values: 3 (33.3% unique)\n",
      "gs5: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 4.0\n",
      "  Mean: 3.3000, Std: 1.3375\n",
      "  Unique values: 4 (40.0% unique)\n",
      "gs6: 10 observed values (20.00%)\n",
      "  Range: 2.0 to 4.0\n",
      "  Mean: 3.8000, Std: 0.6325\n",
      "  Unique values: 2 (20.0% unique)\n",
      "gs7: 7 observed values (14.00%)\n",
      "  Range: 0.0 to 4.0\n",
      "  Mean: 3.0000, Std: 1.5275\n",
      "  Unique values: 4 (57.1% unique)\n",
      "ge1: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 3.0\n",
      "  Mean: 1.2000, Std: 1.0328\n",
      "  Unique values: 4 (40.0% unique)\n",
      "ge2: 10 observed values (20.00%)\n",
      "  Range: 2.0 to 4.0\n",
      "  Mean: 2.4000, Std: 0.6992\n",
      "  Unique values: 3 (30.0% unique)\n",
      "ge3: 9 observed values (18.00%)\n",
      "  Range: 0.0 to 2.0\n",
      "  Mean: 0.8889, Std: 0.9280\n",
      "  Unique values: 3 (33.3% unique)\n",
      "ge4: 9 observed values (18.00%)\n",
      "  Range: 0.0 to 4.0\n",
      "  Mean: 2.1111, Std: 1.3642\n",
      "  Unique values: 5 (55.6% unique)\n",
      "ge5: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 4.0\n",
      "  Mean: 1.1000, Std: 1.3703\n",
      "  Unique values: 4 (40.0% unique)\n",
      "ge6: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 4.0\n",
      "  Mean: 1.5000, Std: 1.1785\n",
      "  Unique values: 4 (40.0% unique)\n",
      "gf1: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 4.0\n",
      "  Mean: 1.7000, Std: 1.5670\n",
      "  Unique values: 5 (50.0% unique)\n",
      "gf2: 9 observed values (18.00%)\n",
      "  Range: 0.0 to 4.0\n",
      "  Mean: 2.2222, Std: 1.7873\n",
      "  Unique values: 4 (44.4% unique)\n",
      "gf3: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 4.0\n",
      "  Mean: 2.3000, Std: 1.2517\n",
      "  Unique values: 5 (50.0% unique)\n",
      "gf4: 10 observed values (20.00%)\n",
      "  Range: 1.0 to 4.0\n",
      "  Mean: 2.7000, Std: 0.9487\n",
      "  Unique values: 4 (40.0% unique)\n",
      "gf5: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 4.0\n",
      "  Mean: 1.3000, Std: 1.4181\n",
      "  Unique values: 5 (50.0% unique)\n",
      "gf6: 9 observed values (18.00%)\n",
      "  Range: 0.0 to 4.0\n",
      "  Mean: 2.2222, Std: 1.4814\n",
      "  Unique values: 4 (44.4% unique)\n",
      "gf7: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 4.0\n",
      "  Mean: 2.1000, Std: 1.5951\n",
      "  Unique values: 4 (40.0% unique)\n",
      "a_hn1: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 4.0\n",
      "  Mean: 1.5000, Std: 1.7159\n",
      "  Unique values: 4 (40.0% unique)\n",
      "a_hn2: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 4.0\n",
      "  Mean: 1.4000, Std: 1.4298\n",
      "  Unique values: 3 (30.0% unique)\n",
      "a_hn3: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 2.0\n",
      "  Mean: 0.7000, Std: 0.9487\n",
      "  Unique values: 3 (30.0% unique)\n",
      "a_hn4: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 4.0\n",
      "  Mean: 2.5000, Std: 1.5092\n",
      "  Unique values: 4 (40.0% unique)\n",
      "a_hn5: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 4.0\n",
      "  Mean: 1.3000, Std: 1.6364\n",
      "  Unique values: 4 (40.0% unique)\n",
      "a_hn7: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 4.0\n",
      "  Mean: 2.2000, Std: 1.6865\n",
      "  Unique values: 4 (40.0% unique)\n",
      "a_hn10: 10 observed values (20.00%)\n",
      "  Range: 2.0 to 4.0\n",
      "  Mean: 3.3000, Std: 0.8233\n",
      "  Unique values: 3 (30.0% unique)\n",
      "a_e1: 11 observed values (22.00%)\n",
      "  Range: 0.0 to 4.0\n",
      "  Mean: 2.1818, Std: 1.8878\n",
      "  Unique values: 3 (27.3% unique)\n",
      "a_e2: 11 observed values (22.00%)\n",
      "  Range: 0.0 to 4.0\n",
      "  Mean: 1.4545, Std: 1.8635\n",
      "  Unique values: 4 (36.4% unique)\n",
      "a_e3: 11 observed values (22.00%)\n",
      "  Range: 0.0 to 4.0\n",
      "  Mean: 0.7273, Std: 1.4206\n",
      "  Unique values: 4 (36.4% unique)\n",
      "a_e4: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 3.0\n",
      "  Mean: 1.1000, Std: 1.2867\n",
      "  Unique values: 4 (40.0% unique)\n",
      "a_e5: 9 observed values (18.00%)\n",
      "  Range: 0.0 to 2.0\n",
      "  Mean: 0.7778, Std: 0.9718\n",
      "  Unique values: 3 (33.3% unique)\n",
      "a_e6: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 4.0\n",
      "  Mean: 1.3000, Std: 1.7670\n",
      "  Unique values: 4 (40.0% unique)\n",
      "a_e7: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 2.0\n",
      "  Mean: 0.3000, Std: 0.6749\n",
      "  Unique values: 3 (30.0% unique)\n",
      "a_c6: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 4.0\n",
      "  Mean: 1.9000, Std: 1.5951\n",
      "  Unique values: 5 (50.0% unique)\n",
      "a_c2: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 4.0\n",
      "  Mean: 1.3000, Std: 1.3375\n",
      "  Unique values: 5 (50.0% unique)\n",
      "a_act11: 10 observed values (20.00%)\n",
      "  Range: 0.0 to 3.0\n",
      "  Mean: 1.1000, Std: 0.8756\n",
      "  Unique values: 4 (40.0% unique)\n",
      "\n",
      "===== Running imputation on real data =====\n",
      "Missingness statistics before imputation:\n",
      "gp1: 40 missing values (80.00%)\n",
      "gp2: 40 missing values (80.00%)\n",
      "gp3: 40 missing values (80.00%)\n",
      "gp4: 40 missing values (80.00%)\n",
      "gp5: 40 missing values (80.00%)\n",
      "gp6: 40 missing values (80.00%)\n",
      "gp7: 40 missing values (80.00%)\n",
      "gs1: 40 missing values (80.00%)\n",
      "gs2: 40 missing values (80.00%)\n",
      "gs3: 40 missing values (80.00%)\n",
      "gs4: 41 missing values (82.00%)\n",
      "gs5: 40 missing values (80.00%)\n",
      "gs6: 40 missing values (80.00%)\n",
      "gs7: 43 missing values (86.00%)\n",
      "ge1: 40 missing values (80.00%)\n",
      "ge2: 40 missing values (80.00%)\n",
      "ge3: 41 missing values (82.00%)\n",
      "ge4: 41 missing values (82.00%)\n",
      "ge5: 40 missing values (80.00%)\n",
      "ge6: 40 missing values (80.00%)\n",
      "gf1: 40 missing values (80.00%)\n",
      "gf2: 41 missing values (82.00%)\n",
      "gf3: 40 missing values (80.00%)\n",
      "gf4: 40 missing values (80.00%)\n",
      "gf5: 40 missing values (80.00%)\n",
      "gf6: 41 missing values (82.00%)\n",
      "gf7: 40 missing values (80.00%)\n",
      "a_hn1: 40 missing values (80.00%)\n",
      "a_hn2: 40 missing values (80.00%)\n",
      "a_hn3: 40 missing values (80.00%)\n",
      "a_hn4: 40 missing values (80.00%)\n",
      "a_hn5: 40 missing values (80.00%)\n",
      "a_hn7: 40 missing values (80.00%)\n",
      "a_hn10: 40 missing values (80.00%)\n",
      "a_e1: 39 missing values (78.00%)\n",
      "a_e2: 39 missing values (78.00%)\n",
      "a_e3: 39 missing values (78.00%)\n",
      "a_e4: 40 missing values (80.00%)\n",
      "a_e5: 41 missing values (82.00%)\n",
      "a_e6: 40 missing values (80.00%)\n",
      "a_e7: 40 missing values (80.00%)\n",
      "a_c6: 40 missing values (80.00%)\n",
      "a_c2: 40 missing values (80.00%)\n",
      "a_act11: 40 missing values (80.00%)\n",
      "\n",
      "Running LLM imputation...\n",
      "Dropping qol_date column for LLM method\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5687c2d518e41d09d9bac3ff53a1e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM completed in 42.23 seconds\n",
      "Warning: LLM left 39 missing values in gp1\n",
      "LLM - gp1 distribution similarity: KS=0.9000, p=0.3636\n",
      "Warning: LLM left 39 missing values in gp2\n",
      "LLM - gp2 distribution similarity: KS=0.5000, p=1.0000\n",
      "Warning: LLM left 39 missing values in gp3\n",
      "LLM - gp3 distribution similarity: KS=0.6000, p=0.9091\n",
      "Warning: LLM left 39 missing values in gp4\n",
      "LLM - gp4 distribution similarity: KS=0.7000, p=0.7273\n",
      "Warning: LLM left 39 missing values in gp5\n",
      "LLM - gp5 distribution similarity: KS=0.5000, p=1.0000\n",
      "Warning: LLM left 39 missing values in gp6\n",
      "LLM - gp6 distribution similarity: KS=0.7000, p=0.7273\n",
      "Warning: LLM left 39 missing values in gp7\n",
      "LLM - gp7 distribution similarity: KS=0.5000, p=1.0000\n",
      "Warning: LLM left 39 missing values in gs1\n",
      "LLM - gs1 distribution similarity: KS=0.7000, p=0.7273\n",
      "Warning: LLM left 39 missing values in gs2\n",
      "LLM - gs2 distribution similarity: KS=0.2000, p=1.0000\n",
      "Warning: LLM left 39 missing values in gs3\n",
      "LLM - gs3 distribution similarity: KS=0.5000, p=1.0000\n",
      "Warning: LLM left 39 missing values in gs4\n",
      "LLM - gs4 distribution similarity: KS=0.3889, p=0.9273\n",
      "Warning: LLM left 39 missing values in gs5\n",
      "LLM - gs5 distribution similarity: KS=0.3000, p=1.0000\n",
      "Warning: LLM left 39 missing values in gs6\n",
      "LLM - gs6 distribution similarity: KS=0.1000, p=1.0000\n",
      "Warning: LLM left 39 missing values in gs7\n",
      "LLM - gs7 distribution similarity: KS=0.2143, p=0.9970\n",
      "Warning: LLM left 39 missing values in ge1\n",
      "LLM - ge1 distribution similarity: KS=0.7000, p=0.7273\n",
      "Warning: LLM left 39 missing values in ge2\n",
      "LLM - ge2 distribution similarity: KS=0.9000, p=0.3636\n",
      "Warning: LLM left 39 missing values in ge3\n",
      "LLM - ge3 distribution similarity: KS=0.5556, p=0.5455\n",
      "Warning: LLM left 39 missing values in ge4\n",
      "LLM - ge4 distribution similarity: KS=0.8889, p=0.1091\n",
      "Warning: LLM left 39 missing values in ge5\n",
      "LLM - ge5 distribution similarity: KS=0.5000, p=1.0000\n",
      "Warning: LLM left 39 missing values in ge6\n",
      "LLM - ge6 distribution similarity: KS=0.8000, p=0.5455\n",
      "Warning: LLM left 39 missing values in gf1\n",
      "LLM - gf1 distribution similarity: KS=0.7000, p=0.7273\n",
      "Warning: LLM left 39 missing values in gf2\n",
      "LLM - gf2 distribution similarity: KS=0.5556, p=0.5455\n",
      "Warning: LLM left 39 missing values in gf3\n",
      "LLM - gf3 distribution similarity: KS=0.9000, p=0.3636\n",
      "Warning: LLM left 39 missing values in gf4\n",
      "LLM - gf4 distribution similarity: KS=0.8000, p=0.5455\n",
      "Warning: LLM left 39 missing values in gf5\n",
      "LLM - gf5 distribution similarity: KS=0.6000, p=0.9091\n",
      "Warning: LLM left 39 missing values in gf6\n",
      "LLM - gf6 distribution similarity: KS=0.7778, p=0.2182\n",
      "Warning: LLM left 39 missing values in gf7\n",
      "LLM - gf7 distribution similarity: KS=0.7000, p=0.7273\n",
      "Warning: LLM left 39 missing values in a_hn1\n",
      "LLM - a_hn1 distribution similarity: KS=0.8000, p=0.5455\n",
      "Warning: LLM left 39 missing values in a_hn2\n",
      "LLM - a_hn2 distribution similarity: KS=0.8000, p=0.5455\n",
      "Warning: LLM left 39 missing values in a_hn3\n",
      "LLM - a_hn3 distribution similarity: KS=0.4000, p=1.0000\n",
      "Warning: LLM left 39 missing values in a_hn4\n",
      "LLM - a_hn4 distribution similarity: KS=0.8000, p=0.5455\n",
      "Warning: LLM left 39 missing values in a_hn5\n",
      "LLM - a_hn5 distribution similarity: KS=0.5000, p=1.0000\n",
      "Warning: LLM left 39 missing values in a_hn7\n",
      "LLM - a_hn7 distribution similarity: KS=0.7000, p=0.7273\n",
      "Warning: LLM left 39 missing values in a_hn10\n",
      "LLM - a_hn10 distribution similarity: KS=1.0000, p=0.1818\n",
      "Warning: LLM left 39 missing values in a_e1\n",
      "Warning: LLM left 39 missing values in a_e2\n",
      "Warning: LLM left 39 missing values in a_e3\n",
      "Warning: LLM left 39 missing values in a_e4\n",
      "LLM - a_e4 distribution similarity: KS=1.0000, p=0.1818\n",
      "Warning: LLM left 39 missing values in a_e5\n",
      "LLM - a_e5 distribution similarity: KS=0.5000, p=0.7091\n",
      "Warning: LLM left 39 missing values in a_e6\n",
      "LLM - a_e6 distribution similarity: KS=0.4000, p=1.0000\n",
      "Warning: LLM left 39 missing values in a_e7\n",
      "LLM - a_e7 distribution similarity: KS=0.2000, p=1.0000\n",
      "Warning: LLM left 39 missing values in a_c6\n",
      "LLM - a_c6 distribution similarity: KS=0.7000, p=0.7273\n",
      "Warning: LLM left 39 missing values in a_c2\n",
      "LLM - a_c2 distribution similarity: KS=0.9000, p=0.3636\n",
      "Warning: LLM left 39 missing values in a_act11\n",
      "LLM - a_act11 distribution similarity: KS=0.8000, p=0.5455\n",
      "\n",
      "Removing qol_date for plotting functions\n",
      "\n",
      "Plotting execution times...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plotting distribution similarity...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plotting imputation histograms...\n",
      "Plotting histograms for columns: ['gp1', 'gp2', 'gp3', 'gp4', 'gp5', 'gp6', 'gp7', 'gs1', 'gs2', 'gs3', 'gs4', 'gs5', 'gs6', 'gs7', 'ge1', 'ge2', 'ge3', 'ge4', 'ge5', 'ge6', 'gf1', 'gf2', 'gf3', 'gf4', 'gf5', 'gf6', 'gf7', 'a_hn1', 'a_hn2', 'a_hn3', 'a_hn4', 'a_hn5', 'a_hn7', 'a_hn10', 'a_e1', 'a_e2', 'a_e3', 'a_e4', 'a_e5', 'a_e6', 'a_e7', 'a_c6', 'a_c2', 'a_act11']\n",
      "Histogram plot saved to 'imputation_histograms.png'\n",
      "\n",
      "Plotting correlation preservation...\n",
      "Analyzing correlations for columns: ['gp1', 'gp2', 'gp3', 'gp4', 'gp5', 'gp6', 'gp7', 'gs1', 'gs2', 'gs3', 'gs4', 'gs5', 'gs6', 'gs7', 'ge1', 'ge2', 'ge3', 'ge4', 'ge5', 'ge6', 'gf1', 'gf2', 'gf3', 'gf4', 'gf5', 'gf6', 'gf7', 'a_hn1', 'a_hn2', 'a_hn3', 'a_hn4', 'a_hn5', 'a_hn7', 'a_hn10', 'a_e1', 'a_e2', 'a_e3', 'a_e4', 'a_e5', 'a_e6', 'a_e7', 'a_c6', 'a_c2', 'a_act11']\n",
      "Correlation plot saved to 'correlation_preservation.png'\n",
      "Calculating correlation differences...\n",
      "Correlation difference plot saved to 'correlation_differences.png'\n",
      "\n",
      "===== Running sparse validation =====\n",
      "\n",
      "===== Sparse validation for column: gp1 =====\n",
      "Column gp1: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64cb7ddc57094b37a54c7b141e494f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 1.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.4000, RMSE: 0.6325, Acc: 0.6000, AUC: nan, Time: 47.68s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3fe79d3493241929344f1f2059da819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.4000, RMSE: 0.6325, Acc: 0.6000, AUC: nan, Time: 46.62s\n",
      "\n",
      "===== Sparse validation for column: gp2 =====\n",
      "Column gp2: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57abf672ffcd488cac7f13da54324540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.2000, RMSE: 0.4472, Acc: 0.8000, AUC: nan, Time: 45.86s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dafb7e0ef554459b2260afa194250df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.6000, RMSE: 0.7746, Acc: 0.4000, AUC: nan, Time: 45.60s\n",
      "\n",
      "===== Sparse validation for column: gp3 =====\n",
      "Column gp3: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a771d11038314ed3978598a056b28040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 1.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.8000, RMSE: 1.0954, Acc: 0.4000, AUC: nan, Time: 45.77s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89675895f024adbbfef159145b4a648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.8000, RMSE: 1.0954, Acc: 0.4000, AUC: nan, Time: 45.92s\n",
      "\n",
      "===== Sparse validation for column: gp4 =====\n",
      "Column gp4: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f18d41b0f048dcb2315834344aee1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 1.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 1.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.4000, RMSE: 0.6325, Acc: 0.6000, AUC: nan, Time: 46.00s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b3ab9cd65f40eab911890ea58de2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 1.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 1.6000, RMSE: 1.8974, Acc: 0.2000, AUC: nan, Time: 46.39s\n",
      "\n",
      "===== Sparse validation for column: gp5 =====\n",
      "Column gp5: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a8c327fc7e4e7384862930f038ae8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.6000, RMSE: 1.3416, Acc: 0.8000, AUC: nan, Time: 46.18s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531d361eef7742d7bb5b4a02bf168022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.4000, RMSE: 0.6325, Acc: 0.6000, AUC: nan, Time: 46.80s\n",
      "\n",
      "===== Sparse validation for column: gp6 =====\n",
      "Column gp6: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237c8dbbc5484adab4887c566ea7749d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 1.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 1.0000, RMSE: 1.3416, Acc: 0.4000, AUC: nan, Time: 45.96s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e945e49cbab4f54bdba0a568b8dc524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.6000, RMSE: 1.0000, Acc: 0.6000, AUC: nan, Time: 45.98s\n",
      "\n",
      "===== Sparse validation for column: gp7 =====\n",
      "Column gp7: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba085519850d47fe90a6efa62838686b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 1.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.4000, RMSE: 0.6325, Acc: 0.6000, AUC: nan, Time: 45.86s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04cbc3356d36438799df18da65de6d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 1.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 1.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 1.0000, RMSE: 1.1832, Acc: 0.2000, AUC: nan, Time: 45.82s\n",
      "\n",
      "===== Sparse validation for column: gs1 =====\n",
      "Column gs1: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37c56e18486454596cfc2f06b1959e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.4000, RMSE: 0.6325, Acc: 0.6000, AUC: nan, Time: 45.68s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d18392a4f6a42cab3f215f9d308b15f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.4000, RMSE: 0.6325, Acc: 0.6000, AUC: nan, Time: 45.76s\n",
      "\n",
      "===== Sparse validation for column: gs2 =====\n",
      "Column gs2: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a6b5dcb9de49eeb8199cdd9e2880b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.6000, RMSE: 0.7746, Acc: 0.4000, AUC: nan, Time: 46.07s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7053321ce474ff49972bbf3b3190f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.0000, RMSE: 0.0000, Acc: 1.0000, AUC: nan, Time: 46.06s\n",
      "\n",
      "===== Sparse validation for column: gs3 =====\n",
      "Column gs3: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a49d475582414c8f2b055dd5fde7ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.4000, RMSE: 0.6325, Acc: 0.6000, AUC: nan, Time: 45.65s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9794cbb6db5840188ede84b0b5316920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.2000, RMSE: 0.4472, Acc: 0.8000, AUC: nan, Time: 45.98s\n",
      "\n",
      "===== Sparse validation for column: gs4 =====\n",
      "Column gs4: 9 observed values (18.00%)\n",
      "\n",
      "Fold 1/1 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f244bab1a8e40468104c3a7f70d8185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.0000, RMSE: 0.0000, Acc: 1.0000, AUC: nan, Time: 46.12s\n",
      "\n",
      "===== Sparse validation for column: gs5 =====\n",
      "Column gs5: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a8a14e0ed64e7e86b643905f95039b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.0000, RMSE: 0.0000, Acc: 1.0000, AUC: nan, Time: 45.81s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42d6ba8ff7b481cbf02558507f49f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.8000, RMSE: 1.7889, Acc: 0.8000, AUC: nan, Time: 46.23s\n",
      "\n",
      "===== Sparse validation for column: gs6 =====\n",
      "Column gs6: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae369e8b4ca44fb0aea6c68c63d3fd9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.0000, RMSE: 0.0000, Acc: 1.0000, AUC: nan, Time: 47.23s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ec0be01f4046759fac3f4a6c7459bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.4000, RMSE: 0.6325, Acc: 0.6000, AUC: nan, Time: 47.31s\n",
      "\n",
      "===== Sparse validation for column: gs7 =====\n",
      "Column gs7: 7 observed values (14.00%)\n",
      "\n",
      "Fold 1/1 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079e0464da91484dacd555a70febb6a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.8000, RMSE: 1.2649, Acc: 0.6000, AUC: nan, Time: 46.88s\n",
      "\n",
      "===== Sparse validation for column: ge1 =====\n",
      "Column ge1: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142b1f75e9f4477787a6f321d265bfc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.0000, RMSE: 0.0000, Acc: 1.0000, AUC: nan, Time: 46.22s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f9cc17630f4aeaab28c92398542c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.8000, RMSE: 0.8944, Acc: 0.2000, AUC: nan, Time: 47.29s\n",
      "\n",
      "===== Sparse validation for column: ge2 =====\n",
      "Column ge2: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d9fd8e91f6240c4a12cb45579dba961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.4000, RMSE: 0.6325, Acc: 0.6000, AUC: nan, Time: 47.22s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4fcb947c25649218f06595576819e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.4000, RMSE: 0.6325, Acc: 0.6000, AUC: nan, Time: 46.51s\n",
      "\n",
      "===== Sparse validation for column: ge3 =====\n",
      "Column ge3: 9 observed values (18.00%)\n",
      "\n",
      "Fold 1/1 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e4b13bf2d14f4288203952b2bafb8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.4000, RMSE: 0.8944, Acc: 0.8000, AUC: nan, Time: 47.14s\n",
      "\n",
      "===== Sparse validation for column: ge4 =====\n",
      "Column ge4: 9 observed values (18.00%)\n",
      "\n",
      "Fold 1/1 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b76ec1e662240ea88ed7ed44e8d58b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 1.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 1.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.8000, RMSE: 1.4142, Acc: 0.6000, AUC: 0.7500, Time: 46.63s\n",
      "\n",
      "===== Sparse validation for column: ge5 =====\n",
      "Column ge5: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd11de91d0354de5a1b1afd01f1f10ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 1.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 1.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.2000, RMSE: 0.4472, Acc: 0.8000, AUC: nan, Time: 46.23s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41144adad9d144dcb8f860a3dbcad798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.4000, RMSE: 0.8944, Acc: 0.8000, AUC: nan, Time: 47.19s\n",
      "\n",
      "===== Sparse validation for column: ge6 =====\n",
      "Column ge6: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827bccb287d84a0a98cf01006ef2c353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 1.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.8000, RMSE: 1.0954, Acc: 0.4000, AUC: nan, Time: 46.50s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6569eb570604c20986ae5462f0bf40f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 1.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.6000, RMSE: 1.0000, Acc: 0.6000, AUC: nan, Time: 45.67s\n",
      "\n",
      "===== Sparse validation for column: gf1 =====\n",
      "Column gf1: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa3400370d1476ca521e9b7eaa1b774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 1.0000, RMSE: 1.1832, Acc: 0.2000, AUC: nan, Time: 45.68s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6385a1ecd146099da5e909bce3f886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.2000, RMSE: 0.4472, Acc: 0.8000, AUC: nan, Time: 45.83s\n",
      "\n",
      "===== Sparse validation for column: gf2 =====\n",
      "Column gf2: 9 observed values (18.00%)\n",
      "\n",
      "Fold 1/1 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f221f148984d0ebcc9d9e291750d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 1.0000, RMSE: 1.1832, Acc: 0.2000, AUC: nan, Time: 45.64s\n",
      "\n",
      "===== Sparse validation for column: gf3 =====\n",
      "Column gf3: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed996329055c44f1b039ce889354c9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 1.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.8000, RMSE: 1.0954, Acc: 0.4000, AUC: nan, Time: 45.54s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f19ff0792ea5497aa70c64cdbf14aca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 1.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.4000, RMSE: 0.6325, Acc: 0.6000, AUC: nan, Time: 45.62s\n",
      "\n",
      "===== Sparse validation for column: gf4 =====\n",
      "Column gf4: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ef1af7992647b8a9cab6b9a293e57b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.8000, RMSE: 1.0954, Acc: 0.4000, AUC: nan, Time: 45.77s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e3fee95db44045b3aaaac9c1e80c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.8000, RMSE: 0.8944, Acc: 0.2000, AUC: nan, Time: 45.45s\n",
      "\n",
      "===== Sparse validation for column: gf5 =====\n",
      "Column gf5: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c0dab2001745199577f82dbd90c112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 1.2000, RMSE: 1.6733, Acc: 0.4000, AUC: nan, Time: 45.71s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f47ef592894dccb361b6eeaa03d6f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.8000, RMSE: 1.0954, Acc: 0.4000, AUC: nan, Time: 46.61s\n",
      "\n",
      "===== Sparse validation for column: gf6 =====\n",
      "Column gf6: 9 observed values (18.00%)\n",
      "\n",
      "Fold 1/1 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060faecc36b34ecf908bb34cfe14dc6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.4000, RMSE: 0.6325, Acc: 0.6000, AUC: nan, Time: 46.04s\n",
      "\n",
      "===== Sparse validation for column: gf7 =====\n",
      "Column gf7: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69195df0e184647968a231999ceec16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 1.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.8000, RMSE: 1.0954, Acc: 0.4000, AUC: nan, Time: 45.64s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c31324455d49768b06a3d30b8148b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.6000, RMSE: 1.0000, Acc: 0.6000, AUC: nan, Time: 45.90s\n",
      "\n",
      "===== Sparse validation for column: a_hn1 =====\n",
      "Column a_hn1: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d20185d9c6fb41728aaba1d176928ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.2000, RMSE: 0.4472, Acc: 0.8000, AUC: nan, Time: 51.20s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f32a32e6644bcd9cbe7cc0140d6bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.0000, RMSE: 0.0000, Acc: 1.0000, AUC: nan, Time: 49.16s\n",
      "\n",
      "===== Sparse validation for column: a_hn2 =====\n",
      "Column a_hn2: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7244fee85e17419ea7ec98fbe3f5dc06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.8000, RMSE: 0.8944, Acc: 0.2000, AUC: nan, Time: 46.36s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "502348f6dd1e4975a0dfaa5f114bdefa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 1.6000, RMSE: 2.0976, Acc: 0.2000, AUC: nan, Time: 46.29s\n",
      "\n",
      "===== Sparse validation for column: a_hn3 =====\n",
      "Column a_hn3: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7fe995957cb4964b97962577968578d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 1.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.4000, RMSE: 0.6325, Acc: 0.6000, AUC: nan, Time: 46.90s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "548f4c2d16134c499935566841fdd4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.8000, RMSE: 1.2649, Acc: 0.6000, AUC: nan, Time: 47.28s\n",
      "\n",
      "===== Sparse validation for column: a_hn4 =====\n",
      "Column a_hn4: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af3538fa76645818400a1dfbc142f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 1.8000, RMSE: 2.1448, Acc: 0.2000, AUC: nan, Time: 47.61s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89492d6d77774707bd4ac39ae8fd54b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 1.2000, RMSE: 1.6733, Acc: 0.4000, AUC: nan, Time: 47.35s\n",
      "\n",
      "===== Sparse validation for column: a_hn5 =====\n",
      "Column a_hn5: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce8c5c10c7847c788bc86077c0d8a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.0000, RMSE: 0.0000, Acc: 1.0000, AUC: nan, Time: 46.95s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be40ca7f1a7477aa8c0e25f65dcf31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.6000, RMSE: 1.0000, Acc: 0.6000, AUC: nan, Time: 46.30s\n",
      "\n",
      "===== Sparse validation for column: a_hn7 =====\n",
      "Column a_hn7: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7dcf7f36ae48a78bb19af96fcf898f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 1.6000, RMSE: 1.6733, Acc: 0.0000, AUC: nan, Time: 46.07s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1351521ec446e78852481432df9356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.2000, RMSE: 0.4472, Acc: 0.8000, AUC: nan, Time: 46.22s\n",
      "\n",
      "===== Sparse validation for column: a_hn10 =====\n",
      "Column a_hn10: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676daf6722a4422fa43b3711e336d0ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.6000, RMSE: 0.7746, Acc: 0.4000, AUC: nan, Time: 46.22s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8ff3bc7f8f4e1896cb2f6ed6234157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.4000, RMSE: 0.6325, Acc: 0.6000, AUC: nan, Time: 46.24s\n",
      "\n",
      "===== Sparse validation for column: a_e1 =====\n",
      "Column a_e1: 11 observed values (22.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26588a1b5d144bdbafa1c53261bd74f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.4000, RMSE: 0.8944, Acc: 0.8000, AUC: nan, Time: 45.95s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8edce64739bb4094b718293896498874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n",
      "Warning: LLM failed to impute 1/5 values\n",
      "LLM - MAE: 0.5000, RMSE: 1.0000, Acc: 0.7500, AUC: nan, Time: 16.85s\n",
      "\n",
      "===== Sparse validation for column: a_e2 =====\n",
      "Column a_e2: 11 observed values (22.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b42010e19a94d648cea7168c64904c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e2\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 3.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 3.0}'\n",
      "Warning: LLM failed to impute 1/5 values\n",
      "LLM - MAE: 0.5000, RMSE: 0.7071, Acc: 0.5000, AUC: nan, Time: 16.82s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70eff564e2ad4e3798137a65c51c1aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.0000, RMSE: 0.0000, Acc: 1.0000, AUC: nan, Time: 46.07s\n",
      "\n",
      "===== Sparse validation for column: a_e3 =====\n",
      "Column a_e3: 11 observed values (22.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e370d140df24450c8ddf9bb8e6eb45d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n",
      "Warning: LLM failed to impute 1/5 values\n",
      "LLM - MAE: 0.0000, RMSE: 0.0000, Acc: 1.0000, AUC: nan, Time: 16.87s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6812dadfda444e1883adcf022ae9af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 1.2000, RMSE: 1.8974, Acc: 0.4000, AUC: nan, Time: 48.28s\n",
      "\n",
      "===== Sparse validation for column: a_e4 =====\n",
      "Column a_e4: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "826330283be74e79a7ebb17edad51b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 0.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n",
      "Warning: LLM failed to impute 1/5 values\n",
      "LLM - MAE: 0.7500, RMSE: 1.1180, Acc: 0.5000, AUC: nan, Time: 17.13s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b49d7bd3cc4bd6adc1ae19cee13430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 1.2000, RMSE: 1.8974, Acc: 0.6000, AUC: nan, Time: 46.21s\n",
      "\n",
      "===== Sparse validation for column: a_e5 =====\n",
      "Column a_e5: 9 observed values (18.00%)\n",
      "\n",
      "Fold 1/1 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e6fb5f11064ec18ca8e1dfd795e4fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.8000, RMSE: 1.2649, Acc: 0.6000, AUC: nan, Time: 45.71s\n",
      "\n",
      "===== Sparse validation for column: a_e6 =====\n",
      "Column a_e6: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8e471b01da4fdd81658bcaded0c46b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.2000, RMSE: 0.4472, Acc: 0.8000, AUC: nan, Time: 46.04s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98280483d5884fb2acafed9ca8a94e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 3.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.6000, RMSE: 1.0000, Acc: 0.6000, AUC: nan, Time: 45.90s\n",
      "\n",
      "===== Sparse validation for column: a_e7 =====\n",
      "Column a_e7: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1134f52cda1b44a89f8f7efbe31e416a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.4000, RMSE: 0.8944, Acc: 0.8000, AUC: nan, Time: 45.76s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e86ec7951fc4ce1a35e49786f79702e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.2000, RMSE: 0.4472, Acc: 0.8000, AUC: nan, Time: 46.01s\n",
      "\n",
      "===== Sparse validation for column: a_c6 =====\n",
      "Column a_c6: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8ad25ba3734bfcb2dc6b15260e3c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 1.2000, RMSE: 1.6733, Acc: 0.4000, AUC: 0.6250, Time: 46.47s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c6e1898009443e95df6d288ab91d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.2000, RMSE: 0.4472, Acc: 0.8000, AUC: nan, Time: 46.15s\n",
      "\n",
      "===== Sparse validation for column: a_c2 =====\n",
      "Column a_c2: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e270b7b5a624623a42d3c8706265596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 2.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 0.8000, RMSE: 1.0954, Acc: 0.4000, AUC: nan, Time: 46.09s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8c44148da74d75a3c965326fe00d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 2.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "LLM - MAE: 1.8000, RMSE: 2.3238, Acc: 0.2000, AUC: nan, Time: 45.98s\n",
      "\n",
      "===== Sparse validation for column: a_act11 =====\n",
      "Column a_act11: 10 observed values (20.00%)\n",
      "\n",
      "Fold 1/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3dda4ab0df4437b5d077b62ebea992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf2\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_hn10\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_e7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_c2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 1.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 0.0}'\n",
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"a_act11\": 2.0}'\n",
      "LLM - MAE: 0.4000, RMSE: 0.6325, Acc: 0.6000, AUC: nan, Time: 47.88s\n",
      "\n",
      "Fold 2/2 - Testing on 5 samples\n",
      "Running LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b115e65cf7ab4cd690d3578a0cb43c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp2\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gp7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs1\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs3\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs4\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs5\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs6\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 2.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gs7\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge1\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge2\": 4.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge3\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge4\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge5\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"ge6\": 0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Raw extracted string (repr):\n",
      " '{\"gf1\": 0.0}'\n"
     ]
    }
   ],
   "source": [
    "# Add these imports at the top of your file\n",
    "# from TransformerImputer import apply_transformer_imputation\n",
    "# from CUDATransformerImputer import apply_cudatransformer_imputation\n",
    "from peft import PeftModel\n",
    "def evaluate_real_data_imputation(df, columns_to_impute):\n",
    "    \"\"\"\n",
    "    Evaluate imputation methods on real data with existing missing values\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Your real dataset with missing values\n",
    "    columns_to_impute : list\n",
    "        List of column names to impute\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    all_imputed_dfs : dict\n",
    "        Dictionary with imputed DataFrames from each method\n",
    "    original_df_with_missing : pandas.DataFrame\n",
    "        Original dataframe with missing values\n",
    "    execution_times : dict\n",
    "        Dictionary with execution times for each method\n",
    "    \"\"\"\n",
    "    # Define the methods to compare\n",
    "    methods = {\n",
    "        #'MICE': apply_mice_imputation,\n",
    "        #'VAE': apply_vae_imputation,\n",
    "        #'DAE': apply_sklearn_dae_imputation,\n",
    "        #'Bayesian PCA': apply_bpca_imputation,\n",
    "        #'Da XU DL': apply_deep_autoencoder_imputation,\n",
    "        #'SoftImpute': apply_softimpute_imputation,\n",
    "        #'KNN': apply_knn_imputation,\n",
    "        'LLM': lambda df, cols: apply_llm_finetuned_imputation(\n",
    "            df,\n",
    "            cols,\n",
    "            adapter_path=\"../../LoraFineTune/FinalFinalTopK4WH_ans_test3e-5_ep10_n20000_r32_a64_d0.1_q_v_b1_g8\",\n",
    "            base_model_path=\"../../Llama-3.2-3B-Instruct\",\n",
    "            timepoint_correlations=timepoint_correlations,\n",
    "            column_descriptions=column_descriptions,\n",
    "            top_k=4\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # Initialize dictionaries to store results\n",
    "    all_imputed_dfs = {}\n",
    "    execution_times = {}\n",
    "    distribution_similarity = {method: {} for method in methods}\n",
    "    \n",
    "    # Calculate missingness statistics before imputation\n",
    "    print(\"Missingness statistics before imputation:\")\n",
    "    for col in columns_to_impute:\n",
    "        missing_count = df[col].isna().sum()\n",
    "        missing_percent = (missing_count / len(df)) * 100\n",
    "        print(f\"{col}: {missing_count} missing values ({missing_percent:.2f}%)\")\n",
    "    \n",
    "    # Save a copy of the original data with missing values\n",
    "    original_df_with_missing = df.copy()\n",
    "    \n",
    "    # Run each imputation method\n",
    "    for method_name, method_func in methods.items():\n",
    "        print(f\"\\nRunning {method_name} imputation...\")\n",
    "        \n",
    "        try:\n",
    "            # Time the imputation\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Create a copy of the dataframe for this method\n",
    "            method_df = df.copy()\n",
    "            \n",
    "            # For methods other than 'Da XU DL', drop the qol_date column to avoid issues\n",
    "            if method_name != 'Da XU DL' and 'qol_date' in method_df.columns:\n",
    "                print(f\"Dropping qol_date column for {method_name} method\")\n",
    "                method_df = method_df.drop(columns=['qol_date'])\n",
    "            \n",
    "            # Apply the imputation method\n",
    "            imputed_df, _ = method_func(\n",
    "                method_df, \n",
    "                columns_to_impute\n",
    "            )\n",
    "            \n",
    "            end_time = time.time()\n",
    "            execution_time = end_time - start_time\n",
    "            execution_times[method_name] = execution_time\n",
    "            \n",
    "            # Store the imputed dataframe\n",
    "            all_imputed_dfs[method_name] = imputed_df\n",
    "            \n",
    "            # Print execution time\n",
    "            print(f\"{method_name} completed in {execution_time:.2f} seconds\")\n",
    "            \n",
    "            # Check if imputation was successful (no missing values in imputed columns)\n",
    "            for col in columns_to_impute:\n",
    "                if col not in imputed_df.columns:\n",
    "                    print(f\"Warning: Column {col} missing in {method_name} results\")\n",
    "                    continue\n",
    "                    \n",
    "                remaining_missing = imputed_df[col].isna().sum()\n",
    "                if remaining_missing > 0:\n",
    "                    print(f\"Warning: {method_name} left {remaining_missing} missing values in {col}\")\n",
    "                \n",
    "                # Measure distribution similarity between observed and imputed values\n",
    "                observed_values = original_df_with_missing.loc[original_df_with_missing[col].notna(), col]\n",
    "                imputed_indices = original_df_with_missing[col].isna() & ~imputed_df[col].isna()\n",
    "                \n",
    "                if imputed_indices.any():\n",
    "                    imputed_values = imputed_df.loc[imputed_indices, col]\n",
    "                    \n",
    "                    if len(observed_values) > 0 and len(imputed_values) > 0:\n",
    "                        # Kolmogorov-Smirnov test for distribution similarity\n",
    "                        ks_stat, ks_pval = ks_2samp(observed_values, imputed_values)\n",
    "                        distribution_similarity[method_name][col] = {\n",
    "                            'ks_stat': ks_stat,\n",
    "                            'ks_pval': ks_pval\n",
    "                        }\n",
    "                        print(f\"{method_name} - {col} distribution similarity: KS={ks_stat:.4f}, p={ks_pval:.4f}\")\n",
    "                        #Lower KS statistic and higher p-values indicate better distribution preservation\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error running {method_name}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()  # Print the full error trace for better diagnosis\n",
    "    \n",
    "    return all_imputed_dfs, original_df_with_missing, execution_times, distribution_similarity\n",
    "\n",
    "\n",
    "def evaluate_with_sparse_validation(df, columns_to_impute, n_folds=3):\n",
    "    \"\"\"\n",
    "    Evaluate imputation methods using cross-validation optimized for sparse data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Your real dataset with missing values\n",
    "    columns_to_impute : list\n",
    "        List of column names to impute\n",
    "    n_folds : int\n",
    "        Number of validation folds\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    results : dict\n",
    "        Dictionary with validation results for each method\n",
    "    \"\"\"\n",
    "    # Define the methods to compare\n",
    "    methods = {\n",
    "        #'MICE': apply_mice_imputation,\n",
    "        #'VAE': apply_vae_imputation,\n",
    "        #'DAE': apply_sklearn_dae_imputation,\n",
    "        #'Bayesian PCA': apply_bpca_imputation,\n",
    "        #'Da XU DL': apply_deep_autoencoder_imputation,\n",
    "        #'SoftImpute': apply_softimpute_imputation,\n",
    "        #'KNN': apply_knn_imputation,\n",
    "        'LLM': lambda df, cols: apply_llm_finetuned_imputation(\n",
    "            df,\n",
    "            cols,\n",
    "            adapter_path=\"../../LoraFineTune/FinalFinalTopK4WH_ans_test3e-5_ep10_n20000_r32_a64_d0.1_q_v_b1_g8\",\n",
    "            base_model_path=\"../../Llama-3.2-3B-Instruct\",\n",
    "            timepoint_correlations=timepoint_correlations,\n",
    "            column_descriptions=column_descriptions,\n",
    "            top_k=4\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # Initialize results dictionary - now including classification metrics\n",
    "    results = {method: {\n",
    "        'mae': [], 'rmse': [], 'accuracy': [], 'auc_multiclass': [],\n",
    "        'avg_sensitivity': [], 'avg_specificity': [], 'avg_ppv': [], 'avg_npv': [],\n",
    "        'precision_macro': [], 'recall_macro': [], 'time': []\n",
    "    } for method in methods}\n",
    "\n",
    "    # IMPORTANT: Filter out columns that don't exist in the dataframe and any derived date columns\n",
    "    valid_columns = []\n",
    "    for col in columns_to_impute:\n",
    "        if col in df.columns and not col.startswith('qol_date_'):\n",
    "            valid_columns.append(col)\n",
    "\n",
    "    # Print warning if columns were filtered\n",
    "    if len(valid_columns) != len(columns_to_impute):\n",
    "        excluded_cols = set(columns_to_impute) - set(valid_columns)\n",
    "        print(f\"Warning: Excluding {len(excluded_cols)} columns that are not in the dataframe or are derived date columns:\")\n",
    "        print(f\"  {sorted(excluded_cols)}\")\n",
    "        print(f\"Valid columns for validation: {sorted(valid_columns)}\")\n",
    "\n",
    "    # For each column, perform validation on non-missing values\n",
    "    for col in valid_columns:\n",
    "        print(f\"\\n===== Sparse validation for column: {col} =====\")\n",
    "        \n",
    "        # Get indices of non-missing values for this column\n",
    "        observed_indices = df.index[df[col].notna()].tolist()\n",
    "        n_observed = len(observed_indices)\n",
    "        \n",
    "        print(f\"Column {col}: {n_observed} observed values ({n_observed/len(df)*100:.2f}%)\")\n",
    "        \n",
    "        # Skip if too few observations\n",
    "        if n_observed < max(5, n_folds * 2):\n",
    "            print(f\"Too few observed values for validation. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Instead of standard KFold, use a more conservative approach for sparse data\n",
    "        fold_size = max(5, n_observed // n_folds)  # Ensure at least 5 samples per fold\n",
    "        \n",
    "        # Shuffle observed indices\n",
    "        np.random.seed(random.randint(0, 10000))  # For reproducibility\n",
    "        shuffled_indices = np.random.permutation(observed_indices)\n",
    "        \n",
    "        for fold in range(min(n_folds, n_observed // fold_size)):\n",
    "            # Select test indices for this fold\n",
    "            start_idx = fold * fold_size\n",
    "            end_idx = min(start_idx + fold_size, n_observed)\n",
    "            test_indices = shuffled_indices[start_idx:end_idx]\n",
    "            \n",
    "            print(f\"\\nFold {fold+1}/{min(n_folds, n_observed // fold_size)} - Testing on {len(test_indices)} samples\")\n",
    "            \n",
    "            # Create a copy of the original dataframe\n",
    "            df_fold = df.copy()\n",
    "            \n",
    "            # Store original values from test set\n",
    "            original_values = df_fold.loc[test_indices, col].copy()\n",
    "            \n",
    "            # Set test values to NaN (simulating missingness)\n",
    "            df_fold.loc[test_indices, col] = np.nan\n",
    "            \n",
    "            # For each imputation method\n",
    "            for method_name, method_func in methods.items():\n",
    "                print(f\"Running {method_name}...\")\n",
    "                \n",
    "                try:\n",
    "                    # Create a method-specific copy of the dataframe\n",
    "                    method_df = df_fold.copy()\n",
    "                    \n",
    "                    # For methods other than 'Da XU DL', drop the qol_date column\n",
    "                    if method_name != 'Da XU DL' and 'qol_date' in method_df.columns:\n",
    "                        method_df = method_df.drop(columns=['qol_date'])\n",
    "                    \n",
    "                    # Time the imputation\n",
    "                    start_time = time.time()\n",
    "                    \n",
    "                    # Apply imputation - use only valid_columns for imputation\n",
    "                    imputed_df, _ = method_func(method_df.copy(), valid_columns)\n",
    "                    \n",
    "                    end_time = time.time()\n",
    "                    execution_time = end_time - start_time\n",
    "                    \n",
    "                    # Get imputed values for the test indices\n",
    "                    if col not in imputed_df.columns:\n",
    "                        print(f\"Warning: Column {col} not found in {method_name} results. Skipping.\")\n",
    "                        continue\n",
    "                        \n",
    "                    imputed_values = imputed_df.loc[test_indices, col]\n",
    "                    \n",
    "                    # Check for any still-missing values\n",
    "                    still_missing = imputed_values.isna().sum()\n",
    "                    if still_missing > 0:\n",
    "                        print(f\"Warning: {method_name} failed to impute {still_missing}/{len(test_indices)} values\")\n",
    "                        # Use only successfully imputed values for evaluation\n",
    "                        valid_indices = [idx for idx in test_indices if not pd.isna(imputed_df.loc[idx, col])]\n",
    "                        \n",
    "                        if not valid_indices:\n",
    "                            print(f\"No valid imputations to evaluate for {method_name}\")\n",
    "                            continue\n",
    "                            \n",
    "                        original_values_filtered = df.loc[valid_indices, col]\n",
    "                        imputed_values_filtered = imputed_df.loc[valid_indices, col]\n",
    "                    else:\n",
    "                        original_values_filtered = original_values\n",
    "                        imputed_values_filtered = imputed_values\n",
    "                    \n",
    "                    # Calculate continuous metrics (NO ROUNDING)\n",
    "                    mae = mean_absolute_error(original_values_filtered, imputed_values_filtered)\n",
    "                    rmse = np.sqrt(mean_squared_error(original_values_filtered, imputed_values_filtered))\n",
    "                    \n",
    "                    # Calculate classification metrics (WITH ROUNDING)\n",
    "                    real_vals_class = process_for_classification(original_values_filtered)\n",
    "                    imputed_vals_class = process_for_classification(imputed_values_filtered)\n",
    "                    \n",
    "                    classification_metrics = calculate_classification_metrics(real_vals_class, imputed_vals_class)\n",
    "                    \n",
    "                    # Store results\n",
    "                    results[method_name]['mae'].append(mae)\n",
    "                    results[method_name]['rmse'].append(rmse)\n",
    "                    results[method_name]['accuracy'].append(classification_metrics['accuracy'])\n",
    "                    results[method_name]['auc_multiclass'].append(classification_metrics['auc_multiclass'] if not np.isnan(classification_metrics['auc_multiclass']) else 0)\n",
    "                    results[method_name]['avg_sensitivity'].append(classification_metrics['avg_sensitivity'])\n",
    "                    results[method_name]['avg_specificity'].append(classification_metrics['avg_specificity'])\n",
    "                    results[method_name]['avg_ppv'].append(classification_metrics['avg_ppv'])\n",
    "                    results[method_name]['avg_npv'].append(classification_metrics['avg_npv'])\n",
    "                    results[method_name]['precision_macro'].append(classification_metrics['precision_macro'])\n",
    "                    results[method_name]['recall_macro'].append(classification_metrics['recall_macro'])\n",
    "                    results[method_name]['time'].append(execution_time)\n",
    "                    \n",
    "                    print(f\"{method_name} - MAE: {mae:.4f}, RMSE: {rmse:.4f}, Acc: {classification_metrics['accuracy']:.4f}, AUC: {classification_metrics['auc_multiclass']:.4f}, Time: {execution_time:.2f}s\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error with {method_name}: {e}\")\n",
    "                    import traceback\n",
    "                    traceback.print_exc()  # Print full traceback for better debugging\n",
    "\n",
    "    # Calculate average results across all columns and folds\n",
    "    metric_names = ['mae', 'rmse', 'accuracy', 'auc_multiclass', 'avg_sensitivity', 'avg_specificity', \n",
    "                    'avg_ppv', 'avg_npv', 'precision_macro', 'recall_macro', 'time']\n",
    "    \n",
    "    for method in methods:\n",
    "        if results[method]['mae']:  # Check if we have any results\n",
    "            for metric in metric_names:\n",
    "                results[method][f'avg_{metric}'] = np.mean(results[method][metric])\n",
    "                results[method][f'std_{metric}'] = np.std(results[method][metric])\n",
    "        else:\n",
    "            print(f\"No valid results for {method}\")\n",
    "            for metric in metric_names:\n",
    "                results[method][f'avg_{metric}'] = np.nan\n",
    "                results[method][f'std_{metric}'] = np.nan\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_execution_times(execution_times):\n",
    "    \"\"\"\n",
    "    Plot execution times for each imputation method\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    execution_times : dict\n",
    "        Dictionary with execution times for each method\n",
    "    \"\"\"\n",
    "    methods = list(execution_times.keys())\n",
    "    times = list(execution_times.values())\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(methods, times, alpha=0.7, color='green')\n",
    "    \n",
    "    plt.title('Execution Time by Imputation Method', fontsize=14)\n",
    "    plt.ylabel('Time (seconds)', fontsize=12)\n",
    "    plt.xlabel('Method', fontsize=12)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add values on top of bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.02 * max(times),\n",
    "                f'{height:.2f}s', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('imputation_execution_times.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_distribution_similarity(distribution_similarity):\n",
    "    \"\"\"\n",
    "    Plot KS statistics for distribution similarity\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    distribution_similarity : dict\n",
    "        Dictionary with KS test results\n",
    "    \"\"\"\n",
    "    # Prepare data for plotting\n",
    "    methods = list(distribution_similarity.keys())\n",
    "    columns = list(distribution_similarity[methods[0]].keys()) if methods else []\n",
    "    \n",
    "    if not methods or not columns:\n",
    "        print(\"No distribution similarity data to plot\")\n",
    "        return\n",
    "    \n",
    "    # Create a DataFrame for easier plotting\n",
    "    data = []\n",
    "    for method in methods:\n",
    "        for col in columns:\n",
    "            if col in distribution_similarity[method]:\n",
    "                data.append({\n",
    "                    'Method': method,\n",
    "                    'Column': col,\n",
    "                    'KS Statistic': distribution_similarity[method][col]['ks_stat'],\n",
    "                    'p-value': distribution_similarity[method][col]['ks_pval']\n",
    "                })\n",
    "    \n",
    "    if not data:\n",
    "        print(\"No valid distribution similarity data to plot\")\n",
    "        return\n",
    "    \n",
    "    df_plot = pd.DataFrame(data)\n",
    "    \n",
    "    # Plot KS statistics (lower is better - more similar distributions)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    chart = sns.barplot(x='Method', y='KS Statistic', hue='Column', data=df_plot)\n",
    "    \n",
    "    plt.title('Distribution Similarity by Method (Lower KS = More Similar)', fontsize=14)\n",
    "    plt.ylabel('Kolmogorov-Smirnov Statistic', fontsize=12)\n",
    "    plt.xlabel('Method', fontsize=12)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.legend(title='Column', bbox_to_anchor=(1.05, 1), loc='upper left', ncol=3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('distribution_similarity.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot p-values (higher is better - can't reject null hypothesis of same distribution)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    chart = sns.barplot(x='Method', y='p-value', hue='Column', data=df_plot)\n",
    "    \n",
    "    plt.title('Distribution Similarity p-values by Method (Higher = More Similar)', fontsize=14)\n",
    "    plt.ylabel('p-value', fontsize=12)\n",
    "    plt.xlabel('Method', fontsize=12)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.legend(title='Column', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('distribution_pvalues.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_imputation_histograms(original_df, imputed_dfs, columns_to_impute):\n",
    "    \"\"\"\n",
    "    Plot histograms of imputed values compared to original observed values\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    original_df : pandas.DataFrame\n",
    "        Original data with missing values\n",
    "    imputed_dfs : dict\n",
    "        Dictionary of imputed DataFrames from different methods\n",
    "    columns_to_impute : list\n",
    "        List of column names to impute\n",
    "    \"\"\"\n",
    "    # Filter to only include columns that exist in the original dataframe\n",
    "    valid_columns = [col for col in columns_to_impute if col in original_df.columns]\n",
    "    \n",
    "    if not valid_columns:\n",
    "        print(\"No valid columns found for plotting histograms\")\n",
    "        return\n",
    "        \n",
    "    print(f\"Plotting histograms for columns: {valid_columns}\")\n",
    "    \n",
    "    # Number of columns and methods\n",
    "    n_cols = len(valid_columns)\n",
    "    n_methods = len(imputed_dfs)\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(n_cols, 1, figsize=(12, 4 * n_cols))\n",
    "    if n_cols == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    # Plot for each column\n",
    "    for i, col in enumerate(valid_columns):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Plot original observed distribution\n",
    "        observed_values = original_df[col].dropna()\n",
    "        n_observed = len(observed_values)\n",
    "        \n",
    "        sns.histplot(observed_values, ax=ax, \n",
    "                    label=f'Original (observed, n={n_observed})', \n",
    "                    alpha=0.5, color='black', kde=True)\n",
    "        \n",
    "        # Plot imputed distributions (only for previously missing values)\n",
    "        colors = plt.cm.tab10.colors\n",
    "        for j, (method_name, imputed_df) in enumerate(imputed_dfs.items()):\n",
    "            # Make sure the column exists in the imputed dataframe\n",
    "            if col not in imputed_df.columns:\n",
    "                print(f\"Warning: Column {col} not found in {method_name} results\")\n",
    "                continue\n",
    "                \n",
    "            # Get just the imputed values (where original was missing)\n",
    "            missing_mask = original_df[col].isna()\n",
    "            imputed_values = imputed_df.loc[missing_mask, col].dropna()\n",
    "            n_imputed = len(imputed_values)\n",
    "            \n",
    "            if not imputed_values.empty:\n",
    "                color = colors[j % len(colors)]\n",
    "                sns.histplot(imputed_values, ax=ax, \n",
    "                            label=f'{method_name} (imputed, n={n_imputed})', \n",
    "                            alpha=0.5, color=color, kde=True)\n",
    "        \n",
    "        # Add distribution statistics\n",
    "        if not observed_values.empty:\n",
    "            obs_mean = observed_values.mean()\n",
    "            obs_std = observed_values.std()\n",
    "            ax.axvline(obs_mean, color='black', linestyle='--', alpha=0.7)\n",
    "            textstr = f'Observed: μ={obs_mean:.2f}, σ={obs_std:.2f}'\n",
    "            props = dict(boxstyle='round', facecolor='white', alpha=0.5)\n",
    "            ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=10,\n",
    "                    verticalalignment='top', bbox=props)\n",
    "        \n",
    "        ax.set_title(f'Distribution for {col}', fontsize=14)\n",
    "        ax.legend()\n",
    "        ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('imputation_histograms.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()  # Close the plot to free memory\n",
    "    print(\"Histogram plot saved to 'imputation_histograms.png'\")\n",
    "\n",
    "def plot_correlation_preservation(original_df, imputed_dfs, columns_to_impute):\n",
    "    \"\"\"\n",
    "    Plot heatmaps showing how well each method preserves correlations\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    original_df : pandas.DataFrame\n",
    "        Original data with missing values\n",
    "    imputed_dfs : dict\n",
    "        Dictionary of imputed DataFrames from different methods\n",
    "    columns_to_impute : list\n",
    "        List of column names to impute\n",
    "    \"\"\"\n",
    "    # Filter to only include columns that exist in all dataframes\n",
    "    valid_columns = []\n",
    "    for col in columns_to_impute:\n",
    "        if col in original_df.columns:\n",
    "            all_valid = True\n",
    "            for method_name, imputed_df in imputed_dfs.items():\n",
    "                if col not in imputed_df.columns:\n",
    "                    all_valid = False\n",
    "                    break\n",
    "            if all_valid:\n",
    "                valid_columns.append(col)\n",
    "    \n",
    "    if not valid_columns:\n",
    "        print(\"No valid columns found for correlation analysis\")\n",
    "        return\n",
    "        \n",
    "    print(f\"Analyzing correlations for columns: {valid_columns}\")\n",
    "    \n",
    "    # Calculate original correlations (using only complete cases)\n",
    "    # This is important for sparse data - we need a baseline for comparison\n",
    "    complete_cases = original_df[valid_columns].dropna()\n",
    "    \n",
    "    if len(complete_cases) < 2:\n",
    "        print(\"Not enough complete cases to calculate original correlations\")\n",
    "        # Use pairwise correlations instead\n",
    "        original_corr = original_df[valid_columns].corr(method='pearson')\n",
    "    else:\n",
    "        original_corr = complete_cases.corr()\n",
    "    \n",
    "    # Calculate number of methods first\n",
    "    n_methods = len(imputed_dfs)\n",
    "    # Set up the figure - 2 rows, 4 columns\n",
    "    n_rows = 2\n",
    "    n_cols = 4\n",
    "    total_plots = n_methods + 1  # +1 for original correlations\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 8))  # 4 columns * 5 width, 2 rows * 4 height\n",
    "    axes = axes.flatten()  # Flatten to make indexing easier\n",
    "\n",
    "    if n_methods == 0:\n",
    "        print(\"No imputed dataframes to plot correlations\")\n",
    "        return\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for idx in range(total_plots, n_rows * n_cols):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    # Plot original correlation\n",
    "    sns.heatmap(original_corr, annot=False, cmap='coolwarm', vmin=-1, vmax=1, ax=axes[0])\n",
    "    axes[0].set_title('Original Correlations', fontsize=14)\n",
    "    axes[0].set_xticklabels([])\n",
    "    axes[0].set_yticklabels([])\n",
    "    axes[0].set_xlabel('')\n",
    "    axes[0].set_ylabel('')\n",
    "    \n",
    "    # Plot correlations for each imputation method\n",
    "    for i, (method_name, imputed_df) in enumerate(imputed_dfs.items()):\n",
    "        imputed_corr = imputed_df[valid_columns].corr()\n",
    "        sns.heatmap(imputed_corr, annot=False, cmap='coolwarm', vmin=-1, vmax=1, ax=axes[i+1])\n",
    "        axes[i+1].set_title(f'{method_name} Correlations', fontsize=14)\n",
    "        axes[i+1].set_xticklabels([])\n",
    "        axes[i+1].set_yticklabels([])\n",
    "        axes[i+1].set_xlabel('')\n",
    "        axes[i+1].set_ylabel('')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('correlation_preservation.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()  # Close the plot to free memory\n",
    "    print(\"Correlation plot saved to 'correlation_preservation.png'\")\n",
    "    \n",
    "    # Calculate and plot correlation differences\n",
    "    print(\"Calculating correlation differences...\")\n",
    "    correlation_diffs = {}\n",
    "    \n",
    "    for method_name, imputed_df in imputed_dfs.items():\n",
    "        imputed_corr = imputed_df[valid_columns].corr()\n",
    "        # Calculate absolute differences between original and imputed correlations\n",
    "        diff_matrix = np.abs(original_corr - imputed_corr)\n",
    "        correlation_diffs[method_name] = diff_matrix\n",
    "    \n",
    "    # Plot correlation differences (lower is better - less difference from original)\n",
    "    # Calculate grid dimensions: 2 rows, 4 columns\n",
    "    n_rows = 2\n",
    "    n_cols = 4\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 8))  # 4 columns * 5 width, 2 rows * 4 height\n",
    "    axes = axes.flatten()  # Flatten to make indexing easier\n",
    "\n",
    "    # Hide unused subplots if n_methods < 8\n",
    "    for idx in range(n_methods, n_rows * n_cols):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    for i, (method_name, diff_matrix) in enumerate(correlation_diffs.items()):\n",
    "        sns.heatmap(diff_matrix, annot=False, cmap='YlOrRd', vmin=0, vmax=1, ax=axes[i])\n",
    "        axes[i].set_title(f'{method_name} Correlation Differences', fontsize=12)\n",
    "        \n",
    "        # Hide x and y tick labels to reduce clutter\n",
    "        axes[i].set_xticklabels([])\n",
    "        axes[i].set_yticklabels([])\n",
    "        axes[i].set_xlabel('')\n",
    "        axes[i].set_ylabel('')\n",
    "        \n",
    "        # Calculate and display average difference\n",
    "        avg_diff = np.mean(diff_matrix.values)\n",
    "        axes[i].text(0.5, -0.05, f'Avg Diff: {avg_diff:.4f}', \n",
    "                    horizontalalignment='center', transform=axes[i].transAxes, fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('correlation_differences.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()  # Close the plot to free memory\n",
    "    print(\"Correlation difference plot saved to 'correlation_differences.png'\")\n",
    "\n",
    "\n",
    "\n",
    "def plot_validation_results(validation_results):\n",
    "    \"\"\"\n",
    "    Plot validation results including classification metrics\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    validation_results : dict\n",
    "        Dictionary with validation results\n",
    "    \"\"\"\n",
    "    # Prepare data for plotting\n",
    "    methods = [m for m in validation_results.keys() \n",
    "              if 'avg_mae' in validation_results[m] and not np.isnan(validation_results[m]['avg_mae'])]\n",
    "    \n",
    "    if not methods:\n",
    "        print(\"No valid validation results to plot\")\n",
    "        return\n",
    "    \n",
    "    # Extract metrics\n",
    "    mae_means = [validation_results[m]['avg_mae'] for m in methods]\n",
    "    mae_stds = [validation_results[m]['std_mae'] for m in methods]\n",
    "    rmse_means = [validation_results[m]['avg_rmse'] for m in methods]\n",
    "    rmse_stds = [validation_results[m]['std_rmse'] for m in methods]\n",
    "    acc_means = [validation_results[m].get('avg_accuracy', 0) for m in methods]\n",
    "    acc_stds = [validation_results[m].get('std_accuracy', 0) for m in methods]\n",
    "    auc_means = [validation_results[m].get('avg_auc_multiclass', 0) for m in methods]\n",
    "    auc_stds = [validation_results[m].get('std_auc_multiclass', 0) for m in methods]\n",
    "    sens_means = [validation_results[m].get('avg_avg_sensitivity', 0) for m in methods]\n",
    "    sens_stds = [validation_results[m].get('std_avg_sensitivity', 0) for m in methods]\n",
    "    spec_means = [validation_results[m].get('avg_avg_specificity', 0) for m in methods]\n",
    "    spec_stds = [validation_results[m].get('std_avg_specificity', 0) for m in methods]\n",
    "    ppv_means = [validation_results[m].get('avg_avg_ppv', 0) for m in methods]\n",
    "    ppv_stds = [validation_results[m].get('std_avg_ppv', 0) for m in methods]\n",
    "    npv_means = [validation_results[m].get('avg_avg_npv', 0) for m in methods]\n",
    "    npv_stds = [validation_results[m].get('std_avg_npv', 0) for m in methods]\n",
    "    time_means = [validation_results[m]['avg_time'] for m in methods]\n",
    "    time_stds = [validation_results[m]['std_time'] for m in methods]\n",
    "    \n",
    "    # Create figure with multiple subplots\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    metrics_data = [\n",
    "        (mae_means, mae_stds, 'MAE (Lower = Better)', 'blue'),\n",
    "        (rmse_means, rmse_stds, 'RMSE (Lower = Better)', 'orange'),\n",
    "        (acc_means, acc_stds, 'Accuracy (Higher = Better)', 'green'),\n",
    "        (auc_means, auc_stds, 'AUC Multi-class (Higher = Better)', 'red'),\n",
    "        (sens_means, sens_stds, 'Average Sensitivity (Higher = Better)', 'purple'),\n",
    "        (spec_means, spec_stds, 'Average Specificity (Higher = Better)', 'brown'),\n",
    "        (ppv_means, ppv_stds, 'Average PPV (Higher = Better)', 'pink'),\n",
    "        (npv_means, npv_stds, 'Average NPV (Higher = Better)', 'gray'),\n",
    "        (time_means, time_stds, 'Execution Time (Lower = Better)', 'cyan')\n",
    "    ]\n",
    "    \n",
    "    for i, (means, stds, title, color) in enumerate(metrics_data):\n",
    "        bars = axes[i].bar(methods, means, yerr=stds, capsize=5, alpha=0.7, color=color)\n",
    "        axes[i].set_title(title, fontsize=12)\n",
    "        axes[i].set_ylabel(title.split('(')[0].strip(), fontsize=10)\n",
    "        axes[i].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add values on top of bars (accounting for error bars)\n",
    "        for j, bar in enumerate(bars):\n",
    "            height = bar.get_height()\n",
    "            if not np.isnan(height):\n",
    "                # Add the standard deviation to position text above the error bar\n",
    "                text_height = height + stds[j] + 0.005 * max(means)\n",
    "                axes[i].text(bar.get_x() + bar.get_width()/2., text_height,\n",
    "                        f'{height:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('validation_results_with_classification.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def create_summary_dataframe(imputed_dfs, validation_results, distribution_similarity, execution_times):\n",
    "    \"\"\"\n",
    "    Create a summary dataframe of all results including classification metrics\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    imputed_dfs : dict\n",
    "        Dictionary of imputed DataFrames\n",
    "    validation_results : dict\n",
    "        Dictionary with validation results\n",
    "    distribution_similarity : dict\n",
    "        Dictionary with distribution similarity results\n",
    "    execution_times : dict\n",
    "        Dictionary with execution times\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    summary_df : pandas.DataFrame\n",
    "        DataFrame with summary of all results\n",
    "    \"\"\"\n",
    "    # Get list of methods\n",
    "    methods = list(imputed_dfs.keys())\n",
    "    \n",
    "    # Initialize summary data\n",
    "    summary_data = []\n",
    "    \n",
    "    for method in methods:\n",
    "        method_summary = {'Method': method}\n",
    "        \n",
    "        # Add validation metrics if available\n",
    "        if method in validation_results and 'avg_mae' in validation_results[method]:\n",
    "            method_summary['MAE'] = validation_results[method]['avg_mae']\n",
    "            method_summary['RMSE'] = validation_results[method]['avg_rmse']\n",
    "            method_summary['Accuracy'] = validation_results[method].get('avg_accuracy', np.nan)\n",
    "            method_summary['AUC'] = validation_results[method].get('avg_auc_multiclass', np.nan)\n",
    "            method_summary['Sensitivity'] = validation_results[method].get('avg_avg_sensitivity', np.nan)\n",
    "            method_summary['Specificity'] = validation_results[method].get('avg_avg_specificity', np.nan)\n",
    "            method_summary['PPV'] = validation_results[method].get('avg_avg_ppv', np.nan)\n",
    "            method_summary['NPV'] = validation_results[method].get('avg_avg_npv', np.nan)\n",
    "        else:\n",
    "            method_summary['MAE'] = np.nan\n",
    "            method_summary['RMSE'] = np.nan\n",
    "            method_summary['Accuracy'] = np.nan\n",
    "            method_summary['AUC'] = np.nan\n",
    "            method_summary['Sensitivity'] = np.nan\n",
    "            method_summary['Specificity'] = np.nan\n",
    "            method_summary['PPV'] = np.nan\n",
    "            method_summary['NPV'] = np.nan\n",
    "        \n",
    "        # Add execution time\n",
    "        if method in execution_times:\n",
    "            method_summary['Time (s)'] = execution_times[method]\n",
    "        else:\n",
    "            method_summary['Time (s)'] = np.nan\n",
    "        \n",
    "        # Add average distribution similarity metrics if available\n",
    "        if method in distribution_similarity:\n",
    "            ks_stats = []\n",
    "            ks_pvals = []\n",
    "            \n",
    "            for col, results in distribution_similarity[method].items():\n",
    "                if 'ks_stat' in results:\n",
    "                    ks_stats.append(results['ks_stat'])\n",
    "                if 'ks_pval' in results:\n",
    "                    ks_pvals.append(results['ks_pval'])\n",
    "            \n",
    "            if ks_stats:\n",
    "                method_summary['Avg KS Stat'] = np.mean(ks_stats)\n",
    "            else:\n",
    "                method_summary['Avg KS Stat'] = np.nan\n",
    "                \n",
    "            if ks_pvals:\n",
    "                method_summary['Avg KS p-value'] = np.mean(ks_pvals)\n",
    "            else:\n",
    "                method_summary['Avg KS p-value'] = np.nan\n",
    "        else:\n",
    "            method_summary['Avg KS Stat'] = np.nan\n",
    "            method_summary['Avg KS p-value'] = np.nan\n",
    "        \n",
    "        summary_data.append(method_summary)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Add ranks for each metric (1 is best)\n",
    "    # Lower is better for these metrics\n",
    "    for metric in ['MAE', 'RMSE', 'Time (s)', 'Avg KS Stat']:\n",
    "        if metric in summary_df.columns:\n",
    "            summary_df[f'{metric} Rank'] = summary_df[metric].rank()\n",
    "    \n",
    "    # Higher is better for these metrics\n",
    "    for metric in ['Accuracy', 'AUC', 'Sensitivity', 'Specificity', 'PPV', 'NPV', 'Avg KS p-value']:\n",
    "        if metric in summary_df.columns:\n",
    "            summary_df[f'{metric} Rank'] = summary_df[metric].rank(ascending=False)\n",
    "    \n",
    "    # Add average rank\n",
    "    rank_columns = [col for col in summary_df.columns if 'Rank' in col]\n",
    "    if rank_columns:\n",
    "        summary_df['Average Rank'] = summary_df[rank_columns].mean(axis=1)\n",
    "        summary_df = summary_df.sort_values('Average Rank')\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "\n",
    "\n",
    "def main_real_data(df, columns_to_impute):\n",
    "    \"\"\"\n",
    "    Main function to run imputation comparison on real data with high missingness\n",
    "    \n",
    "        Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Your real dataset with missing values\n",
    "    columns_to_impute : list\n",
    "        List of column names to impute (default: ge1-ge6)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    imputed_dfs : dict\n",
    "        Dictionary of imputed DataFrames from each method\n",
    "    summary_df : pandas.DataFrame\n",
    "        DataFrame with summary of all results\n",
    "    \"\"\"\n",
    "    print(\"===== Analyzing Dataset =====\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "    # Filter out any derived date columns from columns_to_impute\n",
    "    valid_columns = [col for col in columns_to_impute if col in df.columns and not col.startswith('qol_date_')]\n",
    "    if len(valid_columns) != len(columns_to_impute):\n",
    "        excluded_cols = set(columns_to_impute) - set(valid_columns)\n",
    "        print(f\"Warning: Excluding {len(excluded_cols)} columns that are not in the dataframe or are derived date columns:\")\n",
    "        print(f\"  {sorted(excluded_cols)}\")\n",
    "        print(f\"Using valid columns: {sorted(valid_columns)}\")\n",
    "        columns_to_impute = valid_columns\n",
    "\n",
    "    # Show basic statistics of the dataset\n",
    "    print(\"\\nMissing value counts:\")\n",
    "    missing_counts = df[columns_to_impute].isna().sum()\n",
    "    missing_percents = (missing_counts / len(df)) * 100\n",
    "    for col, count, percent in zip(columns_to_impute, missing_counts, missing_percents):\n",
    "        print(f\"{col}: {count} missing values ({percent:.2f}%)\")\n",
    "\n",
    "    # Print observed values statistics\n",
    "    print(\"\\nObserved values per column:\")\n",
    "    for i, col in enumerate(columns_to_impute):\n",
    "        observed = df[col].dropna()\n",
    "        n_observed = len(observed)\n",
    "        if n_observed > 0:\n",
    "            print(f\"{col}: {n_observed} observed values ({100-missing_percents[i]:.2f}%)\")\n",
    "            print(f\"  Range: {observed.min()} to {observed.max()}\")\n",
    "            print(f\"  Mean: {observed.mean():.4f}, Std: {observed.std():.4f}\")\n",
    "            print(f\"  Unique values: {observed.nunique()} ({observed.nunique()/n_observed*100:.1f}% unique)\")\n",
    "        else:\n",
    "            print(f\"{col}: No observed values\")\n",
    "\n",
    "    print(\"\\n===== Running imputation on real data =====\")\n",
    "    imputed_dfs, original_df, execution_times, distribution_similarity = evaluate_real_data_imputation(\n",
    "        df, columns_to_impute\n",
    "    )\n",
    "\n",
    "    # Create a version of original_df without qol_date for plotting\n",
    "    plotting_df = original_df.copy()\n",
    "    if 'qol_date' in plotting_df.columns:\n",
    "        print(\"\\nRemoving qol_date for plotting functions\")\n",
    "        plotting_df = plotting_df.drop(columns=['qol_date'])\n",
    "\n",
    "    # Also remove any derived date columns if they exist\n",
    "    date_derived_cols = [col for col in plotting_df.columns if col.startswith('qol_date_')]\n",
    "    if date_derived_cols:\n",
    "        print(f\"Removing derived date columns: {date_derived_cols}\")\n",
    "        plotting_df = plotting_df.drop(columns=date_derived_cols)\n",
    "\n",
    "    # Plot execution times\n",
    "    print(\"\\nPlotting execution times...\")\n",
    "    plot_execution_times(execution_times)\n",
    "\n",
    "    # Plot distribution similarity\n",
    "    print(\"\\nPlotting distribution similarity...\")\n",
    "    plot_distribution_similarity(distribution_similarity)\n",
    "\n",
    "    # Plot histograms of imputed values\n",
    "    print(\"\\nPlotting imputation histograms...\")\n",
    "    plot_imputation_histograms(plotting_df, imputed_dfs, columns_to_impute)\n",
    "\n",
    "    # Plot correlation preservation\n",
    "    print(\"\\nPlotting correlation preservation...\")\n",
    "    plot_correlation_preservation(plotting_df, imputed_dfs, columns_to_impute)\n",
    "\n",
    "    print(\"\\n===== Running sparse validation =====\")\n",
    "    validation_results = evaluate_with_sparse_validation(df, columns_to_impute, n_folds=3)\n",
    "\n",
    "    # Plot validation results\n",
    "    print(\"\\nPlotting validation results...\")\n",
    "    plot_validation_results(validation_results)\n",
    "\n",
    "    # Create summary dataframe\n",
    "    print(\"\\nCreating summary of results...\")\n",
    "    summary_df = create_summary_dataframe(\n",
    "        imputed_dfs, \n",
    "        validation_results, \n",
    "        distribution_similarity, \n",
    "        execution_times\n",
    "    )\n",
    "\n",
    "    # Print summary of results\n",
    "    print(\"\\n===== Summary of Results =====\")\n",
    "    print(summary_df.to_string())\n",
    "\n",
    "    # Save summary to CSV\n",
    "    summary_df.to_csv('imputation_summary.csv', index=False)\n",
    "\n",
    "    # Print recommended method based on average rank\n",
    "    if 'Average Rank' in summary_df.columns and not summary_df.empty:\n",
    "        best_method = summary_df.iloc[0]['Method']\n",
    "        print(f\"\\nRecommended imputation method: {best_method}\")\n",
    "\n",
    "    return imputed_dfs, summary_df\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your real dataset with missing values here\n",
    "    # df = pd.read_csv('your_dataset.csv')\n",
    "    \n",
    "    # Define columns to impute\n",
    "    \n",
    "    ordinal_cols = (\n",
    "    [f\"gp{i}\" for i in range(1, 8)] + [f\"gs{i}\" for i in range(1, 8)] +\n",
    "    [f\"ge{i}\" for i in range(1, 7)] + [f\"gf{i}\" for i in range(1, 8)] +\n",
    "    [f\"a_hn{i}\" for i in range(1, 6)] + [\"a_hn7\", \"a_hn10\"] +\n",
    "    [f\"a_e{i}\" for i in range(1, 8)] + [\"a_c6\", \"a_c2\", \"a_act11\"]\n",
    ")\n",
    "    columns_to_impute = ordinal_cols#['ge1', 'ge2', 'ge3', 'ge4', 'ge5', 'ge6']\n",
    "    \n",
    "    # Run the analysis\n",
    "    imputed_dfs, summary_df = main_real_data(df, columns_to_impute)\n",
    "    \n",
    "    # Example of how to save the best imputed dataset\n",
    "    if not summary_df.empty:\n",
    "        worst_method = summary_df.iloc[0]['Method']\n",
    "        print(f\"\\nSaving imputed dataset from {worst_method}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_finetuned_model(base_model_path, adapter_path):\n",
    "    \"\"\"\n",
    "    Load the base model and the LoRA adapter.\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model_path, use_fast=True)\n",
    "\n",
    "    # Load base model\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_path,\n",
    "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "        device_map=\"auto\" if torch.cuda.is_available() else None\n",
    "    )\n",
    "\n",
    "    # Load LoRA adapter\n",
    "    model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    return tokenizer, model\n",
    "\n",
    "\n",
    "def test_prompt(prompt, model, tokenizer, max_new_tokens=256):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(\"\\n🧠 Prompt:\")\n",
    "    print(prompt)\n",
    "    print(\"\\n📤 Output:\")\n",
    "    print(decoded)\n",
    "    return decoded\n",
    "\n",
    "def build_llama3_chat_prompt(user_input: str) -> str:\n",
    "    # Remove the <instructions>...</instructions> block\n",
    "    input_cleaned = re.sub(r\"<instructions>.*?</instructions>\", \"\", user_input, flags=re.DOTALL).strip()\n",
    "\n",
    "    system_message = (\n",
    "        \"You are an AI assistant trained using the ReAct approach (Reason + Act). \"\n",
    "        \"Your goal is to impute missing patient survey responses by reasoning through the most relevant predictor variables. \"\n",
    "        \"All values range from 0 to 4: \"\n",
    "        \"- 0 means 'not at all' \"\n",
    "        \"- 1 means 'a little bit' \"\n",
    "        \"- 2 means 'somewhat' \"\n",
    "        \"- 3 means 'quite a bit' \"\n",
    "        \"- 4 means 'very much'. \"\n",
    "        \"First, think step-by-step and explain your reasoning inside <think>...</think> tags. \"\n",
    "        \"Then, give your final imputed answer in JSON format inside <answer>...</answer>.\"\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\"\n",
    "        f\"{system_message}<|eot_id|>\\n\"\n",
    "        \"<|start_header_id|>user<|end_header_id|>\\n\"\n",
    "        f\"{input_cleaned}<|eot_id|>\\n\"\n",
    "        \"<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a04470de5a64be492ca67d5b7aed0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adapter_path = \"../../LoraFineTune/FinalFinalTopK4WH_ans_test3e-5_ep8_n20000_r32_a64_d0.1_q_v_b1_g8\"\n",
    "base_model_path = \"../../Llama-3.2-3B-Instruct\"\n",
    "\n",
    "# Load model\n",
    "tokenizer, model = load_finetuned_model(base_model_path, adapter_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Prompt:\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are an AI assistant trained using the ReAct approach (Reason + Act). Your goal is to impute missing patient survey responses by reasoning through the most relevant predictor variables. All values range from 0 to 4: - 0 means 'not at all' - 1 means 'a little bit' - 2 means 'somewhat' - 3 means 'quite a bit' - 4 means 'very much'. First, think step-by-step and explain your reasoning inside <think>...</think> tags. Then, give your final imputed answer in JSON format inside <answer>...</answer>.<|eot_id|>\n",
      "<|start_header_id|>user<|end_header_id|>\n",
      "<target>\n",
      "We are trying to impute 'gp1': I have a lack of energy\n",
      "</target>\n",
      "<correlations>\n",
      "- I feel ill = 0.0 (correlation: 0.56)\n",
      "- I am able to work (include work at home) = 4.0 (correlation: -0.53)\n",
      "- I have trouble meeting the needs of my family = 0.0 (correlation: 0.52)\n",
      "- I am able to enjoy life = 4.0 (correlation: -0.47)\n",
      "</correlations><|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "📤 Output:\n",
      "system\n",
      "You are an AI assistant trained using the ReAct approach (Reason + Act). Your goal is to impute missing patient survey responses by reasoning through the most relevant predictor variables. All values range from 0 to 4: - 0 means 'not at all' - 1 means 'a little bit' - 2 means'somewhat' - 3 means 'quite a bit' - 4 means'very much'. First, think step-by-step and explain your reasoning inside <think>...</think> tags. Then, give your final imputed answer in JSON format inside <answer>...</answer>.\n",
      "user\n",
      "<target>\n",
      "We are trying to impute 'gp1': I have a lack of energy\n",
      "</target>\n",
      "<correlations>\n",
      "- I feel ill = 0.0 (correlation: 0.56)\n",
      "- I am able to work (include work at home) = 4.0 (correlation: -0.53)\n",
      "- I have trouble meeting the needs of my family = 0.0 (correlation: 0.52)\n",
      "- I am able to enjoy life = 4.0 (correlation: -0.47)\n",
      "</correlations>\n",
      "assistant\n",
      "<answer>{\"gp1\": 0.0}</answer>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a valid chat-formatted prompt from raw user-style input\n",
    "raw_input = \"\"\"\n",
    "<instructions>\n",
    "You are an AI assistant designed to impute missing patient survey responses based on other available answers.\n",
    "All values range from 0 to 4:\n",
    "- 0 means 'not at all'\n",
    "- 1 means 'a little bit'\n",
    "- 2 means 'somewhat'\n",
    "- 3 means 'quite a bit'\n",
    "- 4 means 'very much'\n",
    "\n",
    "Use the provided information to infer the most likely response for the missing item.\n",
    "Return your final answer as a JSON object inside <answer>...</answer> tags.\n",
    "</instructions>\n",
    "<target>\n",
    "We are trying to impute 'gp1': I have a lack of energy\n",
    "</target>\n",
    "<correlations>\n",
    "- I feel ill = 0.0 (correlation: 0.56)\n",
    "- I am able to work (include work at home) = 4.0 (correlation: -0.53)\n",
    "- I have trouble meeting the needs of my family = 0.0 (correlation: 0.52)\n",
    "- I am able to enjoy life = 4.0 (correlation: -0.47)\n",
    "</correlations>\n",
    "\"\"\"\n",
    "\n",
    "chat_prompt = build_llama3_chat_prompt(raw_input)\n",
    "\n",
    "# Then call your test function\n",
    "output = test_prompt(chat_prompt, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
